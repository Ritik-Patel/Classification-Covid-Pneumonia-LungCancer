{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optuna-Normal-Pneumonia-COVID.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RTRrck6joDr",
        "outputId": "abf66768-843d-4881-e13a-46284602e8df"
      },
      "source": [
        "l!pip install optuna\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.9.1-py3-none-any.whl (302 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 61 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 71 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 81 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 92 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 102 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 112 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 122 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 143 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 153 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 163 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 174 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 184 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 194 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 204 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 215 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 225 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 235 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 245 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 256 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 266 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 276 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 286 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 296 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 302 kB 11.7 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-5.0.1-py2.py3-none-any.whl (10 kB)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.0)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.6.5-py2.py3-none-any.whl (164 kB)\n",
            "\u001b[K     |████████████████████████████████| 164 kB 46.5 MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "  Downloading cliff-3.8.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.22)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.0)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.6.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.1)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.2)\n",
            "Collecting python-editor>=0.3\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.4.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 51.7 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.1.2-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 46.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=6af2ee20d3a20a8205d5f3a6b78122004e9ab07f1e48ac58f5a0e97ad80c9483\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, colorama, stevedore, python-editor, Mako, cmd2, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.4 alembic-1.6.5 cliff-3.8.0 cmaes-0.8.2 cmd2-2.1.2 colorama-0.4.4 colorlog-5.0.1 optuna-2.9.1 pbr-5.6.0 pyperclip-1.8.2 python-editor-1.0.4 stevedore-3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MP1F_A6Ffpg6",
        "outputId": "17d61ed5-552f-4831-d322-0b404ed82321"
      },
      "source": [
        "optuna.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.9.1'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXscgTU0M_iq"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "import tensorflow.keras.optimizers\n",
        "import tensorflow.keras.losses\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16, ResNet101, Xception\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, MaxPooling2D, GlobalAveragePooling2D, Dropout, BatchNormalization, Conv2D, InputLayer\n",
        "\n",
        "import optuna\n",
        "from optuna.integration import TFKerasPruningCallback\n",
        "from optuna.trial import TrialState\n",
        "from optuna.integration import KerasPruningCallback\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.samplers import CmaEsSampler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--44Xf84cpnj",
        "outputId": "3cc85d22-35ce-472a-8d21-33d5b07dde8a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD-v-_nhNLnv"
      },
      "source": [
        "LR = 0.0001\n",
        "EPOCHS = 7\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = 224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8n1MklXNNZj",
        "outputId": "aab9cd6e-fe11-4853-c590-95ae500fac91"
      },
      "source": [
        "imagePaths = []\n",
        "\n",
        "i = 0\n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/Colab Notebooks/COVID-19_Radiography_Dataset/COVID/'):\n",
        "    for filename in filenames:\n",
        "        if (filename[-3:] == 'png'):\n",
        "            if (i < 500):\n",
        "              imagePaths.append(os.path.join(dirname, filename))\n",
        "              i +=1\n",
        "\n",
        "i = 0\n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/Colab Notebooks/COVID-19_Radiography_Dataset/Normal/'):\n",
        "    for filename in filenames:\n",
        "        if (filename[-3:] == 'png'):\n",
        "            if (i < 500):\n",
        "              imagePaths.append(os.path.join(dirname, filename))\n",
        "              i +=1\n",
        "\n",
        "i = 0\n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/Colab Notebooks/COVID-19_Radiography_Dataset/Viral Pneumonia/'):\n",
        "    for filename in filenames:\n",
        "        if (filename[-3:] == 'png'):\n",
        "            if (i < 500):\n",
        "              imagePaths.append(os.path.join(dirname, filename))\n",
        "              i +=1\n",
        "\n",
        "\n",
        "#Should return length for our dataset.\n",
        "len(imagePaths) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1500"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "rllShkgGNSKY",
        "outputId": "9f646901-7482-4ef8-9543-546ae957b460"
      },
      "source": [
        "print(imagePaths[66])\n",
        "\n",
        "image = cv2.imread(imagePaths[0])\n",
        "print(image.shape)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/COVID-19_Radiography_Dataset/COVID/COVID-3422.png\n",
            "(299, 299, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psIVSvGONUQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2c5176c-5eee-46fc-b567-90d6009c2ae2"
      },
      "source": [
        "IMG_SIZE = 224\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "\n",
        "for img_path in imagePaths:\n",
        "    label = img_path.split(os.path.sep)[-2]\n",
        "    \n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))/255.0\n",
        "    \n",
        "    X.append(img)\n",
        "    y.append(label)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(type(X), type(y), '\\n')\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> \n",
            "\n",
            "(1500, 224, 224, 3) (1500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "GXETxAelNWkK",
        "outputId": "c4592715-7c5c-4ff4-c758-dd57c2745b8e"
      },
      "source": [
        "#View counts of different labels\n",
        "y_df = pd.DataFrame(y, columns=['Labels'])\n",
        "print(y_df.head(), \"\\n\")\n",
        "print(y_df['Labels'].value_counts())\n",
        "\n",
        "sns.countplot(y_df['Labels'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Labels\n",
            "0  COVID\n",
            "1  COVID\n",
            "2  COVID\n",
            "3  COVID\n",
            "4  COVID \n",
            "\n",
            "COVID              500\n",
            "Normal             500\n",
            "Viral Pneumonia    500\n",
            "Name: Labels, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning:\n",
            "\n",
            "Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsY1Lx-xNXI3"
      },
      "source": [
        "#Encode labels as integers\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "#Convert list of labels to one-hot format\n",
        "y_encoded = np_utils.to_categorical(y_encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeO4fvtDNZWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b3147e2-05a0-4afa-fb1d-2151ec899750"
      },
      "source": [
        "#Check properties of label array\n",
        "print(y_encoded, '\\n')\n",
        "print(y_encoded[0], '\\n')\n",
        "print(type(y_encoded), '\\n')\n",
        "print(le.classes_, '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]] \n",
            "\n",
            "[1. 0. 0.] \n",
            "\n",
            "<class 'numpy.ndarray'> \n",
            "\n",
            "['COVID' 'Normal' 'Viral Pneumonia'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPuij2SONa88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b6611fe-8d83-49fa-b262-0e56c3847646"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.25, stratify=y_encoded, random_state=3)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "train_aug = ImageDataGenerator(rotation_range=15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1125, 224, 224, 3)\n",
            "(1125, 3)\n",
            "(375, 224, 224, 3)\n",
            "(375, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1esz3LNPOKmD"
      },
      "source": [
        "from tensorflow.keras.initializers import RandomNormal\n",
        "import tensorflow as tf\n",
        "def cnn():\n",
        "    base_model1 = Xception(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    features1 = base_model1.output\n",
        "    ######################################################################################################\n",
        "\n",
        "    base_model2 = ResNet101(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    features2 = base_model2.output\n",
        "    ######################################################################################################\n",
        "\n",
        "    #base_model3 = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    #features3 = base_model3.output\n",
        "    conv=tf.keras.layers.concatenate([features1,features2]) #Concatenate the extracted features\n",
        "    ####################################################################################################\n",
        "\n",
        "    conv = Sequential()\n",
        "    #onv.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3))(concatenated))\n",
        "    conv.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "    conv.add(MaxPooling2D((2, 2), padding='same'))\n",
        "    conv.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "    conv.add(MaxPooling2D((2, 2), padding='same'))\n",
        "    conv.add(Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "    conv.add(MaxPooling2D((2, 2), padding='same'))\n",
        "    conv.add(Conv2D(256, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "    conv.add(MaxPooling2D((2, 2), padding='same'))\n",
        "    conv.add(Conv2D(512, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "    conv.add(MaxPooling2D((2, 2), padding='same'))\n",
        "    conv.add(Flatten())\n",
        "    conv.add(Dropout(rate=dropout))\n",
        "    conv.add(Dense(512, activation='relu'))\n",
        "    conv.add(Dropout(rate=dropout))\n",
        "    conv.add(Dense(64, activation='relu'))\n",
        "    conv.add(Dense(3, activation='sigmoid'))\n",
        "    return conv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsTDBsp-joC5"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJfTsIwRoolI"
      },
      "source": [
        "from tensorflow.keras.backend import clear_session\n",
        "\n",
        "def objective(trial):\n",
        "    if tf.__version__ >= \"2\":\n",
        "        monitor = \"val_accuracy\"\n",
        "    else:\n",
        "        monitor = \"val_acc\"\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    epochs = trial.suggest_int('epochs', 40, 65)\n",
        "    batch_size = trial.suggest_int('batch_size', 24, 32)\n",
        "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n",
        "    conv = cnn()\n",
        "\n",
        "    conv.compile(optimizer= Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    #model.fit(cancer_files_train,train_labels,batch_size=None,epochs=10)\n",
        "    history = conv.fit(X_train, \n",
        "                        y_train, \n",
        "                        batch_size=batch_size,\n",
        "                        validation_data=(X_test, y_test),\n",
        "                        epochs=epochs,\n",
        "                        verbose=1)\n",
        "    \n",
        "    score = conv.evaluate(X_test, y_test, verbose=0)\n",
        "    return history.history[monitor][-1]\n",
        "\n",
        "\n",
        "#study = optuna.create_study(direction='maximize')\n",
        "#study.optimize(objective, n_trials=10)\n",
        "#trial = study.best_trial\n",
        "\n",
        "#print('Accuracy: {}'.format(trial.value))\n",
        "#print('Best hyperparameters: {}'.format(trial.params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-89iJnD4VRls",
        "outputId": "51c314b1-9c4b-4ab6-ff9d-0b2106457780"
      },
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #study = optuna.create_study(sampler=TPESampler())\n",
        "    #study.optimize(objective, n_trials=10)\n",
        "    study = optuna.create_study(sampler = optuna.samplers.CmaEsSampler())\n",
        "    study.optimize(objective, n_trials=15)\n",
        "\n",
        "    #study.optimize(objective, n_trials=25, timeout=600)\n",
        "    #pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "    #complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "    print(\"Study statistics: \")\n",
        "    print(\"  Number of finished trials: \", len(study.trials))\n",
        "    #print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "    #print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: \", trial.value)\n",
        "\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 09:31:28,200]\u001b[0m A new study created in memory with name: no-name-7f4ade57-93e0-4a05-af6c-5e22775b476b\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/47\n",
            "52/52 [==============================] - 39s 159ms/step - loss: 0.5108 - accuracy: 0.5926 - val_loss: 0.3893 - val_accuracy: 0.6889\n",
            "Epoch 2/47\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.3480 - accuracy: 0.7793 - val_loss: 0.2476 - val_accuracy: 0.8511\n",
            "Epoch 3/47\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.2733 - accuracy: 0.8311 - val_loss: 0.2435 - val_accuracy: 0.8311\n",
            "Epoch 4/47\n",
            "52/52 [==============================] - 6s 119ms/step - loss: 0.2378 - accuracy: 0.8637 - val_loss: 0.2048 - val_accuracy: 0.8756\n",
            "Epoch 5/47\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.1893 - accuracy: 0.8756 - val_loss: 0.2027 - val_accuracy: 0.8778\n",
            "Epoch 6/47\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.1718 - accuracy: 0.8926 - val_loss: 0.2067 - val_accuracy: 0.8800\n",
            "Epoch 7/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.1382 - accuracy: 0.9200 - val_loss: 0.1894 - val_accuracy: 0.9000\n",
            "Epoch 8/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.1049 - accuracy: 0.9430 - val_loss: 0.1916 - val_accuracy: 0.8956\n",
            "Epoch 9/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0908 - accuracy: 0.9481 - val_loss: 0.1702 - val_accuracy: 0.9044\n",
            "Epoch 10/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0811 - accuracy: 0.9511 - val_loss: 0.1815 - val_accuracy: 0.9067\n",
            "Epoch 11/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0527 - accuracy: 0.9733 - val_loss: 0.1701 - val_accuracy: 0.9289\n",
            "Epoch 12/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0390 - accuracy: 0.9800 - val_loss: 0.2377 - val_accuracy: 0.9067\n",
            "Epoch 13/47\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.0453 - accuracy: 0.9770 - val_loss: 0.2125 - val_accuracy: 0.9044\n",
            "Epoch 14/47\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.0481 - accuracy: 0.9756 - val_loss: 0.1925 - val_accuracy: 0.9067\n",
            "Epoch 15/47\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.0371 - accuracy: 0.9807 - val_loss: 0.2297 - val_accuracy: 0.9000\n",
            "Epoch 16/47\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.0331 - accuracy: 0.9844 - val_loss: 0.2311 - val_accuracy: 0.8978\n",
            "Epoch 17/47\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.0217 - accuracy: 0.9911 - val_loss: 0.2362 - val_accuracy: 0.9222\n",
            "Epoch 18/47\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.0237 - accuracy: 0.9859 - val_loss: 0.2317 - val_accuracy: 0.9200\n",
            "Epoch 19/47\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.0167 - accuracy: 0.9926 - val_loss: 0.2269 - val_accuracy: 0.9222\n",
            "Epoch 20/47\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.0238 - accuracy: 0.9867 - val_loss: 0.2142 - val_accuracy: 0.9178\n",
            "Epoch 21/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0393 - accuracy: 0.9852 - val_loss: 0.2319 - val_accuracy: 0.9067\n",
            "Epoch 22/47\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.0311 - accuracy: 0.9844 - val_loss: 0.2286 - val_accuracy: 0.9178\n",
            "Epoch 23/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0113 - accuracy: 0.9948 - val_loss: 0.2356 - val_accuracy: 0.9200\n",
            "Epoch 24/47\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9267\n",
            "Epoch 25/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 0.2691 - val_accuracy: 0.9289\n",
            "Epoch 26/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0052 - accuracy: 0.9970 - val_loss: 0.3001 - val_accuracy: 0.9200\n",
            "Epoch 27/47\n",
            "52/52 [==============================] - 6s 122ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.2363 - val_accuracy: 0.9067\n",
            "Epoch 28/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.2980 - val_accuracy: 0.9178\n",
            "Epoch 29/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0050 - accuracy: 0.9978 - val_loss: 0.3590 - val_accuracy: 0.9222\n",
            "Epoch 30/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0165 - accuracy: 0.9896 - val_loss: 0.3157 - val_accuracy: 0.9067\n",
            "Epoch 31/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0164 - accuracy: 0.9889 - val_loss: 0.2307 - val_accuracy: 0.9222\n",
            "Epoch 32/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0121 - accuracy: 0.9948 - val_loss: 0.2320 - val_accuracy: 0.9244\n",
            "Epoch 33/47\n",
            "52/52 [==============================] - 6s 122ms/step - loss: 0.0102 - accuracy: 0.9941 - val_loss: 0.3024 - val_accuracy: 0.9133\n",
            "Epoch 34/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0269 - accuracy: 0.9859 - val_loss: 0.3628 - val_accuracy: 0.9044\n",
            "Epoch 35/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0148 - accuracy: 0.9911 - val_loss: 0.3067 - val_accuracy: 0.9222\n",
            "Epoch 36/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0036 - accuracy: 0.9985 - val_loss: 0.2775 - val_accuracy: 0.9289\n",
            "Epoch 37/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0044 - accuracy: 0.9978 - val_loss: 0.3561 - val_accuracy: 0.9178\n",
            "Epoch 38/47\n",
            "52/52 [==============================] - 6s 122ms/step - loss: 0.0186 - accuracy: 0.9919 - val_loss: 0.4424 - val_accuracy: 0.8844\n",
            "Epoch 39/47\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.0449 - accuracy: 0.9733 - val_loss: 0.2416 - val_accuracy: 0.9244\n",
            "Epoch 40/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0036 - accuracy: 0.9985 - val_loss: 0.2510 - val_accuracy: 0.9111\n",
            "Epoch 41/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 9.3467e-04 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9222\n",
            "Epoch 42/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0038 - accuracy: 0.9978 - val_loss: 0.2795 - val_accuracy: 0.9244\n",
            "Epoch 43/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0085 - accuracy: 0.9948 - val_loss: 0.2764 - val_accuracy: 0.9244\n",
            "Epoch 44/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0066 - accuracy: 0.9963 - val_loss: 0.2936 - val_accuracy: 0.9111\n",
            "Epoch 45/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 0.9311\n",
            "Epoch 46/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0016 - accuracy: 0.9985 - val_loss: 0.3364 - val_accuracy: 0.9178\n",
            "Epoch 47/47\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0049 - accuracy: 0.9978 - val_loss: 0.2963 - val_accuracy: 0.9267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 09:37:16,013]\u001b[0m Trial 0 finished with value: 0.9266666769981384 and parameters: {'epochs': 47, 'batch_size': 26, 'lr': 0.0004215227456976838}. Best is trial 0 with value: 0.9266666769981384.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/52\n",
            "49/49 [==============================] - 10s 148ms/step - loss: 0.5846 - accuracy: 0.5296 - val_loss: 0.4382 - val_accuracy: 0.6978\n",
            "Epoch 2/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.4440 - accuracy: 0.6770 - val_loss: 0.3610 - val_accuracy: 0.7556\n",
            "Epoch 3/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.3930 - accuracy: 0.7200 - val_loss: 0.3314 - val_accuracy: 0.7333\n",
            "Epoch 4/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.3469 - accuracy: 0.7674 - val_loss: 0.2687 - val_accuracy: 0.8222\n",
            "Epoch 5/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.2872 - accuracy: 0.8067 - val_loss: 0.2387 - val_accuracy: 0.8733\n",
            "Epoch 6/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.2524 - accuracy: 0.8489 - val_loss: 0.2367 - val_accuracy: 0.8422\n",
            "Epoch 7/52\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.2275 - accuracy: 0.8748 - val_loss: 0.2044 - val_accuracy: 0.8667\n",
            "Epoch 8/52\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.2140 - accuracy: 0.8815 - val_loss: 0.2046 - val_accuracy: 0.8644\n",
            "Epoch 9/52\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.1934 - accuracy: 0.8889 - val_loss: 0.1905 - val_accuracy: 0.8756\n",
            "Epoch 10/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.1762 - accuracy: 0.8978 - val_loss: 0.1962 - val_accuracy: 0.8844\n",
            "Epoch 11/52\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.1592 - accuracy: 0.9104 - val_loss: 0.1887 - val_accuracy: 0.8911\n",
            "Epoch 12/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.1496 - accuracy: 0.9170 - val_loss: 0.2141 - val_accuracy: 0.8667\n",
            "Epoch 13/52\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.1450 - accuracy: 0.9141 - val_loss: 0.1695 - val_accuracy: 0.8911\n",
            "Epoch 14/52\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.1245 - accuracy: 0.9281 - val_loss: 0.1891 - val_accuracy: 0.8756\n",
            "Epoch 15/52\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.1208 - accuracy: 0.9304 - val_loss: 0.1766 - val_accuracy: 0.8822\n",
            "Epoch 16/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.1178 - accuracy: 0.9341 - val_loss: 0.1696 - val_accuracy: 0.9067\n",
            "Epoch 17/52\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.0961 - accuracy: 0.9511 - val_loss: 0.1700 - val_accuracy: 0.8933\n",
            "Epoch 18/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0961 - accuracy: 0.9437 - val_loss: 0.1776 - val_accuracy: 0.8889\n",
            "Epoch 19/52\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.0995 - accuracy: 0.9496 - val_loss: 0.2214 - val_accuracy: 0.8533\n",
            "Epoch 20/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0740 - accuracy: 0.9607 - val_loss: 0.1844 - val_accuracy: 0.9133\n",
            "Epoch 21/52\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.0679 - accuracy: 0.9659 - val_loss: 0.1768 - val_accuracy: 0.9200\n",
            "Epoch 22/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0719 - accuracy: 0.9578 - val_loss: 0.1602 - val_accuracy: 0.9267\n",
            "Epoch 23/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0564 - accuracy: 0.9733 - val_loss: 0.1847 - val_accuracy: 0.9089\n",
            "Epoch 24/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0605 - accuracy: 0.9719 - val_loss: 0.1673 - val_accuracy: 0.9022\n",
            "Epoch 25/52\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.0494 - accuracy: 0.9756 - val_loss: 0.1660 - val_accuracy: 0.9244\n",
            "Epoch 26/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0577 - accuracy: 0.9741 - val_loss: 0.1658 - val_accuracy: 0.9156\n",
            "Epoch 27/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0493 - accuracy: 0.9756 - val_loss: 0.1738 - val_accuracy: 0.9178\n",
            "Epoch 28/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0306 - accuracy: 0.9881 - val_loss: 0.1657 - val_accuracy: 0.9222\n",
            "Epoch 29/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0275 - accuracy: 0.9904 - val_loss: 0.1979 - val_accuracy: 0.9267\n",
            "Epoch 30/52\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0248 - accuracy: 0.9919 - val_loss: 0.1706 - val_accuracy: 0.9244\n",
            "Epoch 31/52\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.0342 - accuracy: 0.9807 - val_loss: 0.1907 - val_accuracy: 0.9333\n",
            "Epoch 32/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0302 - accuracy: 0.9859 - val_loss: 0.2074 - val_accuracy: 0.9111\n",
            "Epoch 33/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0217 - accuracy: 0.9904 - val_loss: 0.1786 - val_accuracy: 0.9311\n",
            "Epoch 34/52\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.2137 - val_accuracy: 0.9244\n",
            "Epoch 35/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0198 - accuracy: 0.9911 - val_loss: 0.2080 - val_accuracy: 0.9156\n",
            "Epoch 36/52\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.2328 - val_accuracy: 0.8978\n",
            "Epoch 37/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0172 - accuracy: 0.9933 - val_loss: 0.1965 - val_accuracy: 0.9267\n",
            "Epoch 38/52\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0172 - accuracy: 0.9933 - val_loss: 0.2087 - val_accuracy: 0.9200\n",
            "Epoch 39/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0116 - accuracy: 0.9978 - val_loss: 0.2066 - val_accuracy: 0.9333\n",
            "Epoch 40/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.2093 - val_accuracy: 0.9222\n",
            "Epoch 41/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0069 - accuracy: 0.9993 - val_loss: 0.1997 - val_accuracy: 0.9289\n",
            "Epoch 42/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.2109 - val_accuracy: 0.9244\n",
            "Epoch 43/52\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9267\n",
            "Epoch 44/52\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0128 - accuracy: 0.9948 - val_loss: 0.2144 - val_accuracy: 0.9222\n",
            "Epoch 45/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0079 - accuracy: 0.9993 - val_loss: 0.2143 - val_accuracy: 0.9289\n",
            "Epoch 46/52\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9244\n",
            "Epoch 47/52\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0109 - accuracy: 0.9956 - val_loss: 0.2004 - val_accuracy: 0.9356\n",
            "Epoch 48/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.2083 - val_accuracy: 0.9267\n",
            "Epoch 49/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9244\n",
            "Epoch 50/52\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9267\n",
            "Epoch 51/52\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9267\n",
            "Epoch 52/52\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9311\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 09:42:45,713]\u001b[0m Trial 1 finished with value: 0.9311110973358154 and parameters: {'epochs': 52, 'batch_size': 28, 'lr': 4.876532477045271e-05}. Best is trial 0 with value: 0.9266666769981384.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/52\n",
            "47/47 [==============================] - 10s 168ms/step - loss: 0.5358 - accuracy: 0.5748 - val_loss: 0.3950 - val_accuracy: 0.6667\n",
            "Epoch 2/52\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.3760 - accuracy: 0.7496 - val_loss: 0.3102 - val_accuracy: 0.7911\n",
            "Epoch 3/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.3053 - accuracy: 0.8119 - val_loss: 0.2578 - val_accuracy: 0.8533\n",
            "Epoch 4/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.2515 - accuracy: 0.8459 - val_loss: 0.2332 - val_accuracy: 0.8467\n",
            "Epoch 5/52\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.2088 - accuracy: 0.8793 - val_loss: 0.2024 - val_accuracy: 0.8756\n",
            "Epoch 6/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.1837 - accuracy: 0.8926 - val_loss: 0.1934 - val_accuracy: 0.8822\n",
            "Epoch 7/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.1573 - accuracy: 0.9067 - val_loss: 0.1817 - val_accuracy: 0.8889\n",
            "Epoch 8/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.1472 - accuracy: 0.9170 - val_loss: 0.2411 - val_accuracy: 0.8422\n",
            "Epoch 9/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.1347 - accuracy: 0.9178 - val_loss: 0.1758 - val_accuracy: 0.8822\n",
            "Epoch 10/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.1068 - accuracy: 0.9407 - val_loss: 0.2219 - val_accuracy: 0.8467\n",
            "Epoch 11/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0859 - accuracy: 0.9563 - val_loss: 0.2361 - val_accuracy: 0.8778\n",
            "Epoch 12/52\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.1093 - accuracy: 0.9422 - val_loss: 0.1907 - val_accuracy: 0.9044\n",
            "Epoch 13/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0675 - accuracy: 0.9622 - val_loss: 0.1879 - val_accuracy: 0.9022\n",
            "Epoch 14/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0522 - accuracy: 0.9674 - val_loss: 0.1791 - val_accuracy: 0.9222\n",
            "Epoch 15/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0584 - accuracy: 0.9726 - val_loss: 0.2210 - val_accuracy: 0.9022\n",
            "Epoch 16/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0590 - accuracy: 0.9696 - val_loss: 0.1825 - val_accuracy: 0.9067\n",
            "Epoch 17/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0430 - accuracy: 0.9793 - val_loss: 0.2882 - val_accuracy: 0.8822\n",
            "Epoch 18/52\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.0378 - accuracy: 0.9793 - val_loss: 0.1691 - val_accuracy: 0.9178\n",
            "Epoch 19/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0229 - accuracy: 0.9911 - val_loss: 0.2496 - val_accuracy: 0.9067\n",
            "Epoch 20/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0278 - accuracy: 0.9874 - val_loss: 0.1962 - val_accuracy: 0.9156\n",
            "Epoch 21/52\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.0285 - accuracy: 0.9844 - val_loss: 0.2768 - val_accuracy: 0.9044\n",
            "Epoch 22/52\n",
            "47/47 [==============================] - 6s 126ms/step - loss: 0.0352 - accuracy: 0.9852 - val_loss: 0.1974 - val_accuracy: 0.9133\n",
            "Epoch 23/52\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.0104 - accuracy: 0.9956 - val_loss: 0.2007 - val_accuracy: 0.9311\n",
            "Epoch 24/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.2151 - val_accuracy: 0.9311\n",
            "Epoch 25/52\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.0143 - accuracy: 0.9941 - val_loss: 0.2152 - val_accuracy: 0.9311\n",
            "Epoch 26/52\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.0076 - accuracy: 0.9963 - val_loss: 0.2094 - val_accuracy: 0.9356\n",
            "Epoch 27/52\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.3001 - val_accuracy: 0.9244\n",
            "Epoch 28/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.2864 - val_accuracy: 0.9222\n",
            "Epoch 29/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0172 - accuracy: 0.9926 - val_loss: 0.3119 - val_accuracy: 0.8933\n",
            "Epoch 30/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0119 - accuracy: 0.9941 - val_loss: 0.2439 - val_accuracy: 0.9333\n",
            "Epoch 31/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0223 - accuracy: 0.9896 - val_loss: 0.2084 - val_accuracy: 0.9244\n",
            "Epoch 32/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.2454 - val_accuracy: 0.9311\n",
            "Epoch 33/52\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.0141 - accuracy: 0.9926 - val_loss: 0.2611 - val_accuracy: 0.9067\n",
            "Epoch 34/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0193 - accuracy: 0.9926 - val_loss: 0.2514 - val_accuracy: 0.9289\n",
            "Epoch 35/52\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.2401 - val_accuracy: 0.9356\n",
            "Epoch 36/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9200\n",
            "Epoch 37/52\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9356\n",
            "Epoch 38/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 6.9506e-04 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9356\n",
            "Epoch 39/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 3.5330e-04 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9333\n",
            "Epoch 40/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 2.7637e-04 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9378\n",
            "Epoch 41/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0163 - accuracy: 0.9933 - val_loss: 0.2469 - val_accuracy: 0.8978\n",
            "Epoch 42/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.2612 - val_accuracy: 0.9356\n",
            "Epoch 43/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.2359 - val_accuracy: 0.9111\n",
            "Epoch 44/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 8.7021e-04 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9400\n",
            "Epoch 45/52\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 5.6483e-04 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9422\n",
            "Epoch 46/52\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 6.9384e-04 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9467\n",
            "Epoch 47/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 2.4729e-04 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9400\n",
            "Epoch 48/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 1.6054e-04 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9378\n",
            "Epoch 49/52\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 2.0933e-04 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.9378\n",
            "Epoch 50/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 1.4795e-04 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9311\n",
            "Epoch 51/52\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 1.5132e-04 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.9378\n",
            "Epoch 52/52\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 2.2396e-04 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.9311\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 09:48:15,537]\u001b[0m Trial 2 finished with value: 0.9311110973358154 and parameters: {'epochs': 52, 'batch_size': 29, 'lr': 0.00018383451140882706}. Best is trial 0 with value: 0.9266666769981384.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/53\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.6101 - accuracy: 0.4859 - val_loss: 0.4757 - val_accuracy: 0.7133\n",
            "Epoch 2/53\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.4347 - accuracy: 0.6896 - val_loss: 0.3530 - val_accuracy: 0.7733\n",
            "Epoch 3/53\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.3631 - accuracy: 0.7504 - val_loss: 0.2881 - val_accuracy: 0.8244\n",
            "Epoch 4/53\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.3198 - accuracy: 0.7844 - val_loss: 0.2587 - val_accuracy: 0.8289\n",
            "Epoch 5/53\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.2675 - accuracy: 0.8489 - val_loss: 0.2132 - val_accuracy: 0.8667\n",
            "Epoch 6/53\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.2353 - accuracy: 0.8696 - val_loss: 0.2232 - val_accuracy: 0.8733\n",
            "Epoch 7/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.2253 - accuracy: 0.8667 - val_loss: 0.1974 - val_accuracy: 0.8867\n",
            "Epoch 8/53\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.1975 - accuracy: 0.8844 - val_loss: 0.2081 - val_accuracy: 0.8667\n",
            "Epoch 9/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.1902 - accuracy: 0.8859 - val_loss: 0.1866 - val_accuracy: 0.8844\n",
            "Epoch 10/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.1570 - accuracy: 0.9126 - val_loss: 0.2120 - val_accuracy: 0.8556\n",
            "Epoch 11/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.1526 - accuracy: 0.9141 - val_loss: 0.1897 - val_accuracy: 0.8978\n",
            "Epoch 12/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.1390 - accuracy: 0.9185 - val_loss: 0.1737 - val_accuracy: 0.8889\n",
            "Epoch 13/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.1186 - accuracy: 0.9393 - val_loss: 0.1748 - val_accuracy: 0.8911\n",
            "Epoch 14/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.1101 - accuracy: 0.9415 - val_loss: 0.1799 - val_accuracy: 0.8956\n",
            "Epoch 15/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.1056 - accuracy: 0.9504 - val_loss: 0.1824 - val_accuracy: 0.9089\n",
            "Epoch 16/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0941 - accuracy: 0.9504 - val_loss: 0.1729 - val_accuracy: 0.9067\n",
            "Epoch 17/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0868 - accuracy: 0.9593 - val_loss: 0.1667 - val_accuracy: 0.9022\n",
            "Epoch 18/53\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.0798 - accuracy: 0.9600 - val_loss: 0.1709 - val_accuracy: 0.9178\n",
            "Epoch 19/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0639 - accuracy: 0.9644 - val_loss: 0.1691 - val_accuracy: 0.9111\n",
            "Epoch 20/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0638 - accuracy: 0.9659 - val_loss: 0.1693 - val_accuracy: 0.8978\n",
            "Epoch 21/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0574 - accuracy: 0.9711 - val_loss: 0.1898 - val_accuracy: 0.9044\n",
            "Epoch 22/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0487 - accuracy: 0.9763 - val_loss: 0.1736 - val_accuracy: 0.9222\n",
            "Epoch 23/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0474 - accuracy: 0.9748 - val_loss: 0.1720 - val_accuracy: 0.9022\n",
            "Epoch 24/53\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.0422 - accuracy: 0.9770 - val_loss: 0.1820 - val_accuracy: 0.9067\n",
            "Epoch 25/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0411 - accuracy: 0.9830 - val_loss: 0.1703 - val_accuracy: 0.9222\n",
            "Epoch 26/53\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.0292 - accuracy: 0.9896 - val_loss: 0.1800 - val_accuracy: 0.9267\n",
            "Epoch 27/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0248 - accuracy: 0.9867 - val_loss: 0.2166 - val_accuracy: 0.9178\n",
            "Epoch 28/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0296 - accuracy: 0.9852 - val_loss: 0.2296 - val_accuracy: 0.8889\n",
            "Epoch 29/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0283 - accuracy: 0.9852 - val_loss: 0.2088 - val_accuracy: 0.9133\n",
            "Epoch 30/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0228 - accuracy: 0.9919 - val_loss: 0.1936 - val_accuracy: 0.9267\n",
            "Epoch 31/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0274 - accuracy: 0.9904 - val_loss: 0.2346 - val_accuracy: 0.9000\n",
            "Epoch 32/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0177 - accuracy: 0.9956 - val_loss: 0.2125 - val_accuracy: 0.9200\n",
            "Epoch 33/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0177 - accuracy: 0.9919 - val_loss: 0.2301 - val_accuracy: 0.9289\n",
            "Epoch 34/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.2266 - val_accuracy: 0.9244\n",
            "Epoch 35/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0244 - accuracy: 0.9874 - val_loss: 0.3117 - val_accuracy: 0.9044\n",
            "Epoch 36/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.2547 - val_accuracy: 0.9133\n",
            "Epoch 37/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0089 - accuracy: 0.9978 - val_loss: 0.2297 - val_accuracy: 0.9200\n",
            "Epoch 38/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 0.2604 - val_accuracy: 0.9178\n",
            "Epoch 39/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9200\n",
            "Epoch 40/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 0.2975 - val_accuracy: 0.8956\n",
            "Epoch 41/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0175 - accuracy: 0.9926 - val_loss: 0.2655 - val_accuracy: 0.9089\n",
            "Epoch 42/53\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.2633 - val_accuracy: 0.9133\n",
            "Epoch 43/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0070 - accuracy: 0.9993 - val_loss: 0.2462 - val_accuracy: 0.9178\n",
            "Epoch 44/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9222\n",
            "Epoch 45/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.2667 - val_accuracy: 0.9222\n",
            "Epoch 46/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.2801 - val_accuracy: 0.9244\n",
            "Epoch 47/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9267\n",
            "Epoch 48/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0104 - accuracy: 0.9956 - val_loss: 0.2631 - val_accuracy: 0.9222\n",
            "Epoch 49/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.2830 - val_accuracy: 0.9222\n",
            "Epoch 50/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0217 - accuracy: 0.9889 - val_loss: 0.2616 - val_accuracy: 0.9222\n",
            "Epoch 51/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0571 - accuracy: 0.9719 - val_loss: 0.2100 - val_accuracy: 0.9089\n",
            "Epoch 52/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0189 - accuracy: 0.9926 - val_loss: 0.2313 - val_accuracy: 0.9089\n",
            "Epoch 53/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0097 - accuracy: 0.9978 - val_loss: 0.2368 - val_accuracy: 0.9222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 09:54:45,618]\u001b[0m Trial 3 finished with value: 0.9222221970558167 and parameters: {'epochs': 53, 'batch_size': 28, 'lr': 5.9153123921054314e-05}. Best is trial 3 with value: 0.9222221970558167.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/52\n",
            "45/45 [==============================] - 9s 141ms/step - loss: 0.5163 - accuracy: 0.5815 - val_loss: 0.3696 - val_accuracy: 0.7467\n",
            "Epoch 2/52\n",
            "45/45 [==============================] - 6s 134ms/step - loss: 0.3469 - accuracy: 0.7778 - val_loss: 0.2293 - val_accuracy: 0.8467\n",
            "Epoch 3/52\n",
            "45/45 [==============================] - 6s 131ms/step - loss: 0.2659 - accuracy: 0.8400 - val_loss: 0.2100 - val_accuracy: 0.8733\n",
            "Epoch 4/52\n",
            "45/45 [==============================] - 6s 134ms/step - loss: 0.2125 - accuracy: 0.8837 - val_loss: 0.2512 - val_accuracy: 0.8400\n",
            "Epoch 5/52\n",
            "45/45 [==============================] - 6s 131ms/step - loss: 0.2062 - accuracy: 0.8704 - val_loss: 0.2011 - val_accuracy: 0.8644\n",
            "Epoch 6/52\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 0.1764 - accuracy: 0.8896 - val_loss: 0.2267 - val_accuracy: 0.8378\n",
            "Epoch 7/52\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 0.1486 - accuracy: 0.9133 - val_loss: 0.1749 - val_accuracy: 0.9022\n",
            "Epoch 8/52\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 0.1221 - accuracy: 0.9378 - val_loss: 0.1790 - val_accuracy: 0.8933\n",
            "Epoch 9/52\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 0.1017 - accuracy: 0.9422 - val_loss: 0.1748 - val_accuracy: 0.8933\n",
            "Epoch 10/52\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 0.0895 - accuracy: 0.9526 - val_loss: 0.1998 - val_accuracy: 0.8867\n",
            "Epoch 11/52\n",
            "45/45 [==============================] - 6s 134ms/step - loss: 0.0712 - accuracy: 0.9570 - val_loss: 0.2065 - val_accuracy: 0.8978\n",
            "Epoch 12/52\n",
            "45/45 [==============================] - 6s 134ms/step - loss: 0.0580 - accuracy: 0.9681 - val_loss: 0.1866 - val_accuracy: 0.9067\n",
            "Epoch 13/52\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 0.0544 - accuracy: 0.9704 - val_loss: 0.2086 - val_accuracy: 0.9156\n",
            "Epoch 14/52\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 0.0302 - accuracy: 0.9852 - val_loss: 0.2201 - val_accuracy: 0.9111\n",
            "Epoch 15/52\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 0.0384 - accuracy: 0.9807 - val_loss: 0.2010 - val_accuracy: 0.9089\n",
            "Epoch 16/52\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 0.0245 - accuracy: 0.9889 - val_loss: 0.2208 - val_accuracy: 0.9044\n",
            "Epoch 17/52\n",
            "45/45 [==============================] - 6s 134ms/step - loss: 0.0142 - accuracy: 0.9933 - val_loss: 0.2411 - val_accuracy: 0.9111\n",
            "Epoch 18/52\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 0.0319 - accuracy: 0.9867 - val_loss: 0.2023 - val_accuracy: 0.9111\n",
            "Epoch 19/52\n",
            "45/45 [==============================] - 6s 131ms/step - loss: 0.0347 - accuracy: 0.9800 - val_loss: 0.2864 - val_accuracy: 0.8867\n",
            "Epoch 20/52\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 0.0287 - accuracy: 0.9852 - val_loss: 0.2219 - val_accuracy: 0.8978\n",
            "Epoch 21/52\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 0.0234 - accuracy: 0.9874 - val_loss: 0.1883 - val_accuracy: 0.9067\n",
            "Epoch 22/52\n",
            "45/45 [==============================] - 6s 131ms/step - loss: 0.0141 - accuracy: 0.9933 - val_loss: 0.2479 - val_accuracy: 0.9111\n",
            "Epoch 23/52\n",
            "45/45 [==============================] - 6s 131ms/step - loss: 0.0202 - accuracy: 0.9911 - val_loss: 0.2204 - val_accuracy: 0.9244\n",
            "Epoch 24/52\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 0.0168 - accuracy: 0.9919 - val_loss: 0.2651 - val_accuracy: 0.9222\n",
            "Epoch 25/52\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.2262 - val_accuracy: 0.9311\n",
            "Epoch 26/52\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9333\n",
            "Epoch 27/52\n",
            "45/45 [==============================] - 6s 134ms/step - loss: 7.1820e-04 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.9378\n",
            "Epoch 28/52\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 3.3291e-04 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9311\n",
            "Epoch 29/52\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 4.4310e-04 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9378\n",
            "Epoch 30/52\n",
            "45/45 [==============================] - 6s 134ms/step - loss: 4.1374e-04 - accuracy: 1.0000 - val_loss: 0.2886 - val_accuracy: 0.9244\n",
            "Epoch 31/52\n",
            "45/45 [==============================] - 6s 134ms/step - loss: 2.2180e-04 - accuracy: 1.0000 - val_loss: 0.2823 - val_accuracy: 0.9289\n",
            "Epoch 32/52\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 1.4514e-04 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9289\n",
            "Epoch 33/52\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 1.4901e-04 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9267\n",
            "Epoch 34/52\n",
            "45/45 [==============================] - 6s 134ms/step - loss: 1.6125e-04 - accuracy: 1.0000 - val_loss: 0.3014 - val_accuracy: 0.9244\n",
            "Epoch 35/52\n",
            "45/45 [==============================] - 6s 135ms/step - loss: 1.3897e-04 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.9267\n",
            "Epoch 36/52\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 3.1541e-04 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9222\n",
            "Epoch 37/52\n",
            "45/45 [==============================] - 6s 134ms/step - loss: 0.0031 - accuracy: 0.9985 - val_loss: 0.3446 - val_accuracy: 0.9178\n",
            "Epoch 38/52\n",
            "45/45 [==============================] - 6s 134ms/step - loss: 0.0172 - accuracy: 0.9911 - val_loss: 0.4482 - val_accuracy: 0.8756\n",
            "Epoch 39/52\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 0.0559 - accuracy: 0.9704 - val_loss: 0.2467 - val_accuracy: 0.8978\n",
            "Epoch 40/52\n",
            "45/45 [==============================] - 6s 134ms/step - loss: 0.0337 - accuracy: 0.9815 - val_loss: 0.2280 - val_accuracy: 0.9178\n",
            "Epoch 41/52\n",
            "45/45 [==============================] - 6s 134ms/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.2843 - val_accuracy: 0.9156\n",
            "Epoch 42/52\n",
            "45/45 [==============================] - 6s 131ms/step - loss: 0.0154 - accuracy: 0.9933 - val_loss: 0.3073 - val_accuracy: 0.9089\n",
            "Epoch 43/52\n",
            "45/45 [==============================] - 6s 135ms/step - loss: 0.0267 - accuracy: 0.9911 - val_loss: 0.2270 - val_accuracy: 0.9222\n",
            "Epoch 44/52\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.2474 - val_accuracy: 0.9267\n",
            "Epoch 45/52\n",
            "45/45 [==============================] - 6s 131ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9333\n",
            "Epoch 46/52\n",
            "45/45 [==============================] - 6s 131ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.9267\n",
            "Epoch 47/52\n",
            "45/45 [==============================] - 6s 132ms/step - loss: 8.6571e-04 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9222\n",
            "Epoch 48/52\n",
            "45/45 [==============================] - 6s 132ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.2934 - val_accuracy: 0.9222\n",
            "Epoch 49/52\n",
            "45/45 [==============================] - 6s 134ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.2753 - val_accuracy: 0.9200\n",
            "Epoch 50/52\n",
            "45/45 [==============================] - 6s 131ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3246 - val_accuracy: 0.9222\n",
            "Epoch 51/52\n",
            "45/45 [==============================] - 6s 136ms/step - loss: 4.0558e-04 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9244\n",
            "Epoch 52/52\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 2.4548e-04 - accuracy: 1.0000 - val_loss: 0.3412 - val_accuracy: 0.9267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 10:00:05,189]\u001b[0m Trial 4 finished with value: 0.9266666769981384 and parameters: {'epochs': 52, 'batch_size': 30, 'lr': 0.00025938483827051814}. Best is trial 3 with value: 0.9222221970558167.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/53\n",
            "49/49 [==============================] - 8s 136ms/step - loss: 0.5581 - accuracy: 0.5274 - val_loss: 0.4191 - val_accuracy: 0.6267\n",
            "Epoch 2/53\n",
            "49/49 [==============================] - 6s 129ms/step - loss: 0.4078 - accuracy: 0.7015 - val_loss: 0.3519 - val_accuracy: 0.7667\n",
            "Epoch 3/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.3505 - accuracy: 0.7489 - val_loss: 0.2953 - val_accuracy: 0.8044\n",
            "Epoch 4/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.3062 - accuracy: 0.8059 - val_loss: 0.2415 - val_accuracy: 0.8733\n",
            "Epoch 5/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.2628 - accuracy: 0.8481 - val_loss: 0.2174 - val_accuracy: 0.8711\n",
            "Epoch 6/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.2229 - accuracy: 0.8681 - val_loss: 0.2091 - val_accuracy: 0.8689\n",
            "Epoch 7/53\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 0.1937 - accuracy: 0.8859 - val_loss: 0.1991 - val_accuracy: 0.8756\n",
            "Epoch 8/53\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 0.1697 - accuracy: 0.9081 - val_loss: 0.1842 - val_accuracy: 0.8844\n",
            "Epoch 9/53\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 0.1574 - accuracy: 0.9133 - val_loss: 0.2108 - val_accuracy: 0.8533\n",
            "Epoch 10/53\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 0.1360 - accuracy: 0.9252 - val_loss: 0.1988 - val_accuracy: 0.8822\n",
            "Epoch 11/53\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 0.1314 - accuracy: 0.9281 - val_loss: 0.1968 - val_accuracy: 0.8711\n",
            "Epoch 12/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.1258 - accuracy: 0.9222 - val_loss: 0.1717 - val_accuracy: 0.8956\n",
            "Epoch 13/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.1006 - accuracy: 0.9467 - val_loss: 0.1965 - val_accuracy: 0.8844\n",
            "Epoch 14/53\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 0.0882 - accuracy: 0.9481 - val_loss: 0.1684 - val_accuracy: 0.9133\n",
            "Epoch 15/53\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 0.0827 - accuracy: 0.9593 - val_loss: 0.1796 - val_accuracy: 0.9022\n",
            "Epoch 16/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.0618 - accuracy: 0.9652 - val_loss: 0.1684 - val_accuracy: 0.9200\n",
            "Epoch 17/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.0538 - accuracy: 0.9696 - val_loss: 0.1691 - val_accuracy: 0.9089\n",
            "Epoch 18/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0474 - accuracy: 0.9778 - val_loss: 0.1847 - val_accuracy: 0.9133\n",
            "Epoch 19/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.0414 - accuracy: 0.9793 - val_loss: 0.1848 - val_accuracy: 0.9111\n",
            "Epoch 20/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.0460 - accuracy: 0.9800 - val_loss: 0.1875 - val_accuracy: 0.9156\n",
            "Epoch 21/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.0339 - accuracy: 0.9859 - val_loss: 0.1745 - val_accuracy: 0.9156\n",
            "Epoch 22/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.0303 - accuracy: 0.9830 - val_loss: 0.1841 - val_accuracy: 0.9289\n",
            "Epoch 23/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0243 - accuracy: 0.9904 - val_loss: 0.1720 - val_accuracy: 0.9244\n",
            "Epoch 24/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0232 - accuracy: 0.9889 - val_loss: 0.2010 - val_accuracy: 0.9156\n",
            "Epoch 25/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.0276 - accuracy: 0.9874 - val_loss: 0.1791 - val_accuracy: 0.9222\n",
            "Epoch 26/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0147 - accuracy: 0.9933 - val_loss: 0.2003 - val_accuracy: 0.9089\n",
            "Epoch 27/53\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 0.0115 - accuracy: 0.9948 - val_loss: 0.2090 - val_accuracy: 0.9289\n",
            "Epoch 28/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.2642 - val_accuracy: 0.8978\n",
            "Epoch 29/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0145 - accuracy: 0.9948 - val_loss: 0.2300 - val_accuracy: 0.9200\n",
            "Epoch 30/53\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.0426 - accuracy: 0.9793 - val_loss: 0.1993 - val_accuracy: 0.9156\n",
            "Epoch 31/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0356 - accuracy: 0.9859 - val_loss: 0.1889 - val_accuracy: 0.9333\n",
            "Epoch 32/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.0175 - accuracy: 0.9933 - val_loss: 0.1889 - val_accuracy: 0.9200\n",
            "Epoch 33/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.2152 - val_accuracy: 0.9244\n",
            "Epoch 34/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0051 - accuracy: 0.9978 - val_loss: 0.2506 - val_accuracy: 0.9178\n",
            "Epoch 35/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.2261 - val_accuracy: 0.9222\n",
            "Epoch 36/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.0098 - accuracy: 0.9948 - val_loss: 0.2525 - val_accuracy: 0.9156\n",
            "Epoch 37/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.0082 - accuracy: 0.9948 - val_loss: 0.2738 - val_accuracy: 0.9067\n",
            "Epoch 38/53\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9356\n",
            "Epoch 39/53\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.2526 - val_accuracy: 0.9222\n",
            "Epoch 40/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9289\n",
            "Epoch 41/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0333 - accuracy: 0.9844 - val_loss: 0.2674 - val_accuracy: 0.9156\n",
            "Epoch 42/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0249 - accuracy: 0.9919 - val_loss: 0.2266 - val_accuracy: 0.9222\n",
            "Epoch 43/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0146 - accuracy: 0.9911 - val_loss: 0.2479 - val_accuracy: 0.9156\n",
            "Epoch 44/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.0073 - accuracy: 0.9956 - val_loss: 0.2474 - val_accuracy: 0.9200\n",
            "Epoch 45/53\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9222\n",
            "Epoch 46/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.0035 - accuracy: 0.9985 - val_loss: 0.2631 - val_accuracy: 0.9244\n",
            "Epoch 47/53\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9289\n",
            "Epoch 48/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9267\n",
            "Epoch 49/53\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9267\n",
            "Epoch 50/53\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 5.6612e-04 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 0.9222\n",
            "Epoch 51/53\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 7.1881e-04 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9289\n",
            "Epoch 52/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 4.7091e-04 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9311\n",
            "Epoch 53/53\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 4.5733e-04 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 10:05:43,459]\u001b[0m Trial 5 finished with value: 0.9266666769981384 and parameters: {'epochs': 53, 'batch_size': 28, 'lr': 9.117299246455307e-05}. Best is trial 3 with value: 0.9222221970558167.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/53\n",
            "47/47 [==============================] - 7s 141ms/step - loss: 0.5432 - accuracy: 0.5481 - val_loss: 0.3832 - val_accuracy: 0.6711\n",
            "Epoch 2/53\n",
            "47/47 [==============================] - 6s 130ms/step - loss: 0.3695 - accuracy: 0.7378 - val_loss: 0.2895 - val_accuracy: 0.8289\n",
            "Epoch 3/53\n",
            "47/47 [==============================] - 6s 130ms/step - loss: 0.2994 - accuracy: 0.8319 - val_loss: 0.2364 - val_accuracy: 0.8578\n",
            "Epoch 4/53\n",
            "47/47 [==============================] - 6s 131ms/step - loss: 0.2551 - accuracy: 0.8496 - val_loss: 0.2219 - val_accuracy: 0.8622\n",
            "Epoch 5/53\n",
            "47/47 [==============================] - 6s 131ms/step - loss: 0.2227 - accuracy: 0.8630 - val_loss: 0.2035 - val_accuracy: 0.8644\n",
            "Epoch 6/53\n",
            "47/47 [==============================] - 6s 130ms/step - loss: 0.1826 - accuracy: 0.8911 - val_loss: 0.1811 - val_accuracy: 0.8911\n",
            "Epoch 7/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.1729 - accuracy: 0.9000 - val_loss: 0.2128 - val_accuracy: 0.8578\n",
            "Epoch 8/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.1733 - accuracy: 0.8970 - val_loss: 0.2057 - val_accuracy: 0.8733\n",
            "Epoch 9/53\n",
            "47/47 [==============================] - 6s 130ms/step - loss: 0.1322 - accuracy: 0.9193 - val_loss: 0.1735 - val_accuracy: 0.8933\n",
            "Epoch 10/53\n",
            "47/47 [==============================] - 6s 131ms/step - loss: 0.1048 - accuracy: 0.9437 - val_loss: 0.1730 - val_accuracy: 0.9000\n",
            "Epoch 11/53\n",
            "47/47 [==============================] - 6s 131ms/step - loss: 0.0857 - accuracy: 0.9504 - val_loss: 0.1662 - val_accuracy: 0.9022\n",
            "Epoch 12/53\n",
            "47/47 [==============================] - 6s 130ms/step - loss: 0.0815 - accuracy: 0.9519 - val_loss: 0.1537 - val_accuracy: 0.9178\n",
            "Epoch 13/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0646 - accuracy: 0.9644 - val_loss: 0.1711 - val_accuracy: 0.9067\n",
            "Epoch 14/53\n",
            "47/47 [==============================] - 6s 130ms/step - loss: 0.0690 - accuracy: 0.9585 - val_loss: 0.1924 - val_accuracy: 0.8911\n",
            "Epoch 15/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0681 - accuracy: 0.9652 - val_loss: 0.1744 - val_accuracy: 0.9133\n",
            "Epoch 16/53\n",
            "47/47 [==============================] - 6s 130ms/step - loss: 0.0416 - accuracy: 0.9778 - val_loss: 0.2045 - val_accuracy: 0.9089\n",
            "Epoch 17/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0372 - accuracy: 0.9830 - val_loss: 0.1836 - val_accuracy: 0.9111\n",
            "Epoch 18/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0401 - accuracy: 0.9793 - val_loss: 0.2012 - val_accuracy: 0.9044\n",
            "Epoch 19/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0272 - accuracy: 0.9867 - val_loss: 0.1920 - val_accuracy: 0.9311\n",
            "Epoch 20/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0275 - accuracy: 0.9867 - val_loss: 0.1918 - val_accuracy: 0.9244\n",
            "Epoch 21/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.2154 - val_accuracy: 0.9178\n",
            "Epoch 22/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.2223 - val_accuracy: 0.9222\n",
            "Epoch 23/53\n",
            "47/47 [==============================] - 6s 130ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.2267 - val_accuracy: 0.9289\n",
            "Epoch 24/53\n",
            "47/47 [==============================] - 6s 130ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.2770 - val_accuracy: 0.9267\n",
            "Epoch 25/53\n",
            "47/47 [==============================] - 6s 131ms/step - loss: 0.0210 - accuracy: 0.9889 - val_loss: 0.2972 - val_accuracy: 0.8933\n",
            "Epoch 26/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0176 - accuracy: 0.9919 - val_loss: 0.2194 - val_accuracy: 0.9222\n",
            "Epoch 27/53\n",
            "47/47 [==============================] - 6s 130ms/step - loss: 0.0228 - accuracy: 0.9881 - val_loss: 0.3031 - val_accuracy: 0.8911\n",
            "Epoch 28/53\n",
            "47/47 [==============================] - 6s 130ms/step - loss: 0.0438 - accuracy: 0.9778 - val_loss: 0.2274 - val_accuracy: 0.9200\n",
            "Epoch 29/53\n",
            "47/47 [==============================] - 6s 130ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.2081 - val_accuracy: 0.9289\n",
            "Epoch 30/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9356\n",
            "Epoch 31/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0035 - accuracy: 0.9985 - val_loss: 0.2623 - val_accuracy: 0.9244\n",
            "Epoch 32/53\n",
            "47/47 [==============================] - 6s 130ms/step - loss: 0.0161 - accuracy: 0.9941 - val_loss: 0.2742 - val_accuracy: 0.9022\n",
            "Epoch 33/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0126 - accuracy: 0.9948 - val_loss: 0.2205 - val_accuracy: 0.9356\n",
            "Epoch 34/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.2654 - val_accuracy: 0.9244\n",
            "Epoch 35/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.2516 - val_accuracy: 0.9200\n",
            "Epoch 36/53\n",
            "47/47 [==============================] - 6s 131ms/step - loss: 0.0028 - accuracy: 0.9985 - val_loss: 0.2857 - val_accuracy: 0.9178\n",
            "Epoch 37/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 0.2330 - val_accuracy: 0.9333\n",
            "Epoch 38/53\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0060 - accuracy: 0.9970 - val_loss: 0.3438 - val_accuracy: 0.9111\n",
            "Epoch 39/53\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.0144 - accuracy: 0.9941 - val_loss: 0.2366 - val_accuracy: 0.9356\n",
            "Epoch 40/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0050 - accuracy: 0.9978 - val_loss: 0.2694 - val_accuracy: 0.9200\n",
            "Epoch 41/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0067 - accuracy: 0.9948 - val_loss: 0.2890 - val_accuracy: 0.9178\n",
            "Epoch 42/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9333\n",
            "Epoch 43/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 8.6713e-04 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9333\n",
            "Epoch 44/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 2.9727e-04 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.9356\n",
            "Epoch 45/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 6.3175e-04 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.9244\n",
            "Epoch 46/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.2757 - val_accuracy: 0.9311\n",
            "Epoch 47/53\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 4.5301e-04 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.9333\n",
            "Epoch 48/53\n",
            "47/47 [==============================] - 6s 129ms/step - loss: 1.8392e-04 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9311\n",
            "Epoch 49/53\n",
            "35/47 [=====================>........] - ETA: 1s - loss: 1.6871e-04 - accuracy: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-982683e04938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#study.optimize(objective, n_trials=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCmaEsSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#study.optimize(objective, n_trials=25, timeout=600)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-7fd0d0f164b5>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     20\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                         verbose=1)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         \u001b[0mtensor_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0mvariables_used\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m       \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1933\u001b[0m         \u001b[0mtensor_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGMTrgT2K4Dh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "522c0cfd-47b4-4f1f-eb44-2a5d82f62ba0"
      },
      "source": [
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"35123f9f-ac25-4e29-8ce4-8f617a6645f4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"35123f9f-ac25-4e29-8ce4-8f617a6645f4\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '35123f9f-ac25-4e29-8ce4-8f617a6645f4',\n",
              "                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], \"y\": [0.9177777767181396, 0.9200000166893005, 0.9266666769981384, 0.9222221970558167, 0.9200000166893005, 0.9288889169692993, 0.9444444179534912, 0.9311110973358154, 0.9200000166893005, 0.9155555367469788, 0.9133333563804626, 0.9311110973358154, 0.9111111164093018, 0.9377777576446533, 0.897777795791626]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], \"y\": [0.9177777767181396, 0.9177777767181396, 0.9177777767181396, 0.9177777767181396, 0.9177777767181396, 0.9177777767181396, 0.9177777767181396, 0.9177777767181396, 0.9177777767181396, 0.9155555367469788, 0.9133333563804626, 0.9133333563804626, 0.9111111164093018, 0.9111111164093018, 0.897777795791626]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('35123f9f-ac25-4e29-8ce4-8f617a6645f4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8MbvOzgK4cC"
      },
      "source": [
        "optuna.visualization.plot_intermediate_values(study)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9a7_v9hPJ0b"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "### TPE+CMAES\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mV9dCOJPJbY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0594d0f-61a5-436c-a732-612f6f67f401"
      },
      "source": [
        "base_model1 = Xception(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "features1 = base_model1.output\n",
        "    ######################################################################################################\n",
        "\n",
        "base_model2 = ResNet101(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "features2 = base_model2.output\n",
        "    ######################################################################################################\n",
        "\n",
        "    #base_model3 = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    #features3 = base_model3.output\n",
        "conv=tf.keras.layers.concatenate([features1,features2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 4s 0us/step\n",
            "83697664/83683744 [==============================] - 4s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "171450368/171446536 [==============================] - 7s 0us/step\n",
            "171458560/171446536 [==============================] - 7s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYonQYPgfskk",
        "outputId": "302b069f-9755-4130-d544-233aa8075658"
      },
      "source": [
        "from keras.backend import clear_session\n",
        "clear_session()\n",
        "\n",
        "def objective(trial):\n",
        "    if tf.__version__ >= \"2\":\n",
        "        monitor = \"val_accuracy\"\n",
        "    else:\n",
        "        monitor = \"val_acc\"\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    epochs = trial.suggest_int('epochs', 40, 70)\n",
        "    batch_size = trial.suggest_int('batch_size', 24, 32)\n",
        "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n",
        "    dropout = trial.suggest_float(\"dropout_l{}\".format(i), 0.5, 0.75)\n",
        "    #optimiser = trial.suggest_categorical('optimizer', ['SGD','RMSprop','Adam','Adadelta','Adagrad','Adamax','Nadam','Ftrl'])\n",
        "    loss = trial.suggest_categorical('Loss', ['categorical_crossentropy','poisson','kullback_leibler_divergence']) \n",
        "\n",
        "    conv = Sequential()\n",
        "    #onv.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3))(concatenated))\n",
        "    conv.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "    conv.add(MaxPooling2D((2, 2), padding='same'))\n",
        "    conv.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "    conv.add(MaxPooling2D((2, 2), padding='same'))\n",
        "    conv.add(Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "    conv.add(MaxPooling2D((2, 2), padding='same'))\n",
        "    conv.add(Conv2D(256, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "    conv.add(MaxPooling2D((2, 2), padding='same'))\n",
        "    conv.add(Conv2D(512, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "    conv.add(MaxPooling2D((2, 2), padding='same'))\n",
        "    conv.add(Flatten())\n",
        "    conv.add(Dropout(rate=dropout))\n",
        "    conv.add(Dense(512, activation='relu'))\n",
        "    conv.add(Dropout(rate=dropout))\n",
        "    conv.add(Dense(64, activation='relu'))\n",
        "    conv.add(Dense(3, activation='sigmoid'))\n",
        "    \n",
        "    #optimizer = Adam(lr=1e-3)\n",
        "    conv.compile(optimizer= tensorflow.keras.optimizers.Adam(learning_rate=lr), loss = loss, metrics=['accuracy'])\n",
        "    #model.fit(cancer_files_train,train_labels,batch_size=None,epochs=10)\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(patience=5),\n",
        "        TFKerasPruningCallback(trial, monitor),\n",
        "    ]\n",
        "    history = conv.fit(X_train, \n",
        "                        y_train, \n",
        "                        batch_size=batch_size,\n",
        "                        validation_data=(X_test, y_test),\n",
        "                        epochs=epochs,\n",
        "                        callbacks=callbacks,\n",
        "                        verbose=1)\n",
        "    \n",
        "    score = conv.evaluate(X_test, y_test, verbose=0)\n",
        "    return history.history[monitor][-1]\n",
        "\n",
        "study1 = optuna.create_study(sampler = optuna.samplers.TPESampler(), direction='maximize')\n",
        "study1.optimize(objective, n_trials=5)\n",
        "\n",
        "pruned_trials = study1.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study1.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study1.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study1.best_trial\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-20 04:21:21,854]\u001b[0m A new study created in memory with name: no-name-51a0616f-9a44-4bbc-9bc2-74f31194016b\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/62\n",
            " 6/41 [===>..........................] - ETA: 3s - loss: 0.6015 - accuracy: 0.2917WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0440s vs `on_train_batch_end` time: 0.0569s). Check your callbacks.\n",
            "41/41 [==============================] - 37s 160ms/step - loss: 0.1557 - accuracy: 0.3333 - val_loss: 1.5873e-05 - val_accuracy: 0.3360\n",
            "Epoch 2/62\n",
            "41/41 [==============================] - 5s 123ms/step - loss: 2.0819e-05 - accuracy: 0.3538 - val_loss: 1.1752e-06 - val_accuracy: 0.3520\n",
            "Epoch 3/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: 1.0862e-05 - accuracy: 0.3573 - val_loss: 7.0410e-07 - val_accuracy: 0.3627\n",
            "Epoch 4/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: 1.2498e-05 - accuracy: 0.3556 - val_loss: 3.3156e-07 - val_accuracy: 0.3653\n",
            "Epoch 5/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: 2.1743e-05 - accuracy: 0.3369 - val_loss: -2.2917e-07 - val_accuracy: 0.3653\n",
            "Epoch 6/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: 2.3673e-05 - accuracy: 0.3520 - val_loss: -6.3796e-07 - val_accuracy: 0.3573\n",
            "Epoch 7/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: 9.7729e-06 - accuracy: 0.3316 - val_loss: -9.9525e-07 - val_accuracy: 0.3520\n",
            "Epoch 8/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: 5.2490e-06 - accuracy: 0.3547 - val_loss: -1.2623e-06 - val_accuracy: 0.3467\n",
            "Epoch 9/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: 6.7801e-06 - accuracy: 0.3440 - val_loss: -1.4845e-06 - val_accuracy: 0.3307\n",
            "Epoch 10/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: 5.4982e-06 - accuracy: 0.3378 - val_loss: -1.6717e-06 - val_accuracy: 0.3413\n",
            "Epoch 11/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: 4.7502e-06 - accuracy: 0.3369 - val_loss: -1.8596e-06 - val_accuracy: 0.3413\n",
            "Epoch 12/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: 2.9518e-06 - accuracy: 0.3378 - val_loss: -2.0122e-06 - val_accuracy: 0.3333\n",
            "Epoch 13/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: 9.4592e-06 - accuracy: 0.3307 - val_loss: -2.2150e-06 - val_accuracy: 0.3307\n",
            "Epoch 14/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: 4.4139e-06 - accuracy: 0.3191 - val_loss: -2.3672e-06 - val_accuracy: 0.3280\n",
            "Epoch 15/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: 2.4317e-06 - accuracy: 0.3102 - val_loss: -2.4744e-06 - val_accuracy: 0.3093\n",
            "Epoch 16/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: 9.4816e-07 - accuracy: 0.3298 - val_loss: -2.5472e-06 - val_accuracy: 0.3013\n",
            "Epoch 17/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: 1.6919e-06 - accuracy: 0.3316 - val_loss: -2.6301e-06 - val_accuracy: 0.2960\n",
            "Epoch 18/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: 5.0769e-07 - accuracy: 0.3271 - val_loss: -2.7036e-06 - val_accuracy: 0.2853\n",
            "Epoch 19/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -3.8171e-07 - accuracy: 0.3369 - val_loss: -2.7611e-06 - val_accuracy: 0.2827\n",
            "Epoch 20/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: 1.8051e-07 - accuracy: 0.3440 - val_loss: -2.8135e-06 - val_accuracy: 0.2773\n",
            "Epoch 21/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: 3.8536e-06 - accuracy: 0.3404 - val_loss: -2.8549e-06 - val_accuracy: 0.2747\n",
            "Epoch 22/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: 6.6678e-07 - accuracy: 0.3236 - val_loss: -2.9232e-06 - val_accuracy: 0.2640\n",
            "Epoch 23/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -1.2087e-06 - accuracy: 0.3307 - val_loss: -2.9502e-06 - val_accuracy: 0.2613\n",
            "Epoch 24/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: 3.8799e-07 - accuracy: 0.3200 - val_loss: -2.9900e-06 - val_accuracy: 0.2640\n",
            "Epoch 25/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: -1.3125e-06 - accuracy: 0.3227 - val_loss: -3.0148e-06 - val_accuracy: 0.2720\n",
            "Epoch 26/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: 3.4732e-07 - accuracy: 0.3182 - val_loss: -3.0437e-06 - val_accuracy: 0.2800\n",
            "Epoch 27/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.0086e-06 - accuracy: 0.3164 - val_loss: -3.0574e-06 - val_accuracy: 0.2800\n",
            "Epoch 28/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: -2.3340e-06 - accuracy: 0.3129 - val_loss: -3.0666e-06 - val_accuracy: 0.2827\n",
            "Epoch 29/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -1.6675e-06 - accuracy: 0.3049 - val_loss: -3.0831e-06 - val_accuracy: 0.2827\n",
            "Epoch 30/62\n",
            "41/41 [==============================] - 5s 120ms/step - loss: -2.0356e-06 - accuracy: 0.3280 - val_loss: -3.0971e-06 - val_accuracy: 0.2907\n",
            "Epoch 31/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.1341e-06 - accuracy: 0.3422 - val_loss: -3.1076e-06 - val_accuracy: 0.2880\n",
            "Epoch 32/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.3790e-06 - accuracy: 0.3173 - val_loss: -3.1155e-06 - val_accuracy: 0.2880\n",
            "Epoch 33/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.7335e-06 - accuracy: 0.3049 - val_loss: -3.1216e-06 - val_accuracy: 0.2907\n",
            "Epoch 34/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -1.9422e-06 - accuracy: 0.3191 - val_loss: -3.1321e-06 - val_accuracy: 0.2907\n",
            "Epoch 35/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.4118e-06 - accuracy: 0.3182 - val_loss: -3.1391e-06 - val_accuracy: 0.2907\n",
            "Epoch 36/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.1378e-06 - accuracy: 0.3262 - val_loss: -3.1454e-06 - val_accuracy: 0.2933\n",
            "Epoch 37/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.0430e-06 - accuracy: 0.2996 - val_loss: -3.1534e-06 - val_accuracy: 0.2987\n",
            "Epoch 38/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: -2.4286e-06 - accuracy: 0.3102 - val_loss: -3.1591e-06 - val_accuracy: 0.2907\n",
            "Epoch 39/62\n",
            "41/41 [==============================] - 5s 120ms/step - loss: -2.6291e-06 - accuracy: 0.3022 - val_loss: -3.1654e-06 - val_accuracy: 0.2987\n",
            "Epoch 40/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: -2.1790e-06 - accuracy: 0.3164 - val_loss: -3.1718e-06 - val_accuracy: 0.3040\n",
            "Epoch 41/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.6659e-06 - accuracy: 0.3200 - val_loss: -3.1753e-06 - val_accuracy: 0.3040\n",
            "Epoch 42/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -1.7484e-06 - accuracy: 0.3120 - val_loss: -3.1801e-06 - val_accuracy: 0.3120\n",
            "Epoch 43/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.7293e-06 - accuracy: 0.3209 - val_loss: -3.1852e-06 - val_accuracy: 0.3147\n",
            "Epoch 44/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.8499e-06 - accuracy: 0.3164 - val_loss: -3.1871e-06 - val_accuracy: 0.3120\n",
            "Epoch 45/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.9262e-06 - accuracy: 0.3218 - val_loss: -3.1896e-06 - val_accuracy: 0.3173\n",
            "Epoch 46/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.2952e-06 - accuracy: 0.3244 - val_loss: -3.1925e-06 - val_accuracy: 0.3173\n",
            "Epoch 47/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.5507e-06 - accuracy: 0.3129 - val_loss: -3.1956e-06 - val_accuracy: 0.3280\n",
            "Epoch 48/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -3.0264e-06 - accuracy: 0.3129 - val_loss: -3.1991e-06 - val_accuracy: 0.3253\n",
            "Epoch 49/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.6795e-06 - accuracy: 0.3209 - val_loss: -3.2023e-06 - val_accuracy: 0.3307\n",
            "Epoch 50/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.6840e-06 - accuracy: 0.3200 - val_loss: -3.2039e-06 - val_accuracy: 0.3253\n",
            "Epoch 51/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.9212e-06 - accuracy: 0.3271 - val_loss: -3.2049e-06 - val_accuracy: 0.3280\n",
            "Epoch 52/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.7862e-06 - accuracy: 0.3209 - val_loss: -3.2065e-06 - val_accuracy: 0.3333\n",
            "Epoch 53/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -3.0898e-06 - accuracy: 0.3173 - val_loss: -3.2068e-06 - val_accuracy: 0.3333\n",
            "Epoch 54/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.8705e-06 - accuracy: 0.3253 - val_loss: -3.2080e-06 - val_accuracy: 0.3333\n",
            "Epoch 55/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.9323e-06 - accuracy: 0.3200 - val_loss: -3.2090e-06 - val_accuracy: 0.3333\n",
            "Epoch 56/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: -3.0830e-06 - accuracy: 0.3200 - val_loss: -3.2096e-06 - val_accuracy: 0.3333\n",
            "Epoch 57/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.9278e-06 - accuracy: 0.3218 - val_loss: -3.2109e-06 - val_accuracy: 0.3333\n",
            "Epoch 58/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -3.0139e-06 - accuracy: 0.3227 - val_loss: -3.2122e-06 - val_accuracy: 0.3333\n",
            "Epoch 59/62\n",
            "41/41 [==============================] - 5s 122ms/step - loss: -3.1200e-06 - accuracy: 0.3244 - val_loss: -3.2122e-06 - val_accuracy: 0.3333\n",
            "Epoch 60/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -3.0750e-06 - accuracy: 0.3209 - val_loss: -3.2125e-06 - val_accuracy: 0.3333\n",
            "Epoch 61/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.8410e-06 - accuracy: 0.3271 - val_loss: -3.2138e-06 - val_accuracy: 0.3333\n",
            "Epoch 62/62\n",
            "41/41 [==============================] - 5s 121ms/step - loss: -2.9306e-06 - accuracy: 0.3120 - val_loss: -3.2138e-06 - val_accuracy: 0.3333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-20 04:27:05,730]\u001b[0m Trial 0 finished with value: 0.3333333432674408 and parameters: {'epochs': 62, 'batch_size': 28, 'lr': 3.7237162686191114e-05, 'dropout_l500': 0.5913710402544755, 'optimizer': 'Adam', 'Loss': 'kullback_leibler_divergence'}. Best is trial 0 with value: 0.3333333432674408.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/42\n",
            " 6/36 [====>.........................] - ETA: 3s - loss: 0.7228 - accuracy: 0.3646WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0448s vs `on_train_batch_end` time: 0.0623s). Check your callbacks.\n",
            "36/36 [==============================] - 7s 144ms/step - loss: 0.7093 - accuracy: 0.3458 - val_loss: 0.6968 - val_accuracy: 0.3333\n",
            "Epoch 2/42\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.6978 - accuracy: 0.3653 - val_loss: 0.6874 - val_accuracy: 0.3893\n",
            "Epoch 3/42\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.6847 - accuracy: 0.4996 - val_loss: 0.6661 - val_accuracy: 0.5973\n",
            "Epoch 4/42\n",
            "36/36 [==============================] - 5s 131ms/step - loss: 0.6625 - accuracy: 0.5662 - val_loss: 0.6242 - val_accuracy: 0.5973\n",
            "Epoch 5/42\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.6241 - accuracy: 0.5973 - val_loss: 0.5827 - val_accuracy: 0.6240\n",
            "Epoch 6/42\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.6020 - accuracy: 0.6160 - val_loss: 0.5757 - val_accuracy: 0.6187\n",
            "Epoch 7/42\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.5757 - accuracy: 0.6649 - val_loss: 0.5593 - val_accuracy: 0.6640\n",
            "Epoch 8/42\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.5613 - accuracy: 0.6827 - val_loss: 0.5500 - val_accuracy: 0.6853\n",
            "Epoch 9/42\n",
            "36/36 [==============================] - 5s 132ms/step - loss: 0.5591 - accuracy: 0.6747 - val_loss: 0.5457 - val_accuracy: 0.6693\n",
            "Epoch 10/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.5537 - accuracy: 0.6836 - val_loss: 0.5370 - val_accuracy: 0.7333\n",
            "Epoch 11/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.5402 - accuracy: 0.7227 - val_loss: 0.5314 - val_accuracy: 0.7120\n",
            "Epoch 12/42\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.5365 - accuracy: 0.7262 - val_loss: 0.5363 - val_accuracy: 0.6827\n",
            "Epoch 13/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.5324 - accuracy: 0.7298 - val_loss: 0.5251 - val_accuracy: 0.7173\n",
            "Epoch 14/42\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.5224 - accuracy: 0.7333 - val_loss: 0.5165 - val_accuracy: 0.7413\n",
            "Epoch 15/42\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.5250 - accuracy: 0.7467 - val_loss: 0.5125 - val_accuracy: 0.7600\n",
            "Epoch 16/42\n",
            "36/36 [==============================] - 5s 139ms/step - loss: 0.5134 - accuracy: 0.7636 - val_loss: 0.5101 - val_accuracy: 0.7547\n",
            "Epoch 17/42\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.5065 - accuracy: 0.7849 - val_loss: 0.5005 - val_accuracy: 0.8000\n",
            "Epoch 18/42\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.5050 - accuracy: 0.7760 - val_loss: 0.4964 - val_accuracy: 0.7867\n",
            "Epoch 19/42\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.4968 - accuracy: 0.8000 - val_loss: 0.4911 - val_accuracy: 0.8027\n",
            "Epoch 20/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.4921 - accuracy: 0.7973 - val_loss: 0.4964 - val_accuracy: 0.7707\n",
            "Epoch 21/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.4871 - accuracy: 0.8151 - val_loss: 0.4803 - val_accuracy: 0.8293\n",
            "Epoch 22/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.4832 - accuracy: 0.8187 - val_loss: 0.4872 - val_accuracy: 0.8240\n",
            "Epoch 23/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.4813 - accuracy: 0.8151 - val_loss: 0.4791 - val_accuracy: 0.8427\n",
            "Epoch 24/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.4726 - accuracy: 0.8409 - val_loss: 0.4767 - val_accuracy: 0.8373\n",
            "Epoch 25/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.4704 - accuracy: 0.8436 - val_loss: 0.4745 - val_accuracy: 0.8427\n",
            "Epoch 26/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.4713 - accuracy: 0.8356 - val_loss: 0.4705 - val_accuracy: 0.8427\n",
            "Epoch 27/42\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.4692 - accuracy: 0.8436 - val_loss: 0.4673 - val_accuracy: 0.8533\n",
            "Epoch 28/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.4606 - accuracy: 0.8596 - val_loss: 0.4724 - val_accuracy: 0.8427\n",
            "Epoch 29/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.4633 - accuracy: 0.8569 - val_loss: 0.4631 - val_accuracy: 0.8427\n",
            "Epoch 30/42\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.4574 - accuracy: 0.8489 - val_loss: 0.4685 - val_accuracy: 0.8427\n",
            "Epoch 31/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.4505 - accuracy: 0.8622 - val_loss: 0.4602 - val_accuracy: 0.8533\n",
            "Epoch 32/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.4513 - accuracy: 0.8462 - val_loss: 0.4583 - val_accuracy: 0.8533\n",
            "Epoch 33/42\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.4587 - accuracy: 0.8551 - val_loss: 0.4583 - val_accuracy: 0.8453\n",
            "Epoch 34/42\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.4471 - accuracy: 0.8578 - val_loss: 0.4668 - val_accuracy: 0.8533\n",
            "Epoch 35/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.4495 - accuracy: 0.8462 - val_loss: 0.4544 - val_accuracy: 0.8613\n",
            "Epoch 36/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.4466 - accuracy: 0.8560 - val_loss: 0.4514 - val_accuracy: 0.8453\n",
            "Epoch 37/42\n",
            "36/36 [==============================] - 5s 135ms/step - loss: 0.4446 - accuracy: 0.8667 - val_loss: 0.4626 - val_accuracy: 0.8507\n",
            "Epoch 38/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.4361 - accuracy: 0.8773 - val_loss: 0.4658 - val_accuracy: 0.8453\n",
            "Epoch 39/42\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.4355 - accuracy: 0.8764 - val_loss: 0.4530 - val_accuracy: 0.8693\n",
            "Epoch 40/42\n",
            "36/36 [==============================] - 5s 133ms/step - loss: 0.4394 - accuracy: 0.8649 - val_loss: 0.4588 - val_accuracy: 0.8587\n",
            "Epoch 41/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.4376 - accuracy: 0.8747 - val_loss: 0.4505 - val_accuracy: 0.8640\n",
            "Epoch 42/42\n",
            "36/36 [==============================] - 5s 134ms/step - loss: 0.4353 - accuracy: 0.8711 - val_loss: 0.4469 - val_accuracy: 0.8613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-20 04:31:30,446]\u001b[0m Trial 1 finished with value: 0.8613333106040955 and parameters: {'epochs': 42, 'batch_size': 32, 'lr': 2.5374831753872206e-05, 'dropout_l500': 0.6745798126681045, 'optimizer': 'Adadelta', 'Loss': 'poisson'}. Best is trial 1 with value: 0.8613333106040955.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            " 6/44 [===>..........................] - ETA: 4s - loss: 1.1199 - accuracy: 0.3526WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0433s vs `on_train_batch_end` time: 0.0546s). Check your callbacks.\n",
            "44/44 [==============================] - 8s 141ms/step - loss: 1.0786 - accuracy: 0.3707 - val_loss: 0.9058 - val_accuracy: 0.6667\n",
            "Epoch 2/70\n",
            "44/44 [==============================] - 5s 120ms/step - loss: 0.7654 - accuracy: 0.6320 - val_loss: 0.6422 - val_accuracy: 0.6720\n",
            "Epoch 3/70\n",
            "44/44 [==============================] - 5s 119ms/step - loss: 0.6255 - accuracy: 0.7147 - val_loss: 0.5415 - val_accuracy: 0.7733\n",
            "Epoch 4/70\n",
            "44/44 [==============================] - 5s 119ms/step - loss: 0.5449 - accuracy: 0.7876 - val_loss: 0.4868 - val_accuracy: 0.7973\n",
            "Epoch 5/70\n",
            "44/44 [==============================] - 5s 119ms/step - loss: 0.4822 - accuracy: 0.8116 - val_loss: 0.4398 - val_accuracy: 0.8213\n",
            "Epoch 6/70\n",
            "44/44 [==============================] - 5s 119ms/step - loss: 0.4268 - accuracy: 0.8267 - val_loss: 0.4148 - val_accuracy: 0.8373\n",
            "Epoch 7/70\n",
            "44/44 [==============================] - 5s 120ms/step - loss: 0.3918 - accuracy: 0.8507 - val_loss: 0.3574 - val_accuracy: 0.8507\n",
            "Epoch 8/70\n",
            "44/44 [==============================] - 5s 119ms/step - loss: 0.3629 - accuracy: 0.8640 - val_loss: 0.3382 - val_accuracy: 0.8640\n",
            "Epoch 9/70\n",
            "44/44 [==============================] - 5s 120ms/step - loss: 0.3364 - accuracy: 0.8622 - val_loss: 0.3250 - val_accuracy: 0.8720\n",
            "Epoch 10/70\n",
            "44/44 [==============================] - 5s 122ms/step - loss: 0.2792 - accuracy: 0.8907 - val_loss: 0.3094 - val_accuracy: 0.8800\n",
            "Epoch 11/70\n",
            "44/44 [==============================] - 5s 119ms/step - loss: 0.2701 - accuracy: 0.8924 - val_loss: 0.3942 - val_accuracy: 0.8507\n",
            "Epoch 12/70\n",
            "44/44 [==============================] - 5s 119ms/step - loss: 0.2484 - accuracy: 0.9084 - val_loss: 0.3291 - val_accuracy: 0.8693\n",
            "Epoch 13/70\n",
            "44/44 [==============================] - 5s 119ms/step - loss: 0.2296 - accuracy: 0.9084 - val_loss: 0.3174 - val_accuracy: 0.8827\n",
            "Epoch 14/70\n",
            "44/44 [==============================] - 5s 119ms/step - loss: 0.2071 - accuracy: 0.9209 - val_loss: 0.3125 - val_accuracy: 0.8960\n",
            "Epoch 15/70\n",
            "44/44 [==============================] - 5s 119ms/step - loss: 0.2017 - accuracy: 0.9191 - val_loss: 0.2905 - val_accuracy: 0.8800\n",
            "Epoch 16/70\n",
            "44/44 [==============================] - 5s 120ms/step - loss: 0.1944 - accuracy: 0.9227 - val_loss: 0.2948 - val_accuracy: 0.8933\n",
            "Epoch 17/70\n",
            "44/44 [==============================] - 5s 118ms/step - loss: 0.1625 - accuracy: 0.9298 - val_loss: 0.3320 - val_accuracy: 0.8747\n",
            "Epoch 18/70\n",
            "44/44 [==============================] - 5s 120ms/step - loss: 0.1483 - accuracy: 0.9396 - val_loss: 0.3309 - val_accuracy: 0.8907\n",
            "Epoch 19/70\n",
            "44/44 [==============================] - 5s 119ms/step - loss: 0.1479 - accuracy: 0.9431 - val_loss: 0.2519 - val_accuracy: 0.9013\n",
            "Epoch 20/70\n",
            "44/44 [==============================] - 5s 119ms/step - loss: 0.1130 - accuracy: 0.9600 - val_loss: 0.2864 - val_accuracy: 0.9013\n",
            "Epoch 21/70\n",
            "44/44 [==============================] - 5s 120ms/step - loss: 0.1079 - accuracy: 0.9582 - val_loss: 0.2852 - val_accuracy: 0.9040\n",
            "Epoch 22/70\n",
            "44/44 [==============================] - 5s 118ms/step - loss: 0.1148 - accuracy: 0.9591 - val_loss: 0.2479 - val_accuracy: 0.9067\n",
            "Epoch 23/70\n",
            "44/44 [==============================] - 5s 119ms/step - loss: 0.1045 - accuracy: 0.9609 - val_loss: 0.2812 - val_accuracy: 0.9093\n",
            "Epoch 24/70\n",
            "44/44 [==============================] - 5s 119ms/step - loss: 0.0723 - accuracy: 0.9733 - val_loss: 0.2944 - val_accuracy: 0.9040\n",
            "Epoch 25/70\n",
            "44/44 [==============================] - 5s 119ms/step - loss: 0.0897 - accuracy: 0.9680 - val_loss: 0.2881 - val_accuracy: 0.9040\n",
            "Epoch 26/70\n",
            "44/44 [==============================] - 5s 120ms/step - loss: 0.0636 - accuracy: 0.9787 - val_loss: 0.2894 - val_accuracy: 0.9147\n",
            "Epoch 27/70\n",
            "44/44 [==============================] - 5s 119ms/step - loss: 0.0680 - accuracy: 0.9742 - val_loss: 0.2852 - val_accuracy: 0.9200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-20 04:33:56,932]\u001b[0m Trial 2 finished with value: 0.9200000166893005 and parameters: {'epochs': 70, 'batch_size': 26, 'lr': 0.0002194159278335913, 'dropout_l500': 0.6886279251938925, 'optimizer': 'RMSprop', 'Loss': 'categorical_crossentropy'}. Best is trial 2 with value: 0.9200000166893005.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/69\n",
            " 6/45 [===>..........................] - ETA: 4s - loss: 0.6319 - accuracy: 0.2800WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0157s vs `on_train_batch_end` time: 0.0748s). Check your callbacks.\n",
            "45/45 [==============================] - 8s 125ms/step - loss: 0.1586 - accuracy: 0.3271 - val_loss: 2.4711e-06 - val_accuracy: 0.3653\n",
            "Epoch 2/69\n",
            "45/45 [==============================] - 5s 120ms/step - loss: 6.6033e-05 - accuracy: 0.3191 - val_loss: -1.8039e-06 - val_accuracy: 0.3307\n",
            "Epoch 3/69\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 1.5647e-05 - accuracy: 0.3351 - val_loss: -2.0144e-06 - val_accuracy: 0.3120\n",
            "Epoch 4/69\n",
            "45/45 [==============================] - 5s 121ms/step - loss: 3.2600e-05 - accuracy: 0.3422 - val_loss: -2.2668e-06 - val_accuracy: 0.2987\n",
            "Epoch 5/69\n",
            "45/45 [==============================] - 5s 121ms/step - loss: 3.5013e-05 - accuracy: 0.3271 - val_loss: -2.4845e-06 - val_accuracy: 0.2853\n",
            "Epoch 6/69\n",
            "45/45 [==============================] - 5s 120ms/step - loss: 2.8182e-05 - accuracy: 0.3200 - val_loss: -2.6823e-06 - val_accuracy: 0.2800\n",
            "Epoch 7/69\n",
            "45/45 [==============================] - 5s 116ms/step - loss: 3.4853e-05 - accuracy: 0.3271 - val_loss: -2.8170e-06 - val_accuracy: 0.2613\n",
            "Epoch 8/69\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 1.1382e-05 - accuracy: 0.3244 - val_loss: -2.8968e-06 - val_accuracy: 0.2693\n",
            "Epoch 9/69\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 1.4277e-05 - accuracy: 0.3307 - val_loss: -2.9639e-06 - val_accuracy: 0.2827\n",
            "Epoch 10/69\n",
            "45/45 [==============================] - 5s 120ms/step - loss: 1.1747e-05 - accuracy: 0.3129 - val_loss: -3.0183e-06 - val_accuracy: 0.2827\n",
            "Epoch 11/69\n",
            "45/45 [==============================] - 5s 121ms/step - loss: 4.7831e-06 - accuracy: 0.3111 - val_loss: -3.0466e-06 - val_accuracy: 0.2907\n",
            "Epoch 12/69\n",
            "45/45 [==============================] - 5s 121ms/step - loss: 5.8645e-06 - accuracy: 0.3378 - val_loss: -3.0733e-06 - val_accuracy: 0.2853\n",
            "Epoch 13/69\n",
            "45/45 [==============================] - 5s 121ms/step - loss: 1.0889e-05 - accuracy: 0.3271 - val_loss: -3.1054e-06 - val_accuracy: 0.2880\n",
            "Epoch 14/69\n",
            "45/45 [==============================] - 5s 122ms/step - loss: 1.0051e-05 - accuracy: 0.3289 - val_loss: -3.1317e-06 - val_accuracy: 0.2933\n",
            "Epoch 15/69\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 2.5243e-06 - accuracy: 0.3333 - val_loss: -3.1480e-06 - val_accuracy: 0.2987\n",
            "Epoch 16/69\n",
            "45/45 [==============================] - 5s 121ms/step - loss: 1.8607e-06 - accuracy: 0.3191 - val_loss: -3.1591e-06 - val_accuracy: 0.3013\n",
            "Epoch 17/69\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 1.6990e-06 - accuracy: 0.3351 - val_loss: -3.1680e-06 - val_accuracy: 0.2987\n",
            "Epoch 18/69\n",
            "45/45 [==============================] - 5s 121ms/step - loss: 8.1909e-06 - accuracy: 0.3307 - val_loss: -3.1763e-06 - val_accuracy: 0.3120\n",
            "Epoch 19/69\n",
            "45/45 [==============================] - 5s 118ms/step - loss: 2.7305e-07 - accuracy: 0.3298 - val_loss: -3.1858e-06 - val_accuracy: 0.3147\n",
            "Epoch 20/69\n",
            "45/45 [==============================] - 5s 120ms/step - loss: 1.1732e-06 - accuracy: 0.3191 - val_loss: -3.1918e-06 - val_accuracy: 0.3147\n",
            "Epoch 21/69\n",
            "45/45 [==============================] - 5s 117ms/step - loss: -1.1068e-06 - accuracy: 0.3138 - val_loss: -3.1953e-06 - val_accuracy: 0.3173\n",
            "Epoch 22/69\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 1.3960e-06 - accuracy: 0.3262 - val_loss: -3.2001e-06 - val_accuracy: 0.3227\n",
            "Epoch 23/69\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 2.2895e-07 - accuracy: 0.3316 - val_loss: -3.2033e-06 - val_accuracy: 0.3200\n",
            "Epoch 24/69\n",
            "45/45 [==============================] - 5s 120ms/step - loss: 2.0020e-06 - accuracy: 0.3280 - val_loss: -3.2077e-06 - val_accuracy: 0.3307\n",
            "Epoch 25/69\n",
            "45/45 [==============================] - 5s 120ms/step - loss: 1.3098e-08 - accuracy: 0.3253 - val_loss: -3.2099e-06 - val_accuracy: 0.3333\n",
            "Epoch 26/69\n",
            "45/45 [==============================] - 5s 117ms/step - loss: 1.3585e-06 - accuracy: 0.3173 - val_loss: -3.2125e-06 - val_accuracy: 0.3333\n",
            "Epoch 27/69\n",
            "45/45 [==============================] - 5s 120ms/step - loss: 4.9993e-06 - accuracy: 0.3244 - val_loss: -3.2150e-06 - val_accuracy: 0.3333\n",
            "Epoch 28/69\n",
            "45/45 [==============================] - 5s 117ms/step - loss: -2.7460e-06 - accuracy: 0.3307 - val_loss: -3.2154e-06 - val_accuracy: 0.3333\n",
            "Epoch 29/69\n",
            "45/45 [==============================] - 5s 120ms/step - loss: -2.8133e-06 - accuracy: 0.3262 - val_loss: -3.2154e-06 - val_accuracy: 0.3333\n",
            "Epoch 30/69\n",
            "45/45 [==============================] - 5s 117ms/step - loss: -2.5422e-06 - accuracy: 0.3360 - val_loss: -3.2157e-06 - val_accuracy: 0.3333\n",
            "Epoch 31/69\n",
            "45/45 [==============================] - 5s 116ms/step - loss: -2.6620e-06 - accuracy: 0.3236 - val_loss: -3.2163e-06 - val_accuracy: 0.3280\n",
            "Epoch 32/69\n",
            "45/45 [==============================] - 5s 120ms/step - loss: -1.3940e-07 - accuracy: 0.3262 - val_loss: -3.2182e-06 - val_accuracy: 0.3333\n",
            "Epoch 33/69\n",
            "45/45 [==============================] - 5s 116ms/step - loss: -2.6757e-06 - accuracy: 0.3271 - val_loss: -3.2185e-06 - val_accuracy: 0.3333\n",
            "Epoch 34/69\n",
            "45/45 [==============================] - 5s 116ms/step - loss: -2.6993e-06 - accuracy: 0.3227 - val_loss: -3.2189e-06 - val_accuracy: 0.3333\n",
            "Epoch 35/69\n",
            "45/45 [==============================] - 5s 115ms/step - loss: -5.2478e-07 - accuracy: 0.3218 - val_loss: -3.2201e-06 - val_accuracy: 0.3333\n",
            "Epoch 36/69\n",
            "45/45 [==============================] - 5s 117ms/step - loss: -1.7133e-06 - accuracy: 0.3253 - val_loss: -3.2201e-06 - val_accuracy: 0.3333\n",
            "Epoch 37/69\n",
            "45/45 [==============================] - 5s 121ms/step - loss: -2.4210e-06 - accuracy: 0.3156 - val_loss: -3.2204e-06 - val_accuracy: 0.3333\n",
            "Epoch 38/69\n",
            "45/45 [==============================] - 5s 120ms/step - loss: -2.9759e-06 - accuracy: 0.3324 - val_loss: -3.2204e-06 - val_accuracy: 0.3333\n",
            "Epoch 39/69\n",
            "45/45 [==============================] - 5s 116ms/step - loss: -1.9096e-06 - accuracy: 0.3316 - val_loss: -3.2211e-06 - val_accuracy: 0.3333\n",
            "Epoch 40/69\n",
            "45/45 [==============================] - 5s 117ms/step - loss: -2.4937e-06 - accuracy: 0.3262 - val_loss: -3.2211e-06 - val_accuracy: 0.3333\n",
            "Epoch 41/69\n",
            "45/45 [==============================] - 5s 117ms/step - loss: -2.8425e-06 - accuracy: 0.3200 - val_loss: -3.2211e-06 - val_accuracy: 0.3333\n",
            "Epoch 42/69\n",
            "45/45 [==============================] - 5s 116ms/step - loss: -2.1690e-06 - accuracy: 0.3324 - val_loss: -3.2211e-06 - val_accuracy: 0.3333\n",
            "Epoch 43/69\n",
            "45/45 [==============================] - 5s 117ms/step - loss: -2.8426e-06 - accuracy: 0.3209 - val_loss: -3.2220e-06 - val_accuracy: 0.3333\n",
            "Epoch 44/69\n",
            "45/45 [==============================] - 5s 116ms/step - loss: -2.9407e-06 - accuracy: 0.3298 - val_loss: -3.2220e-06 - val_accuracy: 0.3333\n",
            "Epoch 45/69\n",
            "45/45 [==============================] - 5s 120ms/step - loss: -2.3774e-06 - accuracy: 0.3173 - val_loss: -3.2220e-06 - val_accuracy: 0.3333\n",
            "Epoch 46/69\n",
            "45/45 [==============================] - 5s 117ms/step - loss: -3.0332e-06 - accuracy: 0.3271 - val_loss: -3.2227e-06 - val_accuracy: 0.3333\n",
            "Epoch 47/69\n",
            "45/45 [==============================] - 5s 119ms/step - loss: -5.5726e-07 - accuracy: 0.3289 - val_loss: -3.2227e-06 - val_accuracy: 0.3333\n",
            "Epoch 48/69\n",
            "45/45 [==============================] - 5s 118ms/step - loss: -2.7013e-06 - accuracy: 0.3280 - val_loss: -3.2227e-06 - val_accuracy: 0.3333\n",
            "Epoch 49/69\n",
            "45/45 [==============================] - 5s 118ms/step - loss: -2.3861e-06 - accuracy: 0.3289 - val_loss: -3.2227e-06 - val_accuracy: 0.3333\n",
            "Epoch 50/69\n",
            "45/45 [==============================] - 5s 121ms/step - loss: -1.5275e-06 - accuracy: 0.3289 - val_loss: -3.2227e-06 - val_accuracy: 0.3333\n",
            "Epoch 51/69\n",
            "45/45 [==============================] - 5s 121ms/step - loss: -3.1115e-06 - accuracy: 0.3316 - val_loss: -3.2230e-06 - val_accuracy: 0.3333\n",
            "Epoch 52/69\n",
            "45/45 [==============================] - 5s 121ms/step - loss: -3.0483e-06 - accuracy: 0.3351 - val_loss: -3.2230e-06 - val_accuracy: 0.3333\n",
            "Epoch 53/69\n",
            "45/45 [==============================] - 5s 118ms/step - loss: -2.8829e-06 - accuracy: 0.3271 - val_loss: -3.2230e-06 - val_accuracy: 0.3333\n",
            "Epoch 54/69\n",
            "45/45 [==============================] - 5s 122ms/step - loss: -2.5406e-06 - accuracy: 0.3253 - val_loss: -3.2230e-06 - val_accuracy: 0.3333\n",
            "Epoch 55/69\n",
            "45/45 [==============================] - 5s 121ms/step - loss: -3.0940e-06 - accuracy: 0.3298 - val_loss: -3.2230e-06 - val_accuracy: 0.3333\n",
            "Epoch 56/69\n",
            "45/45 [==============================] - 5s 117ms/step - loss: -2.7333e-06 - accuracy: 0.3333 - val_loss: -3.2230e-06 - val_accuracy: 0.3333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-20 04:39:00,140]\u001b[0m Trial 3 finished with value: 0.3333333432674408 and parameters: {'epochs': 69, 'batch_size': 25, 'lr': 4.619556826126265e-05, 'dropout_l500': 0.6816393930174246, 'optimizer': 'SGD', 'Loss': 'kullback_leibler_divergence'}. Best is trial 2 with value: 0.9200000166893005.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            " 6/38 [===>..........................] - ETA: 3s - loss: 1.1091 - accuracy: 0.3167WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0464s vs `on_train_batch_end` time: 0.0588s). Check your callbacks.\n",
            "38/38 [==============================] - 9s 166ms/step - loss: 1.0899 - accuracy: 0.3547 - val_loss: 1.0578 - val_accuracy: 0.6107\n",
            "Epoch 2/70\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 1.0115 - accuracy: 0.5298 - val_loss: 0.8763 - val_accuracy: 0.6453\n",
            "Epoch 3/70\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.8508 - accuracy: 0.5884 - val_loss: 0.7343 - val_accuracy: 0.6320\n",
            "Epoch 4/70\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.7449 - accuracy: 0.6480 - val_loss: 0.6600 - val_accuracy: 0.6400\n",
            "Epoch 5/70\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.6567 - accuracy: 0.6924 - val_loss: 0.6118 - val_accuracy: 0.6907\n",
            "Epoch 6/70\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.6388 - accuracy: 0.6942 - val_loss: 0.5870 - val_accuracy: 0.7440\n",
            "Epoch 7/70\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.6058 - accuracy: 0.7120 - val_loss: 0.5643 - val_accuracy: 0.7253\n",
            "Epoch 8/70\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.5925 - accuracy: 0.7120 - val_loss: 0.5549 - val_accuracy: 0.7573\n",
            "Epoch 9/70\n",
            "38/38 [==============================] - 5s 135ms/step - loss: 0.5396 - accuracy: 0.7680 - val_loss: 0.5630 - val_accuracy: 0.7813\n",
            "Epoch 10/70\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.5526 - accuracy: 0.7396 - val_loss: 0.5412 - val_accuracy: 0.7840\n",
            "Epoch 11/70\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.5155 - accuracy: 0.7911 - val_loss: 0.4704 - val_accuracy: 0.8133\n",
            "Epoch 12/70\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.4511 - accuracy: 0.8098 - val_loss: 0.4790 - val_accuracy: 0.8080\n",
            "Epoch 13/70\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.4506 - accuracy: 0.8204 - val_loss: 0.4443 - val_accuracy: 0.8320\n",
            "Epoch 14/70\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.4327 - accuracy: 0.8302 - val_loss: 0.4250 - val_accuracy: 0.8373\n",
            "Epoch 15/70\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.3938 - accuracy: 0.8471 - val_loss: 0.4206 - val_accuracy: 0.8320\n",
            "Epoch 16/70\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.3935 - accuracy: 0.8436 - val_loss: 0.4143 - val_accuracy: 0.8560\n",
            "Epoch 17/70\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.3675 - accuracy: 0.8542 - val_loss: 0.4075 - val_accuracy: 0.8427\n",
            "Epoch 18/70\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.3763 - accuracy: 0.8533 - val_loss: 0.4048 - val_accuracy: 0.8400\n",
            "Epoch 19/70\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.3573 - accuracy: 0.8524 - val_loss: 0.3731 - val_accuracy: 0.8613\n",
            "Epoch 20/70\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.3157 - accuracy: 0.8773 - val_loss: 0.3972 - val_accuracy: 0.8587\n",
            "Epoch 21/70\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.3427 - accuracy: 0.8676 - val_loss: 0.3721 - val_accuracy: 0.8533\n",
            "Epoch 22/70\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.3278 - accuracy: 0.8631 - val_loss: 0.3743 - val_accuracy: 0.8560\n",
            "Epoch 23/70\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.3205 - accuracy: 0.8684 - val_loss: 0.3819 - val_accuracy: 0.8693\n",
            "Epoch 24/70\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.2928 - accuracy: 0.8889 - val_loss: 0.3445 - val_accuracy: 0.8613\n",
            "Epoch 25/70\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.2922 - accuracy: 0.8827 - val_loss: 0.3547 - val_accuracy: 0.8773\n",
            "Epoch 26/70\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.2716 - accuracy: 0.8933 - val_loss: 0.3516 - val_accuracy: 0.8747\n",
            "Epoch 27/70\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.2777 - accuracy: 0.8871 - val_loss: 0.3333 - val_accuracy: 0.8693\n",
            "Epoch 28/70\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.2658 - accuracy: 0.8871 - val_loss: 0.3376 - val_accuracy: 0.8747\n",
            "Epoch 29/70\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.2647 - accuracy: 0.9058 - val_loss: 0.3518 - val_accuracy: 0.8667\n",
            "Epoch 30/70\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.2423 - accuracy: 0.9040 - val_loss: 0.3391 - val_accuracy: 0.8773\n",
            "Epoch 31/70\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.2352 - accuracy: 0.9120 - val_loss: 0.3335 - val_accuracy: 0.8827\n",
            "Epoch 32/70\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.2271 - accuracy: 0.9049 - val_loss: 0.3443 - val_accuracy: 0.8720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-20 04:42:24,057]\u001b[0m Trial 4 finished with value: 0.871999979019165 and parameters: {'epochs': 70, 'batch_size': 30, 'lr': 3.373012122935467e-05, 'dropout_l500': 0.6175217440692008, 'optimizer': 'Adadelta', 'Loss': 'categorical_crossentropy'}. Best is trial 2 with value: 0.9200000166893005.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  5\n",
            "  Number of pruned trials:  0\n",
            "  Number of complete trials:  5\n",
            "Best trial:\n",
            "  Value:  0.9200000166893005\n",
            "  Params: \n",
            "    epochs: 70\n",
            "    batch_size: 26\n",
            "    lr: 0.0002194159278335913\n",
            "    dropout_l500: 0.6886279251938925\n",
            "    optimizer: RMSprop\n",
            "    Loss: categorical_crossentropy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "cBilcL5eBy2v",
        "outputId": "fafe563a-e057-42e9-fc7d-4b976bcd1833"
      },
      "source": [
        "optuna.visualization.plot_optimization_history(study1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"7e15ae0d-3c63-4a03-b32e-34ce16002841\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"7e15ae0d-3c63-4a03-b32e-34ce16002841\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '7e15ae0d-3c63-4a03-b32e-34ce16002841',\n",
              "                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4], \"y\": [0.3333333432674408, 0.8613333106040955, 0.9200000166893005, 0.3333333432674408, 0.871999979019165]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4], \"y\": [0.3333333432674408, 0.8613333106040955, 0.9200000166893005, 0.9200000166893005, 0.9200000166893005]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7e15ae0d-3c63-4a03-b32e-34ce16002841');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UR8nmbtf_sx",
        "outputId": "eee2fe2d-e5f5-46cf-a21a-389d027e8711"
      },
      "source": [
        "!pip install pycopy-copy\n",
        "!pip install cma"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycopy-copy\n",
            "  Downloading pycopy-copy-3.3.3.post7.tar.gz (3.7 kB)\n",
            "\u001b[31mERROR: File \"setup.py\" not found for legacy project pycopy-copy from https://files.pythonhosted.org/packages/a3/91/62fdd1a19b718f0b81f0042dd6045f90f1cf00566a49127adf75cb0fd0b3/pycopy-copy-3.3.3.post7.tar.gz#sha256=33b5c42cd8f7d57c371fcc4c137498e7f57119364c6761265c9c6e490e5761dd.\u001b[0m\n",
            "Requirement already satisfied: cma in /usr/local/lib/python3.7/dist-packages (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpJICUEPa3CY",
        "outputId": "8ce3ded0-487a-46b5-82cf-bf39f0356fe1"
      },
      "source": [
        "import copy\n",
        "import optuna\n",
        "study_tpe_cmaes = copy.deepcopy(study1)\n",
        "study_tpe_cmaes.sampler = optuna.integration.PyCmaSampler()\n",
        "study_tpe_cmaes.optimize(objective, n_trials=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/55\n",
            " 6/41 [===>..........................] - ETA: 4s - loss: 0.7206 - accuracy: 0.3155WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0481s vs `on_train_batch_end` time: 0.0794s). Check your callbacks.\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.6862 - accuracy: 0.4382 - val_loss: 0.6137 - val_accuracy: 0.5973\n",
            "Epoch 2/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.5793 - accuracy: 0.6444 - val_loss: 0.5609 - val_accuracy: 0.6053\n",
            "Epoch 3/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.5482 - accuracy: 0.6880 - val_loss: 0.5562 - val_accuracy: 0.5973\n",
            "Epoch 4/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.5267 - accuracy: 0.7511 - val_loss: 0.5068 - val_accuracy: 0.7680\n",
            "Epoch 5/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.4949 - accuracy: 0.8204 - val_loss: 0.4839 - val_accuracy: 0.8267\n",
            "Epoch 6/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4754 - accuracy: 0.8276 - val_loss: 0.4682 - val_accuracy: 0.8427\n",
            "Epoch 7/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4577 - accuracy: 0.8507 - val_loss: 0.4642 - val_accuracy: 0.8347\n",
            "Epoch 8/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.4542 - accuracy: 0.8524 - val_loss: 0.4654 - val_accuracy: 0.8507\n",
            "Epoch 9/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4508 - accuracy: 0.8676 - val_loss: 0.4515 - val_accuracy: 0.8613\n",
            "Epoch 10/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.4390 - accuracy: 0.8596 - val_loss: 0.4465 - val_accuracy: 0.8640\n",
            "Epoch 11/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4304 - accuracy: 0.8827 - val_loss: 0.4454 - val_accuracy: 0.8587\n",
            "Epoch 12/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4301 - accuracy: 0.8791 - val_loss: 0.4449 - val_accuracy: 0.8720\n",
            "Epoch 13/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.4205 - accuracy: 0.8907 - val_loss: 0.4367 - val_accuracy: 0.8640\n",
            "Epoch 14/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4112 - accuracy: 0.9076 - val_loss: 0.4346 - val_accuracy: 0.8640\n",
            "Epoch 15/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4069 - accuracy: 0.9244 - val_loss: 0.4369 - val_accuracy: 0.8747\n",
            "Epoch 16/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4039 - accuracy: 0.9173 - val_loss: 0.4553 - val_accuracy: 0.8693\n",
            "Epoch 17/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.4165 - accuracy: 0.8960 - val_loss: 0.4369 - val_accuracy: 0.8853\n",
            "Epoch 18/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.3994 - accuracy: 0.9262 - val_loss: 0.4499 - val_accuracy: 0.8720\n",
            "Epoch 19/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.3972 - accuracy: 0.9218 - val_loss: 0.4316 - val_accuracy: 0.8987\n",
            "Epoch 20/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.3862 - accuracy: 0.9458 - val_loss: 0.4384 - val_accuracy: 0.8987\n",
            "Epoch 21/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.3811 - accuracy: 0.9538 - val_loss: 0.4361 - val_accuracy: 0.8800\n",
            "Epoch 22/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.3802 - accuracy: 0.9449 - val_loss: 0.4304 - val_accuracy: 0.8987\n",
            "Epoch 23/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.3778 - accuracy: 0.9484 - val_loss: 0.4264 - val_accuracy: 0.9013\n",
            "Epoch 24/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.3775 - accuracy: 0.9547 - val_loss: 0.4357 - val_accuracy: 0.8960\n",
            "Epoch 25/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.3791 - accuracy: 0.9431 - val_loss: 0.4306 - val_accuracy: 0.8880\n",
            "Epoch 26/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.3714 - accuracy: 0.9644 - val_loss: 0.4481 - val_accuracy: 0.8907\n",
            "Epoch 27/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.3682 - accuracy: 0.9636 - val_loss: 0.4348 - val_accuracy: 0.8987\n",
            "Epoch 28/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.3625 - accuracy: 0.9689 - val_loss: 0.4340 - val_accuracy: 0.9013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-20 04:46:58,416]\u001b[0m Trial 5 finished with value: 0.9013333320617676 and parameters: {'epochs': 55, 'batch_size': 28, 'lr': 9.476718264853137e-05, 'dropout_l500': 0.5292871885409233, 'optimizer': 'Adadelta', 'Loss': 'poisson'}. Best is trial 2 with value: 0.9200000166893005.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/55\n",
            " 6/41 [===>..........................] - ETA: 3s - loss: 0.7222 - accuracy: 0.2857WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0436s vs `on_train_batch_end` time: 0.0681s). Check your callbacks.\n",
            "41/41 [==============================] - 6s 131ms/step - loss: 0.7006 - accuracy: 0.3849 - val_loss: 0.6784 - val_accuracy: 0.3653\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-20 04:47:06,087]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/55\n",
            " 6/41 [===>..........................] - ETA: 4s - loss: 0.7131 - accuracy: 0.3095WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0485s vs `on_train_batch_end` time: 0.0799s). Check your callbacks.\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.6977 - accuracy: 0.4160 - val_loss: 0.6673 - val_accuracy: 0.5733\n",
            "Epoch 2/55\n",
            "41/41 [==============================] - 5s 123ms/step - loss: 0.6217 - accuracy: 0.6009 - val_loss: 0.5670 - val_accuracy: 0.6853\n",
            "Epoch 3/55\n",
            "41/41 [==============================] - 5s 123ms/step - loss: 0.5529 - accuracy: 0.6853 - val_loss: 0.5466 - val_accuracy: 0.7067\n",
            "Epoch 4/55\n",
            "41/41 [==============================] - 5s 123ms/step - loss: 0.5333 - accuracy: 0.7333 - val_loss: 0.5112 - val_accuracy: 0.7760\n",
            "Epoch 5/55\n",
            "41/41 [==============================] - 5s 123ms/step - loss: 0.5052 - accuracy: 0.7822 - val_loss: 0.5018 - val_accuracy: 0.7973\n",
            "Epoch 6/55\n",
            "41/41 [==============================] - 5s 123ms/step - loss: 0.4881 - accuracy: 0.8142 - val_loss: 0.4853 - val_accuracy: 0.8240\n",
            "Epoch 7/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4790 - accuracy: 0.8187 - val_loss: 0.4861 - val_accuracy: 0.8267\n",
            "Epoch 8/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4633 - accuracy: 0.8427 - val_loss: 0.4654 - val_accuracy: 0.8533\n",
            "Epoch 9/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4618 - accuracy: 0.8453 - val_loss: 0.4638 - val_accuracy: 0.8453\n",
            "Epoch 10/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4550 - accuracy: 0.8640 - val_loss: 0.4592 - val_accuracy: 0.8533\n",
            "Epoch 11/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4450 - accuracy: 0.8711 - val_loss: 0.4526 - val_accuracy: 0.8667\n",
            "Epoch 12/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4420 - accuracy: 0.8702 - val_loss: 0.4441 - val_accuracy: 0.8613\n",
            "Epoch 13/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4312 - accuracy: 0.8738 - val_loss: 0.4456 - val_accuracy: 0.8747\n",
            "Epoch 14/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4267 - accuracy: 0.8880 - val_loss: 0.4423 - val_accuracy: 0.8720\n",
            "Epoch 15/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4222 - accuracy: 0.8898 - val_loss: 0.4406 - val_accuracy: 0.8693\n",
            "Epoch 16/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.4166 - accuracy: 0.9022 - val_loss: 0.4466 - val_accuracy: 0.8800\n",
            "Epoch 17/55\n",
            "41/41 [==============================] - 5s 127ms/step - loss: 0.4095 - accuracy: 0.9049 - val_loss: 0.4332 - val_accuracy: 0.8640\n",
            "Epoch 18/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4149 - accuracy: 0.9111 - val_loss: 0.4423 - val_accuracy: 0.8747\n",
            "Epoch 19/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.4048 - accuracy: 0.9164 - val_loss: 0.4264 - val_accuracy: 0.8880\n",
            "Epoch 20/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4034 - accuracy: 0.9244 - val_loss: 0.4407 - val_accuracy: 0.8827\n",
            "Epoch 21/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.3976 - accuracy: 0.9236 - val_loss: 0.4282 - val_accuracy: 0.8907\n",
            "Epoch 22/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.3978 - accuracy: 0.9191 - val_loss: 0.4398 - val_accuracy: 0.8960\n",
            "Epoch 23/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.3919 - accuracy: 0.9342 - val_loss: 0.4280 - val_accuracy: 0.8960\n",
            "Epoch 24/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.3883 - accuracy: 0.9369 - val_loss: 0.4280 - val_accuracy: 0.8987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-20 04:49:35,190]\u001b[0m Trial 7 finished with value: 0.8986666798591614 and parameters: {'epochs': 55, 'batch_size': 28, 'lr': 0.0001021968772280764, 'dropout_l500': 0.6321291532193782, 'optimizer': 'Adadelta', 'Loss': 'poisson'}. Best is trial 2 with value: 0.9200000166893005.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/55\n",
            " 6/41 [===>..........................] - ETA: 3s - loss: 0.7169 - accuracy: 0.3214WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0419s vs `on_train_batch_end` time: 0.0685s). Check your callbacks.\n",
            "41/41 [==============================] - 6s 132ms/step - loss: 0.6972 - accuracy: 0.3956 - val_loss: 0.6651 - val_accuracy: 0.4987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-20 04:49:43,268]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/55\n",
            " 6/41 [===>..........................] - ETA: 3s - loss: 0.7169 - accuracy: 0.3452WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0425s vs `on_train_batch_end` time: 0.0675s). Check your callbacks.\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.6947 - accuracy: 0.4000 - val_loss: 0.6510 - val_accuracy: 0.5760\n",
            "Epoch 2/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.6081 - accuracy: 0.6098 - val_loss: 0.5648 - val_accuracy: 0.6240\n",
            "Epoch 3/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.5630 - accuracy: 0.6756 - val_loss: 0.5474 - val_accuracy: 0.7227\n",
            "Epoch 4/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.5395 - accuracy: 0.7093 - val_loss: 0.5295 - val_accuracy: 0.7627\n",
            "Epoch 5/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.5176 - accuracy: 0.7493 - val_loss: 0.4967 - val_accuracy: 0.7840\n",
            "Epoch 6/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4916 - accuracy: 0.8169 - val_loss: 0.4904 - val_accuracy: 0.8000\n",
            "Epoch 7/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4856 - accuracy: 0.8222 - val_loss: 0.4778 - val_accuracy: 0.8320\n",
            "Epoch 8/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.4758 - accuracy: 0.8240 - val_loss: 0.4683 - val_accuracy: 0.8427\n",
            "Epoch 9/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4601 - accuracy: 0.8444 - val_loss: 0.4640 - val_accuracy: 0.8293\n",
            "Epoch 10/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4542 - accuracy: 0.8560 - val_loss: 0.4658 - val_accuracy: 0.8453\n",
            "Epoch 11/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4499 - accuracy: 0.8596 - val_loss: 0.4595 - val_accuracy: 0.8427\n",
            "Epoch 12/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.4388 - accuracy: 0.8622 - val_loss: 0.4545 - val_accuracy: 0.8480\n",
            "Epoch 13/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.4287 - accuracy: 0.8800 - val_loss: 0.4460 - val_accuracy: 0.8640\n",
            "Epoch 14/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.4466 - accuracy: 0.8578 - val_loss: 0.4469 - val_accuracy: 0.8560\n",
            "Epoch 15/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.4294 - accuracy: 0.8773 - val_loss: 0.4480 - val_accuracy: 0.8613\n",
            "Epoch 16/55\n",
            "41/41 [==============================] - 5s 126ms/step - loss: 0.4244 - accuracy: 0.8782 - val_loss: 0.4447 - val_accuracy: 0.8613\n",
            "Epoch 17/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4145 - accuracy: 0.8996 - val_loss: 0.4369 - val_accuracy: 0.8640\n",
            "Epoch 18/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.4105 - accuracy: 0.9102 - val_loss: 0.4462 - val_accuracy: 0.8560\n",
            "Epoch 19/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4111 - accuracy: 0.9058 - val_loss: 0.4431 - val_accuracy: 0.8693\n",
            "Epoch 20/55\n",
            "41/41 [==============================] - 5s 125ms/step - loss: 0.4011 - accuracy: 0.9227 - val_loss: 0.4485 - val_accuracy: 0.8613\n",
            "Epoch 21/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.3985 - accuracy: 0.9333 - val_loss: 0.4484 - val_accuracy: 0.8640\n",
            "Epoch 22/55\n",
            "41/41 [==============================] - 5s 124ms/step - loss: 0.4043 - accuracy: 0.9244 - val_loss: 0.4463 - val_accuracy: 0.8747\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-20 04:52:12,802]\u001b[0m Trial 9 finished with value: 0.874666690826416 and parameters: {'epochs': 55, 'batch_size': 28, 'lr': 9.577471303074424e-05, 'dropout_l500': 0.597845229986068, 'optimizer': 'Adadelta', 'Loss': 'poisson'}. Best is trial 2 with value: 0.9200000166893005.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-ctyJNu5OPH",
        "outputId": "ac764d71-d815-4850-f502-f2281212ee17"
      },
      "source": [
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study_tpe_cmaes.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study_tpe_cmaes.best_trial\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  10\n",
            "  Number of pruned trials:  0\n",
            "  Number of complete trials:  5\n",
            "Best trial:\n",
            "  Value:  0.9200000166893005\n",
            "  Params: \n",
            "    epochs: 70\n",
            "    batch_size: 26\n",
            "    lr: 0.0002194159278335913\n",
            "    dropout_l500: 0.6886279251938925\n",
            "    optimizer: RMSprop\n",
            "    Loss: categorical_crossentropy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "XlG5LFJwf4lL",
        "outputId": "9b8eb5ad-7cdd-4f4b-bf13-836eecd55dce"
      },
      "source": [
        "optuna.visualization.plot_optimization_history(study_tpe_cmaes)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"723ab1ba-8cd8-452b-ac14-a0d8cf3401b7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"723ab1ba-8cd8-452b-ac14-a0d8cf3401b7\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '723ab1ba-8cd8-452b-ac14-a0d8cf3401b7',\n",
              "                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 7, 9], \"y\": [0.3333333432674408, 0.8613333106040955, 0.9200000166893005, 0.3333333432674408, 0.871999979019165, 0.9013333320617676, 0.8986666798591614, 0.874666690826416]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 7, 9], \"y\": [0.3333333432674408, 0.8613333106040955, 0.9200000166893005, 0.9200000166893005, 0.9200000166893005, 0.9200000166893005, 0.9200000166893005, 0.9200000166893005]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('723ab1ba-8cd8-452b-ac14-a0d8cf3401b7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "XeFuyw_kmGT4",
        "outputId": "27a59ae6-8eb2-4623-80a3-a85f90c173fa"
      },
      "source": [
        "optuna.visualization.plot_intermediate_values(study_tpe_cmaes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"84cb348b-47ac-43f9-80cf-5dda5ac4bca9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"84cb348b-47ac-43f9-80cf-5dda5ac4bca9\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '84cb348b-47ac-43f9-80cf-5dda5ac4bca9',\n",
              "                        [{\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial0\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], \"y\": [0.335999995470047, 0.35199999809265137, 0.36266666650772095, 0.36533331871032715, 0.36533331871032715, 0.35733333230018616, 0.35199999809265137, 0.3466666638851166, 0.3306666612625122, 0.3413333296775818, 0.3413333296775818, 0.3333333432674408, 0.3306666612625122, 0.328000009059906, 0.30933332443237305, 0.30133333802223206, 0.29600000381469727, 0.2853333353996277, 0.2826666533946991, 0.2773333191871643, 0.2746666669845581, 0.2639999985694885, 0.2613333463668823, 0.2639999985694885, 0.2720000147819519, 0.2800000011920929, 0.2800000011920929, 0.2826666533946991, 0.2826666533946991, 0.2906666696071625, 0.2879999876022339, 0.2879999876022339, 0.2906666696071625, 0.2906666696071625, 0.2906666696071625, 0.2933333218097687, 0.29866665601730347, 0.2906666696071625, 0.29866665601730347, 0.30399999022483826, 0.30399999022483826, 0.31200000643730164, 0.31466665863990784, 0.31200000643730164, 0.3173333406448364, 0.3173333406448364, 0.328000009059906, 0.3253333270549774, 0.3306666612625122, 0.3253333270549774, 0.328000009059906, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial1\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], \"y\": [0.3333333432674408, 0.3893333375453949, 0.5973333120346069, 0.5973333120346069, 0.6240000128746033, 0.6186666488647461, 0.6639999747276306, 0.6853333115577698, 0.6693333387374878, 0.7333333492279053, 0.7120000123977661, 0.6826666593551636, 0.7173333168029785, 0.7413333058357239, 0.7599999904632568, 0.7546666860580444, 0.800000011920929, 0.7866666913032532, 0.8026666641235352, 0.7706666588783264, 0.8293333053588867, 0.8240000009536743, 0.8426666855812073, 0.8373333215713501, 0.8426666855812073, 0.8426666855812073, 0.8533333539962769, 0.8426666855812073, 0.8426666855812073, 0.8426666855812073, 0.8533333539962769, 0.8533333539962769, 0.8453333377838135, 0.8533333539962769, 0.8613333106040955, 0.8453333377838135, 0.8506666421890259, 0.8453333377838135, 0.8693333268165588, 0.8586666584014893, 0.8640000224113464, 0.8613333106040955]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial2\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], \"y\": [0.6666666865348816, 0.671999990940094, 0.7733333110809326, 0.7973333597183228, 0.8213333487510681, 0.8373333215713501, 0.8506666421890259, 0.8640000224113464, 0.871999979019165, 0.8799999952316284, 0.8506666421890259, 0.8693333268165588, 0.8826666474342346, 0.8960000276565552, 0.8799999952316284, 0.8933333158493042, 0.874666690826416, 0.890666663646698, 0.9013333320617676, 0.9013333320617676, 0.9039999842643738, 0.9066666960716248, 0.909333348274231, 0.9039999842643738, 0.9039999842643738, 0.9146666526794434, 0.9200000166893005]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial3\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], \"y\": [0.36533331871032715, 0.3306666612625122, 0.31200000643730164, 0.29866665601730347, 0.2853333353996277, 0.2800000011920929, 0.2613333463668823, 0.2693333327770233, 0.2826666533946991, 0.2826666533946991, 0.2906666696071625, 0.2853333353996277, 0.2879999876022339, 0.2933333218097687, 0.29866665601730347, 0.30133333802223206, 0.29866665601730347, 0.31200000643730164, 0.31466665863990784, 0.31466665863990784, 0.3173333406448364, 0.3226666748523712, 0.3199999928474426, 0.3306666612625122, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.328000009059906, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial4\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], \"y\": [0.6106666922569275, 0.6453333497047424, 0.6320000290870667, 0.6399999856948853, 0.690666675567627, 0.7440000176429749, 0.7253333330154419, 0.7573333382606506, 0.781333327293396, 0.7839999794960022, 0.8133333325386047, 0.8080000281333923, 0.8320000171661377, 0.8373333215713501, 0.8320000171661377, 0.8560000061988831, 0.8426666855812073, 0.8399999737739563, 0.8613333106040955, 0.8586666584014893, 0.8533333539962769, 0.8560000061988831, 0.8693333268165588, 0.8613333106040955, 0.8773333430290222, 0.874666690826416, 0.8693333268165588, 0.874666690826416, 0.8666666746139526, 0.8773333430290222, 0.8826666474342346, 0.871999979019165]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial5\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], \"y\": [0.5973333120346069, 0.6053333282470703, 0.5973333120346069, 0.7680000066757202, 0.8266666531562805, 0.8426666855812073, 0.8346666693687439, 0.8506666421890259, 0.8613333106040955, 0.8640000224113464, 0.8586666584014893, 0.871999979019165, 0.8640000224113464, 0.8640000224113464, 0.874666690826416, 0.8693333268165588, 0.8853333592414856, 0.871999979019165, 0.8986666798591614, 0.8986666798591614, 0.8799999952316284, 0.8986666798591614, 0.9013333320617676, 0.8960000276565552, 0.8880000114440918, 0.890666663646698, 0.8986666798591614, 0.9013333320617676]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial6\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.36533331871032715]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial7\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], \"y\": [0.5733333230018616, 0.6853333115577698, 0.7066666483879089, 0.7760000228881836, 0.7973333597183228, 0.8240000009536743, 0.8266666531562805, 0.8533333539962769, 0.8453333377838135, 0.8533333539962769, 0.8666666746139526, 0.8613333106040955, 0.874666690826416, 0.871999979019165, 0.8693333268165588, 0.8799999952316284, 0.8640000224113464, 0.874666690826416, 0.8880000114440918, 0.8826666474342346, 0.890666663646698, 0.8960000276565552, 0.8960000276565552, 0.8986666798591614]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial8\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.4986666738986969]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial9\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], \"y\": [0.5759999752044678, 0.6240000128746033, 0.7226666808128357, 0.762666642665863, 0.7839999794960022, 0.800000011920929, 0.8320000171661377, 0.8426666855812073, 0.8293333053588867, 0.8453333377838135, 0.8426666855812073, 0.8479999899864197, 0.8640000224113464, 0.8560000061988831, 0.8613333106040955, 0.8613333106040955, 0.8640000224113464, 0.8560000061988831, 0.8693333268165588, 0.8613333106040955, 0.8640000224113464, 0.874666690826416]}],\n",
              "                        {\"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Intermediate Values Plot\"}, \"xaxis\": {\"title\": {\"text\": \"Step\"}}, \"yaxis\": {\"title\": {\"text\": \"Intermediate Value\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('84cb348b-47ac-43f9-80cf-5dda5ac4bca9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX08SXjm8Q3a"
      },
      "source": [
        "## TPES-TESTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6qmXEU_U0s6",
        "outputId": "f97d47c1-c16a-4d04-e956-0cf7a6dafcd7"
      },
      "source": [
        "#TPES sampler\n",
        "from keras.backend import clear_session\n",
        "clear_session()\n",
        "\n",
        "def objective(trial):\n",
        "    if tf.__version__ >= \"2\":\n",
        "        monitor = \"val_accuracy\"\n",
        "    else:\n",
        "        monitor = \"val_acc\"\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    epochs = trial.suggest_int('epochs', 40, 70)\n",
        "    batch_size = trial.suggest_int('batch_size', 24, 32)\n",
        "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n",
        "    conv = cnn()\n",
        "    \n",
        "    #optimizer = Adam(lr=1e-3)\n",
        "    conv.compile(optimizer= Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    #model.fit(cancer_files_train,train_labels,batch_size=None,epochs=10)\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(patience=3),\n",
        "        TFKerasPruningCallback(trial, monitor),\n",
        "    ]\n",
        "    history = conv.fit(X_train, \n",
        "                        y_train, \n",
        "                        batch_size=batch_size,\n",
        "                        validation_data=(X_test, y_test),\n",
        "                        epochs=epochs,\n",
        "                        callbacks=callbacks,\n",
        "                        verbose=1)\n",
        "    \n",
        "    score = conv.evaluate(X_test, y_test, verbose=0)\n",
        "    return history.history[monitor][-1]\n",
        "\n",
        "study1 = optuna.create_study(sampler = optuna.samplers.TPESampler())\n",
        "#study.optimize(objective, n_trials=10)\n",
        "\n",
        "study1.optimize(objective, n_trials=15)\n",
        "pruned_trials = study1.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study1.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study1.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study1.best_trial\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 07:33:10,836]\u001b[0m A new study created in memory with name: no-name-4713314c-b07e-489f-9b15-ab70974b3f2d\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/44\n",
            " 6/49 [==>...........................] - ETA: 4s - loss: 0.6829 - accuracy: 0.3333WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0463s vs `on_train_batch_end` time: 0.0693s). Check your callbacks.\n",
            "49/49 [==============================] - 7s 131ms/step - loss: 0.6271 - accuracy: 0.4504 - val_loss: 0.5485 - val_accuracy: 0.6222\n",
            "Epoch 2/44\n",
            "49/49 [==============================] - 6s 122ms/step - loss: 0.4872 - accuracy: 0.6304 - val_loss: 0.4094 - val_accuracy: 0.7044\n",
            "Epoch 3/44\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 0.4299 - accuracy: 0.6859 - val_loss: 0.3754 - val_accuracy: 0.7511\n",
            "Epoch 4/44\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.3821 - accuracy: 0.7348 - val_loss: 0.3288 - val_accuracy: 0.7711\n",
            "Epoch 5/44\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 0.3432 - accuracy: 0.7585 - val_loss: 0.2684 - val_accuracy: 0.8222\n",
            "Epoch 6/44\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.3060 - accuracy: 0.8081 - val_loss: 0.2382 - val_accuracy: 0.8489\n",
            "Epoch 7/44\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 0.2749 - accuracy: 0.8178 - val_loss: 0.2460 - val_accuracy: 0.8444\n",
            "Epoch 8/44\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 0.2528 - accuracy: 0.8444 - val_loss: 0.2123 - val_accuracy: 0.8644\n",
            "Epoch 9/44\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 0.2240 - accuracy: 0.8704 - val_loss: 0.2066 - val_accuracy: 0.8667\n",
            "Epoch 10/44\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 0.2238 - accuracy: 0.8637 - val_loss: 0.1973 - val_accuracy: 0.8800\n",
            "Epoch 11/44\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 0.1990 - accuracy: 0.8859 - val_loss: 0.1889 - val_accuracy: 0.8800\n",
            "Epoch 12/44\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.1874 - accuracy: 0.8830 - val_loss: 0.1822 - val_accuracy: 0.8822\n",
            "Epoch 13/44\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 0.1632 - accuracy: 0.9089 - val_loss: 0.1920 - val_accuracy: 0.8800\n",
            "Epoch 14/44\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 0.1522 - accuracy: 0.9178 - val_loss: 0.1870 - val_accuracy: 0.8889\n",
            "Epoch 15/44\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.1477 - accuracy: 0.9133 - val_loss: 0.1842 - val_accuracy: 0.8956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 07:35:39,671]\u001b[0m Trial 0 finished with value: 0.8955555558204651 and parameters: {'epochs': 44, 'batch_size': 28, 'lr': 3.796427320222813e-05}. Best is trial 0 with value: 0.8955555558204651.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/52\n",
            " 6/52 [==>...........................] - ETA: 5s - loss: 0.6733 - accuracy: 0.3590WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0449s vs `on_train_batch_end` time: 0.0708s). Check your callbacks.\n",
            "52/52 [==============================] - 7s 126ms/step - loss: 0.5318 - accuracy: 0.5778 - val_loss: 0.3352 - val_accuracy: 0.8067\n",
            "Epoch 2/52\n",
            "52/52 [==============================] - 6s 119ms/step - loss: 0.3290 - accuracy: 0.7985 - val_loss: 0.2533 - val_accuracy: 0.8422\n",
            "Epoch 3/52\n",
            "52/52 [==============================] - 6s 119ms/step - loss: 0.2511 - accuracy: 0.8511 - val_loss: 0.2201 - val_accuracy: 0.8822\n",
            "Epoch 4/52\n",
            "52/52 [==============================] - 6s 118ms/step - loss: 0.2153 - accuracy: 0.8733 - val_loss: 0.2040 - val_accuracy: 0.8778\n",
            "Epoch 5/52\n",
            "52/52 [==============================] - 6s 119ms/step - loss: 0.1652 - accuracy: 0.9030 - val_loss: 0.1847 - val_accuracy: 0.8911\n",
            "Epoch 6/52\n",
            "52/52 [==============================] - 6s 118ms/step - loss: 0.1510 - accuracy: 0.9163 - val_loss: 0.1615 - val_accuracy: 0.9000\n",
            "Epoch 7/52\n",
            "52/52 [==============================] - 6s 118ms/step - loss: 0.1234 - accuracy: 0.9259 - val_loss: 0.1443 - val_accuracy: 0.9178\n",
            "Epoch 8/52\n",
            "52/52 [==============================] - 6s 119ms/step - loss: 0.0913 - accuracy: 0.9452 - val_loss: 0.1525 - val_accuracy: 0.9000\n",
            "Epoch 9/52\n",
            "52/52 [==============================] - 6s 118ms/step - loss: 0.0678 - accuracy: 0.9630 - val_loss: 0.2140 - val_accuracy: 0.9022\n",
            "Epoch 10/52\n",
            "52/52 [==============================] - 6s 119ms/step - loss: 0.0592 - accuracy: 0.9704 - val_loss: 0.1928 - val_accuracy: 0.8978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 07:37:09,003]\u001b[0m Trial 1 finished with value: 0.897777795791626 and parameters: {'epochs': 52, 'batch_size': 26, 'lr': 0.0008473347301584612}. Best is trial 0 with value: 0.8955555558204651.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/54\n",
            " 6/52 [==>...........................] - ETA: 4s - loss: 0.6728 - accuracy: 0.3654WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0422s vs `on_train_batch_end` time: 0.0650s). Check your callbacks.\n",
            "52/52 [==============================] - 7s 127ms/step - loss: 0.5600 - accuracy: 0.4941 - val_loss: 0.4215 - val_accuracy: 0.6711\n",
            "Epoch 2/54\n",
            "52/52 [==============================] - 6s 118ms/step - loss: 0.3794 - accuracy: 0.7578 - val_loss: 0.3450 - val_accuracy: 0.7956\n",
            "Epoch 3/54\n",
            "52/52 [==============================] - 6s 119ms/step - loss: 0.2906 - accuracy: 0.8222 - val_loss: 0.2420 - val_accuracy: 0.8356\n",
            "Epoch 4/54\n",
            "52/52 [==============================] - 6s 119ms/step - loss: 0.2454 - accuracy: 0.8556 - val_loss: 0.2410 - val_accuracy: 0.8467\n",
            "Epoch 5/54\n",
            "52/52 [==============================] - 6s 118ms/step - loss: 0.2042 - accuracy: 0.8733 - val_loss: 0.2373 - val_accuracy: 0.8444\n",
            "Epoch 6/54\n",
            "52/52 [==============================] - 6s 119ms/step - loss: 0.1752 - accuracy: 0.8896 - val_loss: 0.2050 - val_accuracy: 0.8711\n",
            "Epoch 7/54\n",
            "52/52 [==============================] - 6s 118ms/step - loss: 0.1375 - accuracy: 0.9163 - val_loss: 0.1695 - val_accuracy: 0.8956\n",
            "Epoch 8/54\n",
            "52/52 [==============================] - 6s 118ms/step - loss: 0.1148 - accuracy: 0.9341 - val_loss: 0.1817 - val_accuracy: 0.8978\n",
            "Epoch 9/54\n",
            "52/52 [==============================] - 6s 119ms/step - loss: 0.0986 - accuracy: 0.9459 - val_loss: 0.1545 - val_accuracy: 0.9022\n",
            "Epoch 10/54\n",
            "52/52 [==============================] - 6s 119ms/step - loss: 0.1130 - accuracy: 0.9341 - val_loss: 0.1923 - val_accuracy: 0.8933\n",
            "Epoch 11/54\n",
            "52/52 [==============================] - 6s 118ms/step - loss: 0.0631 - accuracy: 0.9674 - val_loss: 0.2501 - val_accuracy: 0.8956\n",
            "Epoch 12/54\n",
            "52/52 [==============================] - 6s 118ms/step - loss: 0.0480 - accuracy: 0.9763 - val_loss: 0.2115 - val_accuracy: 0.9133\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 07:38:37,756]\u001b[0m Trial 2 finished with value: 0.9133333563804626 and parameters: {'epochs': 54, 'batch_size': 26, 'lr': 0.0006222604726094448}. Best is trial 0 with value: 0.8955555558204651.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/59\n",
            " 6/52 [==>...........................] - ETA: 4s - loss: 0.6599 - accuracy: 0.3077WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0417s vs `on_train_batch_end` time: 0.0637s). Check your callbacks.\n",
            "52/52 [==============================] - 7s 127ms/step - loss: 0.5737 - accuracy: 0.4985 - val_loss: 0.4154 - val_accuracy: 0.6356\n",
            "Epoch 2/59\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.3820 - accuracy: 0.7244 - val_loss: 0.2930 - val_accuracy: 0.8222\n",
            "Epoch 3/59\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.3235 - accuracy: 0.7993 - val_loss: 0.2379 - val_accuracy: 0.8378\n",
            "Epoch 4/59\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.2475 - accuracy: 0.8496 - val_loss: 0.2310 - val_accuracy: 0.8644\n",
            "Epoch 5/59\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.2277 - accuracy: 0.8519 - val_loss: 0.2187 - val_accuracy: 0.8756\n",
            "Epoch 6/59\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.1950 - accuracy: 0.8896 - val_loss: 0.1819 - val_accuracy: 0.8867\n",
            "Epoch 7/59\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.1706 - accuracy: 0.8956 - val_loss: 0.1895 - val_accuracy: 0.8800\n",
            "Epoch 8/59\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.1553 - accuracy: 0.9096 - val_loss: 0.2139 - val_accuracy: 0.8733\n",
            "Epoch 9/59\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.1274 - accuracy: 0.9267 - val_loss: 0.1766 - val_accuracy: 0.9000\n",
            "Epoch 10/59\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.1152 - accuracy: 0.9356 - val_loss: 0.1702 - val_accuracy: 0.9067\n",
            "Epoch 11/59\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0997 - accuracy: 0.9452 - val_loss: 0.1744 - val_accuracy: 0.9044\n",
            "Epoch 12/59\n",
            "52/52 [==============================] - 6s 121ms/step - loss: 0.0918 - accuracy: 0.9430 - val_loss: 0.1899 - val_accuracy: 0.9022\n",
            "Epoch 13/59\n",
            "52/52 [==============================] - 6s 120ms/step - loss: 0.0796 - accuracy: 0.9585 - val_loss: 0.1877 - val_accuracy: 0.8933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 07:40:06,949]\u001b[0m Trial 3 finished with value: 0.8933333158493042 and parameters: {'epochs': 59, 'batch_size': 26, 'lr': 0.0001273032982049576}. Best is trial 3 with value: 0.8933333158493042.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/57\n",
            " 6/50 [==>...........................] - ETA: 5s - loss: 0.6636 - accuracy: 0.2469WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0178s vs `on_train_batch_end` time: 0.1037s). Check your callbacks.\n",
            "50/50 [==============================] - 7s 131ms/step - loss: 0.5701 - accuracy: 0.5259 - val_loss: 0.3699 - val_accuracy: 0.7578\n",
            "Epoch 2/57\n",
            "50/50 [==============================] - 6s 124ms/step - loss: 0.3436 - accuracy: 0.7681 - val_loss: 0.2734 - val_accuracy: 0.8067\n",
            "Epoch 3/57\n",
            "50/50 [==============================] - 6s 124ms/step - loss: 0.2789 - accuracy: 0.8370 - val_loss: 0.2128 - val_accuracy: 0.8644\n",
            "Epoch 4/57\n",
            "50/50 [==============================] - 6s 124ms/step - loss: 0.2364 - accuracy: 0.8578 - val_loss: 0.2029 - val_accuracy: 0.8578\n",
            "Epoch 5/57\n",
            "50/50 [==============================] - 6s 124ms/step - loss: 0.1822 - accuracy: 0.8933 - val_loss: 0.1944 - val_accuracy: 0.8800\n",
            "Epoch 6/57\n",
            "50/50 [==============================] - 6s 124ms/step - loss: 0.1624 - accuracy: 0.9089 - val_loss: 0.2452 - val_accuracy: 0.8289\n",
            "Epoch 7/57\n",
            "50/50 [==============================] - 6s 124ms/step - loss: 0.1386 - accuracy: 0.9215 - val_loss: 0.1756 - val_accuracy: 0.8933\n",
            "Epoch 8/57\n",
            "50/50 [==============================] - 6s 125ms/step - loss: 0.1225 - accuracy: 0.9289 - val_loss: 0.1859 - val_accuracy: 0.8889\n",
            "Epoch 9/57\n",
            "50/50 [==============================] - 6s 124ms/step - loss: 0.1039 - accuracy: 0.9415 - val_loss: 0.1627 - val_accuracy: 0.9044\n",
            "Epoch 10/57\n",
            "50/50 [==============================] - 6s 125ms/step - loss: 0.0924 - accuracy: 0.9481 - val_loss: 0.2077 - val_accuracy: 0.9000\n",
            "Epoch 11/57\n",
            "50/50 [==============================] - 6s 125ms/step - loss: 0.0839 - accuracy: 0.9570 - val_loss: 0.1768 - val_accuracy: 0.8978\n",
            "Epoch 12/57\n",
            "50/50 [==============================] - 6s 125ms/step - loss: 0.0616 - accuracy: 0.9681 - val_loss: 0.1977 - val_accuracy: 0.8978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 07:41:28,717]\u001b[0m Trial 4 finished with value: 0.897777795791626 and parameters: {'epochs': 57, 'batch_size': 27, 'lr': 0.00024234978368931642}. Best is trial 3 with value: 0.8933333158493042.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/56\n",
            " 6/52 [==>...........................] - ETA: 5s - loss: 0.6881 - accuracy: 0.2885WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0454s vs `on_train_batch_end` time: 0.0683s). Check your callbacks.\n",
            "52/52 [==============================] - 7s 126ms/step - loss: 0.5206 - accuracy: 0.5674 - val_loss: 0.3580 - val_accuracy: 0.7644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 07:41:41,411]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/62\n",
            " 6/54 [==>...........................] - ETA: 5s - loss: 0.6853 - accuracy: 0.3600WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0162s vs `on_train_batch_end` time: 0.0890s). Check your callbacks.\n",
            "54/54 [==============================] - 7s 123ms/step - loss: 0.6386 - accuracy: 0.4704 - val_loss: 0.5982 - val_accuracy: 0.6689\n",
            "Epoch 2/62\n",
            "54/54 [==============================] - 6s 117ms/step - loss: 0.5659 - accuracy: 0.5844 - val_loss: 0.4844 - val_accuracy: 0.6956\n",
            "Epoch 3/62\n",
            "54/54 [==============================] - 6s 118ms/step - loss: 0.4628 - accuracy: 0.6852 - val_loss: 0.4177 - val_accuracy: 0.6444\n",
            "Epoch 4/62\n",
            "54/54 [==============================] - 6s 118ms/step - loss: 0.4284 - accuracy: 0.6852 - val_loss: 0.3696 - val_accuracy: 0.7467\n",
            "Epoch 5/62\n",
            "54/54 [==============================] - 6s 118ms/step - loss: 0.4052 - accuracy: 0.6963 - val_loss: 0.3565 - val_accuracy: 0.7622\n",
            "Epoch 6/62\n",
            "54/54 [==============================] - 6s 118ms/step - loss: 0.3911 - accuracy: 0.7178 - val_loss: 0.3449 - val_accuracy: 0.7600\n",
            "Epoch 7/62\n",
            "54/54 [==============================] - 6s 117ms/step - loss: 0.3739 - accuracy: 0.7378 - val_loss: 0.3423 - val_accuracy: 0.7600\n",
            "Epoch 8/62\n",
            "54/54 [==============================] - 6s 117ms/step - loss: 0.3657 - accuracy: 0.7533 - val_loss: 0.3268 - val_accuracy: 0.7556\n",
            "Epoch 9/62\n",
            "54/54 [==============================] - 6s 117ms/step - loss: 0.3446 - accuracy: 0.7652 - val_loss: 0.3096 - val_accuracy: 0.7733\n",
            "Epoch 10/62\n",
            "54/54 [==============================] - 6s 119ms/step - loss: 0.3356 - accuracy: 0.7689 - val_loss: 0.3017 - val_accuracy: 0.7822\n",
            "Epoch 11/62\n",
            "54/54 [==============================] - 6s 119ms/step - loss: 0.3205 - accuracy: 0.7881 - val_loss: 0.2894 - val_accuracy: 0.7778\n",
            "Epoch 12/62\n",
            "54/54 [==============================] - 6s 117ms/step - loss: 0.3080 - accuracy: 0.7896 - val_loss: 0.2820 - val_accuracy: 0.7933\n",
            "Epoch 13/62\n",
            "54/54 [==============================] - 6s 120ms/step - loss: 0.3008 - accuracy: 0.7933 - val_loss: 0.2692 - val_accuracy: 0.8111\n",
            "Epoch 14/62\n",
            "54/54 [==============================] - 6s 119ms/step - loss: 0.2916 - accuracy: 0.8074 - val_loss: 0.2665 - val_accuracy: 0.8200\n",
            "Epoch 15/62\n",
            "54/54 [==============================] - 6s 118ms/step - loss: 0.2759 - accuracy: 0.8170 - val_loss: 0.2485 - val_accuracy: 0.8178\n",
            "Epoch 16/62\n",
            "54/54 [==============================] - 6s 118ms/step - loss: 0.2628 - accuracy: 0.8319 - val_loss: 0.2387 - val_accuracy: 0.8511\n",
            "Epoch 17/62\n",
            "54/54 [==============================] - 6s 118ms/step - loss: 0.2513 - accuracy: 0.8467 - val_loss: 0.2281 - val_accuracy: 0.8622\n",
            "Epoch 18/62\n",
            "54/54 [==============================] - 6s 118ms/step - loss: 0.2428 - accuracy: 0.8548 - val_loss: 0.2196 - val_accuracy: 0.8556\n",
            "Epoch 19/62\n",
            "54/54 [==============================] - 6s 117ms/step - loss: 0.2324 - accuracy: 0.8615 - val_loss: 0.2085 - val_accuracy: 0.8667\n",
            "Epoch 20/62\n",
            "54/54 [==============================] - 6s 118ms/step - loss: 0.2197 - accuracy: 0.8822 - val_loss: 0.2117 - val_accuracy: 0.8711\n",
            "Epoch 21/62\n",
            "54/54 [==============================] - 6s 119ms/step - loss: 0.2009 - accuracy: 0.8867 - val_loss: 0.2052 - val_accuracy: 0.8733\n",
            "Epoch 22/62\n",
            "54/54 [==============================] - 6s 118ms/step - loss: 0.2088 - accuracy: 0.8770 - val_loss: 0.1963 - val_accuracy: 0.8844\n",
            "Epoch 23/62\n",
            "54/54 [==============================] - 6s 118ms/step - loss: 0.1976 - accuracy: 0.8874 - val_loss: 0.1901 - val_accuracy: 0.8867\n",
            "Epoch 24/62\n",
            "54/54 [==============================] - 6s 119ms/step - loss: 0.1914 - accuracy: 0.8956 - val_loss: 0.2036 - val_accuracy: 0.8711\n",
            "Epoch 25/62\n",
            "54/54 [==============================] - 6s 119ms/step - loss: 0.1959 - accuracy: 0.8881 - val_loss: 0.1881 - val_accuracy: 0.8867\n",
            "Epoch 26/62\n",
            "54/54 [==============================] - 6s 119ms/step - loss: 0.1848 - accuracy: 0.8948 - val_loss: 0.1967 - val_accuracy: 0.8822\n",
            "Epoch 27/62\n",
            "54/54 [==============================] - 6s 118ms/step - loss: 0.1789 - accuracy: 0.8956 - val_loss: 0.1916 - val_accuracy: 0.8844\n",
            "Epoch 28/62\n",
            "54/54 [==============================] - 6s 118ms/step - loss: 0.1705 - accuracy: 0.9030 - val_loss: 0.1855 - val_accuracy: 0.8889\n",
            "Epoch 29/62\n",
            "54/54 [==============================] - 6s 118ms/step - loss: 0.1618 - accuracy: 0.9178 - val_loss: 0.2028 - val_accuracy: 0.8711\n",
            "Epoch 30/62\n",
            "54/54 [==============================] - 6s 118ms/step - loss: 0.1624 - accuracy: 0.9148 - val_loss: 0.2164 - val_accuracy: 0.8756\n",
            "Epoch 31/62\n",
            "54/54 [==============================] - 6s 117ms/step - loss: 0.1625 - accuracy: 0.9126 - val_loss: 0.1874 - val_accuracy: 0.8844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 07:45:10,565]\u001b[0m Trial 6 finished with value: 0.8844444155693054 and parameters: {'epochs': 62, 'batch_size': 25, 'lr': 1.2019134258427792e-05}. Best is trial 6 with value: 0.8844444155693054.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/57\n",
            " 6/49 [==>...........................] - ETA: 5s - loss: 0.6658 - accuracy: 0.3393WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0445s vs `on_train_batch_end` time: 0.0754s). Check your callbacks.\n",
            "49/49 [==============================] - 7s 131ms/step - loss: 0.6051 - accuracy: 0.5104 - val_loss: 0.5009 - val_accuracy: 0.6444\n",
            "Epoch 2/57\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.4587 - accuracy: 0.6674 - val_loss: 0.4126 - val_accuracy: 0.6467\n",
            "Epoch 3/57\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 0.4076 - accuracy: 0.6963 - val_loss: 0.3528 - val_accuracy: 0.7467\n",
            "Epoch 4/57\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.3786 - accuracy: 0.7267 - val_loss: 0.3247 - val_accuracy: 0.7667\n",
            "Epoch 5/57\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.3492 - accuracy: 0.7563 - val_loss: 0.3302 - val_accuracy: 0.7733\n",
            "Epoch 6/57\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 0.3176 - accuracy: 0.7800 - val_loss: 0.2690 - val_accuracy: 0.8133\n",
            "Epoch 7/57\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.2923 - accuracy: 0.8052 - val_loss: 0.2517 - val_accuracy: 0.8578\n",
            "Epoch 8/57\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.2669 - accuracy: 0.8385 - val_loss: 0.2280 - val_accuracy: 0.8689\n",
            "Epoch 9/57\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.2419 - accuracy: 0.8511 - val_loss: 0.2180 - val_accuracy: 0.8756\n",
            "Epoch 10/57\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.2218 - accuracy: 0.8719 - val_loss: 0.2323 - val_accuracy: 0.8444\n",
            "Epoch 11/57\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 0.2089 - accuracy: 0.8807 - val_loss: 0.2187 - val_accuracy: 0.8756\n",
            "Epoch 12/57\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.1972 - accuracy: 0.8889 - val_loss: 0.1943 - val_accuracy: 0.8800\n",
            "Epoch 13/57\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 0.1908 - accuracy: 0.8881 - val_loss: 0.2069 - val_accuracy: 0.8667\n",
            "Epoch 14/57\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.1736 - accuracy: 0.9022 - val_loss: 0.1877 - val_accuracy: 0.8889\n",
            "Epoch 15/57\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.1629 - accuracy: 0.9059 - val_loss: 0.1901 - val_accuracy: 0.8800\n",
            "Epoch 16/57\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.1572 - accuracy: 0.9193 - val_loss: 0.1763 - val_accuracy: 0.8844\n",
            "Epoch 17/57\n",
            "49/49 [==============================] - 6s 123ms/step - loss: 0.1599 - accuracy: 0.9000 - val_loss: 0.1727 - val_accuracy: 0.8756\n",
            "Epoch 18/57\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.1377 - accuracy: 0.9252 - val_loss: 0.2190 - val_accuracy: 0.8578\n",
            "Epoch 19/57\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.1342 - accuracy: 0.9304 - val_loss: 0.1805 - val_accuracy: 0.8889\n",
            "Epoch 20/57\n",
            "49/49 [==============================] - 6s 124ms/step - loss: 0.1259 - accuracy: 0.9289 - val_loss: 0.1838 - val_accuracy: 0.8822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 07:47:39,294]\u001b[0m Trial 7 finished with value: 0.8822222352027893 and parameters: {'epochs': 57, 'batch_size': 28, 'lr': 3.25850383845482e-05}. Best is trial 7 with value: 0.8822222352027893.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/52\n",
            " 6/44 [===>..........................] - ETA: 4s - loss: 0.6531 - accuracy: 0.3548WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0472s vs `on_train_batch_end` time: 0.0604s). Check your callbacks.\n",
            "44/44 [==============================] - 10s 165ms/step - loss: 0.5689 - accuracy: 0.5237 - val_loss: 0.4168 - val_accuracy: 0.6822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 07:47:54,938]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/57\n",
            " 6/49 [==>...........................] - ETA: 4s - loss: 0.6613 - accuracy: 0.3095WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0436s vs `on_train_batch_end` time: 0.0670s). Check your callbacks.\n",
            "49/49 [==============================] - 7s 130ms/step - loss: 0.5741 - accuracy: 0.5222 - val_loss: 0.4109 - val_accuracy: 0.6800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 07:48:07,415]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            " 6/44 [===>..........................] - ETA: 4s - loss: 0.6879 - accuracy: 0.3226WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0472s vs `on_train_batch_end` time: 0.0783s). Check your callbacks.\n",
            "44/44 [==============================] - 7s 141ms/step - loss: 0.6504 - accuracy: 0.4244 - val_loss: 0.6179 - val_accuracy: 0.6133\n",
            "Epoch 2/70\n",
            "44/44 [==============================] - 6s 131ms/step - loss: 0.6017 - accuracy: 0.5793 - val_loss: 0.5632 - val_accuracy: 0.6311\n",
            "Epoch 3/70\n",
            "44/44 [==============================] - 6s 130ms/step - loss: 0.5194 - accuracy: 0.6496 - val_loss: 0.4330 - val_accuracy: 0.7444\n",
            "Epoch 4/70\n",
            "44/44 [==============================] - 6s 131ms/step - loss: 0.4409 - accuracy: 0.6956 - val_loss: 0.3815 - val_accuracy: 0.7089\n",
            "Epoch 5/70\n",
            "44/44 [==============================] - 6s 134ms/step - loss: 0.4115 - accuracy: 0.6926 - val_loss: 0.3543 - val_accuracy: 0.7333\n",
            "Epoch 6/70\n",
            "44/44 [==============================] - 6s 133ms/step - loss: 0.3920 - accuracy: 0.7296 - val_loss: 0.3440 - val_accuracy: 0.7489\n",
            "Epoch 7/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.3776 - accuracy: 0.7252 - val_loss: 0.3279 - val_accuracy: 0.7533\n",
            "Epoch 8/70\n",
            "44/44 [==============================] - 6s 131ms/step - loss: 0.3588 - accuracy: 0.7393 - val_loss: 0.3361 - val_accuracy: 0.7200\n",
            "Epoch 9/70\n",
            "44/44 [==============================] - 6s 131ms/step - loss: 0.3460 - accuracy: 0.7541 - val_loss: 0.3153 - val_accuracy: 0.7711\n",
            "Epoch 10/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.3356 - accuracy: 0.7726 - val_loss: 0.2901 - val_accuracy: 0.7889\n",
            "Epoch 11/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.3178 - accuracy: 0.7830 - val_loss: 0.2779 - val_accuracy: 0.8044\n",
            "Epoch 12/70\n",
            "44/44 [==============================] - 6s 131ms/step - loss: 0.3115 - accuracy: 0.7881 - val_loss: 0.2807 - val_accuracy: 0.8156\n",
            "Epoch 13/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.2983 - accuracy: 0.8000 - val_loss: 0.2572 - val_accuracy: 0.8244\n",
            "Epoch 14/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.2819 - accuracy: 0.8252 - val_loss: 0.2400 - val_accuracy: 0.8333\n",
            "Epoch 15/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.2709 - accuracy: 0.8252 - val_loss: 0.2278 - val_accuracy: 0.8667\n",
            "Epoch 16/70\n",
            "44/44 [==============================] - 6s 133ms/step - loss: 0.2560 - accuracy: 0.8422 - val_loss: 0.2223 - val_accuracy: 0.8556\n",
            "Epoch 17/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.2485 - accuracy: 0.8504 - val_loss: 0.2161 - val_accuracy: 0.8622\n",
            "Epoch 18/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.2357 - accuracy: 0.8541 - val_loss: 0.2172 - val_accuracy: 0.8644\n",
            "Epoch 19/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.2320 - accuracy: 0.8548 - val_loss: 0.2059 - val_accuracy: 0.8667\n",
            "Epoch 20/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.2285 - accuracy: 0.8659 - val_loss: 0.2159 - val_accuracy: 0.8711\n",
            "Epoch 21/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.2224 - accuracy: 0.8704 - val_loss: 0.2018 - val_accuracy: 0.8756\n",
            "Epoch 22/70\n",
            "44/44 [==============================] - 6s 133ms/step - loss: 0.2102 - accuracy: 0.8741 - val_loss: 0.1960 - val_accuracy: 0.8733\n",
            "Epoch 23/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.2086 - accuracy: 0.8852 - val_loss: 0.1950 - val_accuracy: 0.8822\n",
            "Epoch 24/70\n",
            "44/44 [==============================] - 6s 131ms/step - loss: 0.2000 - accuracy: 0.8822 - val_loss: 0.1937 - val_accuracy: 0.8844\n",
            "Epoch 25/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.1910 - accuracy: 0.8963 - val_loss: 0.1915 - val_accuracy: 0.8756\n",
            "Epoch 26/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.1806 - accuracy: 0.8978 - val_loss: 0.1887 - val_accuracy: 0.8778\n",
            "Epoch 27/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.1812 - accuracy: 0.9022 - val_loss: 0.2257 - val_accuracy: 0.8444\n",
            "Epoch 28/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.1834 - accuracy: 0.8956 - val_loss: 0.1997 - val_accuracy: 0.8756\n",
            "Epoch 29/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.1658 - accuracy: 0.9156 - val_loss: 0.1849 - val_accuracy: 0.8844\n",
            "Epoch 30/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.1577 - accuracy: 0.9259 - val_loss: 0.1900 - val_accuracy: 0.8867\n",
            "Epoch 31/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.1624 - accuracy: 0.9059 - val_loss: 0.1978 - val_accuracy: 0.8778\n",
            "Epoch 32/70\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.1577 - accuracy: 0.9163 - val_loss: 0.1850 - val_accuracy: 0.8867\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 07:51:40,487]\u001b[0m Trial 10 finished with value: 0.8866666555404663 and parameters: {'epochs': 70, 'batch_size': 31, 'lr': 1.3514879518125936e-05}. Best is trial 7 with value: 0.8822222352027893.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/65\n",
            " 6/57 [==>...........................] - ETA: 5s - loss: 0.6929 - accuracy: 0.3333WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0442s vs `on_train_batch_end` time: 0.0620s). Check your callbacks.\n",
            "57/57 [==============================] - 8s 126ms/step - loss: 0.6530 - accuracy: 0.3615 - val_loss: 0.6172 - val_accuracy: 0.5311\n",
            "Epoch 2/65\n",
            "57/57 [==============================] - 7s 118ms/step - loss: 0.5977 - accuracy: 0.5548 - val_loss: 0.5452 - val_accuracy: 0.7156\n",
            "Epoch 3/65\n",
            "57/57 [==============================] - 7s 119ms/step - loss: 0.5107 - accuracy: 0.6489 - val_loss: 0.4292 - val_accuracy: 0.7222\n",
            "Epoch 4/65\n",
            "57/57 [==============================] - 7s 118ms/step - loss: 0.4395 - accuracy: 0.6822 - val_loss: 0.3757 - val_accuracy: 0.7533\n",
            "Epoch 5/65\n",
            "57/57 [==============================] - 7s 121ms/step - loss: 0.4131 - accuracy: 0.7059 - val_loss: 0.3657 - val_accuracy: 0.7356\n",
            "Epoch 6/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.3936 - accuracy: 0.7015 - val_loss: 0.3639 - val_accuracy: 0.7467\n",
            "Epoch 7/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.3879 - accuracy: 0.7244 - val_loss: 0.3434 - val_accuracy: 0.7311\n",
            "Epoch 8/65\n",
            "57/57 [==============================] - 7s 121ms/step - loss: 0.3702 - accuracy: 0.7348 - val_loss: 0.3263 - val_accuracy: 0.7756\n",
            "Epoch 9/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.3614 - accuracy: 0.7452 - val_loss: 0.3270 - val_accuracy: 0.7711\n",
            "Epoch 10/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.3498 - accuracy: 0.7570 - val_loss: 0.3100 - val_accuracy: 0.7800\n",
            "Epoch 11/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.3355 - accuracy: 0.7748 - val_loss: 0.3099 - val_accuracy: 0.7667\n",
            "Epoch 12/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.3256 - accuracy: 0.7852 - val_loss: 0.2950 - val_accuracy: 0.7822\n",
            "Epoch 13/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.3219 - accuracy: 0.7807 - val_loss: 0.2976 - val_accuracy: 0.7822\n",
            "Epoch 14/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.3079 - accuracy: 0.7926 - val_loss: 0.2729 - val_accuracy: 0.8111\n",
            "Epoch 15/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.2999 - accuracy: 0.8096 - val_loss: 0.2613 - val_accuracy: 0.8200\n",
            "Epoch 16/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.2987 - accuracy: 0.8000 - val_loss: 0.2652 - val_accuracy: 0.8289\n",
            "Epoch 17/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.2785 - accuracy: 0.8222 - val_loss: 0.2414 - val_accuracy: 0.8333\n",
            "Epoch 18/65\n",
            "57/57 [==============================] - 7s 119ms/step - loss: 0.2683 - accuracy: 0.8281 - val_loss: 0.2454 - val_accuracy: 0.8467\n",
            "Epoch 19/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.2615 - accuracy: 0.8407 - val_loss: 0.2281 - val_accuracy: 0.8489\n",
            "Epoch 20/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.2455 - accuracy: 0.8659 - val_loss: 0.2278 - val_accuracy: 0.8578\n",
            "Epoch 21/65\n",
            "57/57 [==============================] - 7s 121ms/step - loss: 0.2369 - accuracy: 0.8570 - val_loss: 0.2169 - val_accuracy: 0.8778\n",
            "Epoch 22/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.2360 - accuracy: 0.8570 - val_loss: 0.2135 - val_accuracy: 0.8600\n",
            "Epoch 23/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.2265 - accuracy: 0.8681 - val_loss: 0.2390 - val_accuracy: 0.8467\n",
            "Epoch 24/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.2212 - accuracy: 0.8681 - val_loss: 0.2138 - val_accuracy: 0.8622\n",
            "Epoch 25/65\n",
            "57/57 [==============================] - 7s 119ms/step - loss: 0.2184 - accuracy: 0.8748 - val_loss: 0.1986 - val_accuracy: 0.8822\n",
            "Epoch 26/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.2065 - accuracy: 0.8830 - val_loss: 0.2106 - val_accuracy: 0.8667\n",
            "Epoch 27/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.2039 - accuracy: 0.8919 - val_loss: 0.2022 - val_accuracy: 0.8667\n",
            "Epoch 28/65\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.1998 - accuracy: 0.8807 - val_loss: 0.2000 - val_accuracy: 0.8756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 07:54:58,969]\u001b[0m Trial 11 finished with value: 0.8755555748939514 and parameters: {'epochs': 65, 'batch_size': 24, 'lr': 1.0155934957231253e-05}. Best is trial 11 with value: 0.8755555748939514.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/66\n",
            " 6/57 [==>...........................] - ETA: 5s - loss: 0.6769 - accuracy: 0.3194WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0471s vs `on_train_batch_end` time: 0.0654s). Check your callbacks.\n",
            "57/57 [==============================] - 8s 126ms/step - loss: 0.6250 - accuracy: 0.4541 - val_loss: 0.5642 - val_accuracy: 0.6178\n",
            "Epoch 2/66\n",
            "57/57 [==============================] - 7s 119ms/step - loss: 0.5027 - accuracy: 0.6215 - val_loss: 0.4113 - val_accuracy: 0.7244\n",
            "Epoch 3/66\n",
            "57/57 [==============================] - 7s 119ms/step - loss: 0.4058 - accuracy: 0.7193 - val_loss: 0.3571 - val_accuracy: 0.7178\n",
            "Epoch 4/66\n",
            "57/57 [==============================] - 7s 119ms/step - loss: 0.3704 - accuracy: 0.7400 - val_loss: 0.3487 - val_accuracy: 0.7533\n",
            "Epoch 5/66\n",
            "57/57 [==============================] - 7s 118ms/step - loss: 0.3575 - accuracy: 0.7452 - val_loss: 0.3168 - val_accuracy: 0.7844\n",
            "Epoch 6/66\n",
            "57/57 [==============================] - 7s 118ms/step - loss: 0.3242 - accuracy: 0.7741 - val_loss: 0.3113 - val_accuracy: 0.7889\n",
            "Epoch 7/66\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.3048 - accuracy: 0.7926 - val_loss: 0.2635 - val_accuracy: 0.8222\n",
            "Epoch 8/66\n",
            "57/57 [==============================] - 7s 119ms/step - loss: 0.2714 - accuracy: 0.8348 - val_loss: 0.2321 - val_accuracy: 0.8533\n",
            "Epoch 9/66\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.2492 - accuracy: 0.8511 - val_loss: 0.2150 - val_accuracy: 0.8667\n",
            "Epoch 10/66\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.2379 - accuracy: 0.8519 - val_loss: 0.2115 - val_accuracy: 0.8756\n",
            "Epoch 11/66\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.2124 - accuracy: 0.8770 - val_loss: 0.2044 - val_accuracy: 0.8778\n",
            "Epoch 12/66\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.2023 - accuracy: 0.8837 - val_loss: 0.1995 - val_accuracy: 0.8711\n",
            "Epoch 13/66\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.1881 - accuracy: 0.8933 - val_loss: 0.1984 - val_accuracy: 0.8778\n",
            "Epoch 14/66\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.1848 - accuracy: 0.8911 - val_loss: 0.1876 - val_accuracy: 0.8822\n",
            "Epoch 15/66\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.1687 - accuracy: 0.9037 - val_loss: 0.1928 - val_accuracy: 0.8756\n",
            "Epoch 16/66\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.1589 - accuracy: 0.9119 - val_loss: 0.1870 - val_accuracy: 0.8778\n",
            "Epoch 17/66\n",
            "57/57 [==============================] - 7s 119ms/step - loss: 0.1485 - accuracy: 0.9215 - val_loss: 0.1831 - val_accuracy: 0.8844\n",
            "Epoch 18/66\n",
            "57/57 [==============================] - 7s 119ms/step - loss: 0.1507 - accuracy: 0.9163 - val_loss: 0.2021 - val_accuracy: 0.8733\n",
            "Epoch 19/66\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.1463 - accuracy: 0.9104 - val_loss: 0.1821 - val_accuracy: 0.8867\n",
            "Epoch 20/66\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.1282 - accuracy: 0.9356 - val_loss: 0.1886 - val_accuracy: 0.8822\n",
            "Epoch 21/66\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.1226 - accuracy: 0.9348 - val_loss: 0.1849 - val_accuracy: 0.8889\n",
            "Epoch 22/66\n",
            "57/57 [==============================] - 7s 120ms/step - loss: 0.1144 - accuracy: 0.9415 - val_loss: 0.1846 - val_accuracy: 0.8911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 07:58:28,295]\u001b[0m Trial 12 finished with value: 0.8911111354827881 and parameters: {'epochs': 66, 'batch_size': 24, 'lr': 2.4824227930676562e-05}. Best is trial 11 with value: 0.8755555748939514.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/63\n",
            " 6/45 [===>..........................] - ETA: 4s - loss: 0.6743 - accuracy: 0.3111WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0198s vs `on_train_batch_end` time: 0.1084s). Check your callbacks.\n",
            "45/45 [==============================] - 7s 142ms/step - loss: 0.6261 - accuracy: 0.4556 - val_loss: 0.5728 - val_accuracy: 0.5800\n",
            "Epoch 2/63\n",
            "45/45 [==============================] - 6s 129ms/step - loss: 0.5095 - accuracy: 0.6193 - val_loss: 0.4126 - val_accuracy: 0.6333\n",
            "Epoch 3/63\n",
            "45/45 [==============================] - 6s 129ms/step - loss: 0.4214 - accuracy: 0.7015 - val_loss: 0.3633 - val_accuracy: 0.7533\n",
            "Epoch 4/63\n",
            "45/45 [==============================] - 6s 132ms/step - loss: 0.3855 - accuracy: 0.7385 - val_loss: 0.3441 - val_accuracy: 0.7244\n",
            "Epoch 5/63\n",
            "45/45 [==============================] - 6s 132ms/step - loss: 0.3607 - accuracy: 0.7459 - val_loss: 0.3223 - val_accuracy: 0.7444\n",
            "Epoch 6/63\n",
            "45/45 [==============================] - 6s 132ms/step - loss: 0.3440 - accuracy: 0.7556 - val_loss: 0.2997 - val_accuracy: 0.7933\n",
            "Epoch 7/63\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 0.3150 - accuracy: 0.7985 - val_loss: 0.2936 - val_accuracy: 0.8089\n",
            "Epoch 8/63\n",
            "45/45 [==============================] - 6s 129ms/step - loss: 0.2889 - accuracy: 0.8170 - val_loss: 0.2459 - val_accuracy: 0.8289\n",
            "Epoch 9/63\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 0.2572 - accuracy: 0.8400 - val_loss: 0.2269 - val_accuracy: 0.8756\n",
            "Epoch 10/63\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 0.2515 - accuracy: 0.8430 - val_loss: 0.2153 - val_accuracy: 0.8667\n",
            "Epoch 11/63\n",
            "45/45 [==============================] - 6s 129ms/step - loss: 0.2330 - accuracy: 0.8667 - val_loss: 0.2064 - val_accuracy: 0.8667\n",
            "Epoch 12/63\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 0.2149 - accuracy: 0.8696 - val_loss: 0.1985 - val_accuracy: 0.8778\n",
            "Epoch 13/63\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 0.2080 - accuracy: 0.8711 - val_loss: 0.1949 - val_accuracy: 0.8800\n",
            "Epoch 14/63\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 0.1997 - accuracy: 0.8807 - val_loss: 0.1942 - val_accuracy: 0.8844\n",
            "Epoch 15/63\n",
            "45/45 [==============================] - 6s 129ms/step - loss: 0.1783 - accuracy: 0.8993 - val_loss: 0.1895 - val_accuracy: 0.8822\n",
            "Epoch 16/63\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 0.1748 - accuracy: 0.8978 - val_loss: 0.1848 - val_accuracy: 0.8756\n",
            "Epoch 17/63\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 0.1612 - accuracy: 0.9074 - val_loss: 0.1805 - val_accuracy: 0.8956\n",
            "Epoch 18/63\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 0.1465 - accuracy: 0.9185 - val_loss: 0.1787 - val_accuracy: 0.8889\n",
            "Epoch 19/63\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 0.1405 - accuracy: 0.9193 - val_loss: 0.1778 - val_accuracy: 0.8933\n",
            "Epoch 20/63\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 0.1326 - accuracy: 0.9274 - val_loss: 0.1766 - val_accuracy: 0.9044\n",
            "Epoch 21/63\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 0.1280 - accuracy: 0.9274 - val_loss: 0.1950 - val_accuracy: 0.8933\n",
            "Epoch 22/63\n",
            "45/45 [==============================] - 6s 130ms/step - loss: 0.1212 - accuracy: 0.9370 - val_loss: 0.2004 - val_accuracy: 0.8867\n",
            "Epoch 23/63\n",
            "45/45 [==============================] - 6s 133ms/step - loss: 0.1180 - accuracy: 0.9378 - val_loss: 0.1781 - val_accuracy: 0.8933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 08:00:51,577]\u001b[0m Trial 13 finished with value: 0.8933333158493042 and parameters: {'epochs': 63, 'batch_size': 30, 'lr': 2.6929311624997436e-05}. Best is trial 11 with value: 0.8755555748939514.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/47\n",
            " 6/47 [==>...........................] - ETA: 4s - loss: 0.6783 - accuracy: 0.3333WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0463s vs `on_train_batch_end` time: 0.0765s). Check your callbacks.\n",
            "47/47 [==============================] - 7s 137ms/step - loss: 0.6414 - accuracy: 0.3711 - val_loss: 0.6155 - val_accuracy: 0.6267\n",
            "Epoch 2/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.5992 - accuracy: 0.5704 - val_loss: 0.5583 - val_accuracy: 0.6156\n",
            "Epoch 3/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.5248 - accuracy: 0.6526 - val_loss: 0.4507 - val_accuracy: 0.6289\n",
            "Epoch 4/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.4527 - accuracy: 0.6785 - val_loss: 0.3977 - val_accuracy: 0.6822\n",
            "Epoch 5/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.4159 - accuracy: 0.6970 - val_loss: 0.3691 - val_accuracy: 0.7156\n",
            "Epoch 6/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.4063 - accuracy: 0.7037 - val_loss: 0.3532 - val_accuracy: 0.7600\n",
            "Epoch 7/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.3871 - accuracy: 0.7244 - val_loss: 0.3450 - val_accuracy: 0.7578\n",
            "Epoch 8/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.3859 - accuracy: 0.7326 - val_loss: 0.3372 - val_accuracy: 0.7511\n",
            "Epoch 9/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.3713 - accuracy: 0.7452 - val_loss: 0.3407 - val_accuracy: 0.7644\n",
            "Epoch 10/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.3575 - accuracy: 0.7474 - val_loss: 0.3212 - val_accuracy: 0.7689\n",
            "Epoch 11/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.3487 - accuracy: 0.7607 - val_loss: 0.3172 - val_accuracy: 0.7778\n",
            "Epoch 12/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.3405 - accuracy: 0.7615 - val_loss: 0.3036 - val_accuracy: 0.7822\n",
            "Epoch 13/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.3368 - accuracy: 0.7719 - val_loss: 0.2935 - val_accuracy: 0.8000\n",
            "Epoch 14/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.3194 - accuracy: 0.7852 - val_loss: 0.2873 - val_accuracy: 0.7911\n",
            "Epoch 15/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.3092 - accuracy: 0.7941 - val_loss: 0.2734 - val_accuracy: 0.8089\n",
            "Epoch 16/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.3001 - accuracy: 0.7933 - val_loss: 0.2720 - val_accuracy: 0.8156\n",
            "Epoch 17/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.2893 - accuracy: 0.8022 - val_loss: 0.2555 - val_accuracy: 0.8289\n",
            "Epoch 18/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.2815 - accuracy: 0.8148 - val_loss: 0.2408 - val_accuracy: 0.8333\n",
            "Epoch 19/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.2636 - accuracy: 0.8370 - val_loss: 0.2358 - val_accuracy: 0.8467\n",
            "Epoch 20/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.2581 - accuracy: 0.8393 - val_loss: 0.2248 - val_accuracy: 0.8600\n",
            "Epoch 21/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.2493 - accuracy: 0.8519 - val_loss: 0.2197 - val_accuracy: 0.8578\n",
            "Epoch 22/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.2329 - accuracy: 0.8630 - val_loss: 0.2205 - val_accuracy: 0.8667\n",
            "Epoch 23/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.2309 - accuracy: 0.8704 - val_loss: 0.2363 - val_accuracy: 0.8489\n",
            "Epoch 24/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.2300 - accuracy: 0.8667 - val_loss: 0.1995 - val_accuracy: 0.8733\n",
            "Epoch 25/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.2102 - accuracy: 0.8785 - val_loss: 0.1962 - val_accuracy: 0.8756\n",
            "Epoch 26/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.2048 - accuracy: 0.8807 - val_loss: 0.1965 - val_accuracy: 0.8822\n",
            "Epoch 27/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.2027 - accuracy: 0.8859 - val_loss: 0.1904 - val_accuracy: 0.8822\n",
            "Epoch 28/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.2028 - accuracy: 0.8859 - val_loss: 0.2055 - val_accuracy: 0.8644\n",
            "Epoch 29/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.1910 - accuracy: 0.8919 - val_loss: 0.1878 - val_accuracy: 0.8844\n",
            "Epoch 30/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.1931 - accuracy: 0.8859 - val_loss: 0.1969 - val_accuracy: 0.8800\n",
            "Epoch 31/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.1800 - accuracy: 0.8985 - val_loss: 0.1942 - val_accuracy: 0.8844\n",
            "Epoch 32/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.1765 - accuracy: 0.9007 - val_loss: 0.1819 - val_accuracy: 0.8889\n",
            "Epoch 33/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.1666 - accuracy: 0.9052 - val_loss: 0.1854 - val_accuracy: 0.8867\n",
            "Epoch 34/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.1726 - accuracy: 0.9007 - val_loss: 0.1816 - val_accuracy: 0.8889\n",
            "Epoch 35/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.1669 - accuracy: 0.9074 - val_loss: 0.1771 - val_accuracy: 0.8911\n",
            "Epoch 36/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.1570 - accuracy: 0.9163 - val_loss: 0.1757 - val_accuracy: 0.8933\n",
            "Epoch 37/47\n",
            "47/47 [==============================] - 6s 127ms/step - loss: 0.1534 - accuracy: 0.9185 - val_loss: 0.1760 - val_accuracy: 0.8889\n",
            "Epoch 38/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.1465 - accuracy: 0.9215 - val_loss: 0.1802 - val_accuracy: 0.8933\n",
            "Epoch 39/47\n",
            "47/47 [==============================] - 6s 128ms/step - loss: 0.1494 - accuracy: 0.9067 - val_loss: 0.1961 - val_accuracy: 0.8711\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 08:05:20,571]\u001b[0m Trial 14 finished with value: 0.8711110949516296 and parameters: {'epochs': 47, 'batch_size': 29, 'lr': 1.0102596468396399e-05}. Best is trial 14 with value: 0.8711110949516296.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  15\n",
            "  Number of pruned trials:  3\n",
            "  Number of complete trials:  12\n",
            "Best trial:\n",
            "  Value:  0.8711110949516296\n",
            "  Params: \n",
            "    epochs: 47\n",
            "    batch_size: 29\n",
            "    lr: 1.0102596468396399e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "6nmiWfTTU1A_",
        "outputId": "bd8a585f-aa73-4b49-a0e5-ddc2949b794f"
      },
      "source": [
        "\n",
        "optuna.visualization.plot_optimization_history(study1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"0118d3a1-aeb4-4613-8fa7-cf1aaa097dd6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"0118d3a1-aeb4-4613-8fa7-cf1aaa097dd6\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '0118d3a1-aeb4-4613-8fa7-cf1aaa097dd6',\n",
              "                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 6, 7, 10, 11, 12, 13, 14], \"y\": [0.8955555558204651, 0.897777795791626, 0.9133333563804626, 0.8933333158493042, 0.897777795791626, 0.8844444155693054, 0.8822222352027893, 0.8866666555404663, 0.8755555748939514, 0.8911111354827881, 0.8933333158493042, 0.8711110949516296]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 6, 7, 10, 11, 12, 13, 14], \"y\": [0.8955555558204651, 0.8955555558204651, 0.8955555558204651, 0.8933333158493042, 0.8933333158493042, 0.8844444155693054, 0.8822222352027893, 0.8822222352027893, 0.8755555748939514, 0.8755555748939514, 0.8755555748939514, 0.8711110949516296]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0118d3a1-aeb4-4613-8fa7-cf1aaa097dd6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "e9BDOXm6U1LJ",
        "outputId": "63938c17-db32-4df9-b91a-b659b1da3705"
      },
      "source": [
        "optuna.visualization.plot_intermediate_values(study1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"a148b604-aab9-41dc-84e8-8b0eeec3c356\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"a148b604-aab9-41dc-84e8-8b0eeec3c356\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'a148b604-aab9-41dc-84e8-8b0eeec3c356',\n",
              "                        [{\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial0\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], \"y\": [0.6222222447395325, 0.7044444680213928, 0.7511110901832581, 0.7711111307144165, 0.8222222328186035, 0.8488888740539551, 0.8444444537162781, 0.8644444346427917, 0.8666666746139526, 0.8799999952316284, 0.8799999952316284, 0.8822222352027893, 0.8799999952316284, 0.8888888955116272, 0.8955555558204651]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial1\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.8066666722297668, 0.8422222137451172, 0.8822222352027893, 0.8777777552604675, 0.8911111354827881, 0.8999999761581421, 0.9177777767181396, 0.8999999761581421, 0.902222216129303, 0.897777795791626]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial2\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"y\": [0.6711111068725586, 0.7955555319786072, 0.8355555534362793, 0.846666693687439, 0.8444444537162781, 0.8711110949516296, 0.8955555558204651, 0.897777795791626, 0.902222216129303, 0.8933333158493042, 0.8955555558204651, 0.9133333563804626]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial3\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], \"y\": [0.6355555653572083, 0.8222222328186035, 0.8377777934074402, 0.8644444346427917, 0.8755555748939514, 0.8866666555404663, 0.8799999952316284, 0.8733333349227905, 0.8999999761581421, 0.9066666960716248, 0.9044444561004639, 0.902222216129303, 0.8933333158493042]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial4\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"y\": [0.757777750492096, 0.8066666722297668, 0.8644444346427917, 0.8577777743339539, 0.8799999952316284, 0.8288888931274414, 0.8933333158493042, 0.8888888955116272, 0.9044444561004639, 0.8999999761581421, 0.897777795791626, 0.897777795791626]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial5\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.7644444704055786]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial6\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], \"y\": [0.6688888669013977, 0.695555567741394, 0.644444465637207, 0.746666669845581, 0.7622222304344177, 0.7599999904632568, 0.7599999904632568, 0.7555555701255798, 0.7733333110809326, 0.7822222113609314, 0.7777777910232544, 0.7933333516120911, 0.8111110925674438, 0.8199999928474426, 0.8177777528762817, 0.851111114025116, 0.8622221946716309, 0.855555534362793, 0.8666666746139526, 0.8711110949516296, 0.8733333349227905, 0.8844444155693054, 0.8866666555404663, 0.8711110949516296, 0.8866666555404663, 0.8822222352027893, 0.8844444155693054, 0.8888888955116272, 0.8711110949516296, 0.8755555748939514, 0.8844444155693054]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial7\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0.644444465637207, 0.6466666460037231, 0.746666669845581, 0.7666666507720947, 0.7733333110809326, 0.8133333325386047, 0.8577777743339539, 0.8688889145851135, 0.8755555748939514, 0.8444444537162781, 0.8755555748939514, 0.8799999952316284, 0.8666666746139526, 0.8888888955116272, 0.8799999952316284, 0.8844444155693054, 0.8755555748939514, 0.8577777743339539, 0.8888888955116272, 0.8822222352027893]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial8\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.6822222471237183]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial9\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.6800000071525574]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial10\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], \"y\": [0.6133333444595337, 0.6311110854148865, 0.7444444298744202, 0.7088888883590698, 0.7333333492279053, 0.7488889098167419, 0.753333330154419, 0.7200000286102295, 0.7711111307144165, 0.7888888716697693, 0.804444432258606, 0.8155555725097656, 0.8244444727897644, 0.8333333134651184, 0.8666666746139526, 0.855555534362793, 0.8622221946716309, 0.8644444346427917, 0.8666666746139526, 0.8711110949516296, 0.8755555748939514, 0.8733333349227905, 0.8822222352027893, 0.8844444155693054, 0.8755555748939514, 0.8777777552604675, 0.8444444537162781, 0.8755555748939514, 0.8844444155693054, 0.8866666555404663, 0.8777777552604675, 0.8866666555404663]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial11\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], \"y\": [0.5311111211776733, 0.7155555486679077, 0.7222222089767456, 0.753333330154419, 0.7355555295944214, 0.746666669845581, 0.7311111092567444, 0.7755555510520935, 0.7711111307144165, 0.7799999713897705, 0.7666666507720947, 0.7822222113609314, 0.7822222113609314, 0.8111110925674438, 0.8199999928474426, 0.8288888931274414, 0.8333333134651184, 0.846666693687439, 0.8488888740539551, 0.8577777743339539, 0.8777777552604675, 0.8600000143051147, 0.846666693687439, 0.8622221946716309, 0.8822222352027893, 0.8666666746139526, 0.8666666746139526, 0.8755555748939514]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial12\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], \"y\": [0.6177777647972107, 0.7244444489479065, 0.7177777886390686, 0.753333330154419, 0.7844444513320923, 0.7888888716697693, 0.8222222328186035, 0.8533333539962769, 0.8666666746139526, 0.8755555748939514, 0.8777777552604675, 0.8711110949516296, 0.8777777552604675, 0.8822222352027893, 0.8755555748939514, 0.8777777552604675, 0.8844444155693054, 0.8733333349227905, 0.8866666555404663, 0.8822222352027893, 0.8888888955116272, 0.8911111354827881]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial13\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"y\": [0.5799999833106995, 0.6333333253860474, 0.753333330154419, 0.7244444489479065, 0.7444444298744202, 0.7933333516120911, 0.8088889122009277, 0.8288888931274414, 0.8755555748939514, 0.8666666746139526, 0.8666666746139526, 0.8777777552604675, 0.8799999952316284, 0.8844444155693054, 0.8822222352027893, 0.8755555748939514, 0.8955555558204651, 0.8888888955116272, 0.8933333158493042, 0.9044444561004639, 0.8933333158493042, 0.8866666555404663, 0.8933333158493042]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial14\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38], \"y\": [0.6266666650772095, 0.6155555844306946, 0.6288889050483704, 0.6822222471237183, 0.7155555486679077, 0.7599999904632568, 0.757777750492096, 0.7511110901832581, 0.7644444704055786, 0.7688888907432556, 0.7777777910232544, 0.7822222113609314, 0.800000011920929, 0.7911111116409302, 0.8088889122009277, 0.8155555725097656, 0.8288888931274414, 0.8333333134651184, 0.846666693687439, 0.8600000143051147, 0.8577777743339539, 0.8666666746139526, 0.8488888740539551, 0.8733333349227905, 0.8755555748939514, 0.8822222352027893, 0.8822222352027893, 0.8644444346427917, 0.8844444155693054, 0.8799999952316284, 0.8844444155693054, 0.8888888955116272, 0.8866666555404663, 0.8888888955116272, 0.8911111354827881, 0.8933333158493042, 0.8888888955116272, 0.8933333158493042, 0.8711110949516296]}],\n",
              "                        {\"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Intermediate Values Plot\"}, \"xaxis\": {\"title\": {\"text\": \"Step\"}}, \"yaxis\": {\"title\": {\"text\": \"Intermediate Value\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a148b604-aab9-41dc-84e8-8b0eeec3c356');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWn3gxyk9ayg"
      },
      "source": [
        "### MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI-apIjq9c5E"
      },
      "source": [
        "from tensorflow.keras.initializers import RandomNormal\n",
        "import tensorflow as tf\n",
        "LR = 0.0002194159278335913\n",
        "EPOCHS = 70\n",
        "BATCH_SIZE = 26\n",
        "dropout = 0.6886279251938925\n",
        "def cnn():\n",
        "    base_model1 = Xception(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    features1 = base_model1.output\n",
        "    ######################################################################################################\n",
        "\n",
        "    base_model2 = ResNet101(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    features2 = base_model2.output\n",
        "    ######################################################################################################\n",
        "\n",
        "    #base_model3 = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    #features3 = base_model3.output\n",
        "    conv=tf.keras.layers.concatenate([features1,features2]) #Concatenate the extracted features\n",
        "    ####################################################################################################\n",
        "\n",
        "    conv = Sequential()\n",
        "    #onv.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3))(concatenated))\n",
        "    conv.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "    conv.add(MaxPooling2D((2, 2), padding='same'))\n",
        "    conv.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "    conv.add(MaxPooling2D((2, 2), padding='same'))\n",
        "    conv.add(Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "    conv.add(MaxPooling2D((2, 2), padding='same'))\n",
        "    conv.add(Conv2D(256, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "    conv.add(MaxPooling2D((2, 2), padding='same'))\n",
        "    conv.add(Conv2D(512, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "    conv.add(MaxPooling2D((2, 2), padding='same'))\n",
        "    conv.add(Flatten())\n",
        "    conv.add(Dropout(rate=dropout))\n",
        "    conv.add(Dense(512, activation='relu'))\n",
        "    conv.add(Dropout(rate=dropout))\n",
        "    conv.add(Dense(64, activation='relu'))\n",
        "    conv.add(Dense(3, activation='sigmoid'))\n",
        "    return conv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt_SMVqzRqHZ",
        "outputId": "64c9e752-d65c-49ef-c38b-7cbc95525330"
      },
      "source": [
        "clear_session()\n",
        "conv = cnn()\n",
        "for layer in conv.layers:\n",
        "  layer.trainable = True\n",
        "\n",
        "\n",
        "LR = 0.0002194159278335913\n",
        "EPOCHS = 70\n",
        "BATCH_SIZE = 26\n",
        "dropout = 0.6886279251938925\n",
        "conv.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR, decay = LR/EPOCHS), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "#, decay = LR/EPOCHS\n",
        "history = conv.fit_generator(train_aug.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
        "                                    steps_per_epoch=len(X_train)//BATCH_SIZE,\n",
        "                                    validation_data=(X_test, y_test),\n",
        "                                    validation_steps=len(X_test)//BATCH_SIZE,\n",
        "                                    epochs=EPOCHS,\n",
        "                                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning:\n",
            "\n",
            "`Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "43/43 [==============================] - 17s 379ms/step - loss: 1.0870 - accuracy: 0.4004 - val_loss: 1.0544 - val_accuracy: 0.3360\n",
            "Epoch 2/70\n",
            "43/43 [==============================] - 14s 322ms/step - loss: 0.8587 - accuracy: 0.5732 - val_loss: 0.7259 - val_accuracy: 0.6507\n",
            "Epoch 3/70\n",
            "43/43 [==============================] - 14s 317ms/step - loss: 0.7244 - accuracy: 0.6342 - val_loss: 0.6460 - val_accuracy: 0.6533\n",
            "Epoch 4/70\n",
            "43/43 [==============================] - 14s 322ms/step - loss: 0.6700 - accuracy: 0.6521 - val_loss: 0.5801 - val_accuracy: 0.6907\n",
            "Epoch 5/70\n",
            "43/43 [==============================] - 14s 322ms/step - loss: 0.6156 - accuracy: 0.6806 - val_loss: 0.5593 - val_accuracy: 0.7573\n",
            "Epoch 6/70\n",
            "43/43 [==============================] - 14s 315ms/step - loss: 0.5732 - accuracy: 0.7425 - val_loss: 0.5372 - val_accuracy: 0.7013\n",
            "Epoch 7/70\n",
            "43/43 [==============================] - 14s 321ms/step - loss: 0.5526 - accuracy: 0.7643 - val_loss: 0.4663 - val_accuracy: 0.7867\n",
            "Epoch 8/70\n",
            "43/43 [==============================] - 14s 316ms/step - loss: 0.5078 - accuracy: 0.7871 - val_loss: 0.4135 - val_accuracy: 0.8293\n",
            "Epoch 9/70\n",
            "43/43 [==============================] - 14s 317ms/step - loss: 0.4771 - accuracy: 0.8062 - val_loss: 0.3993 - val_accuracy: 0.8560\n",
            "Epoch 10/70\n",
            "43/43 [==============================] - 14s 316ms/step - loss: 0.4482 - accuracy: 0.8135 - val_loss: 0.4260 - val_accuracy: 0.8240\n",
            "Epoch 11/70\n",
            "43/43 [==============================] - 14s 316ms/step - loss: 0.4552 - accuracy: 0.8271 - val_loss: 0.3730 - val_accuracy: 0.8507\n",
            "Epoch 12/70\n",
            "43/43 [==============================] - 14s 319ms/step - loss: 0.4150 - accuracy: 0.8262 - val_loss: 0.3472 - val_accuracy: 0.8560\n",
            "Epoch 13/70\n",
            "43/43 [==============================] - 14s 315ms/step - loss: 0.3845 - accuracy: 0.8480 - val_loss: 0.3611 - val_accuracy: 0.8427\n",
            "Epoch 14/70\n",
            "43/43 [==============================] - 14s 318ms/step - loss: 0.3963 - accuracy: 0.8317 - val_loss: 0.3541 - val_accuracy: 0.8453\n",
            "Epoch 15/70\n",
            "43/43 [==============================] - 14s 315ms/step - loss: 0.3439 - accuracy: 0.8590 - val_loss: 0.3254 - val_accuracy: 0.8640\n",
            "Epoch 16/70\n",
            "43/43 [==============================] - 13s 312ms/step - loss: 0.3922 - accuracy: 0.8335 - val_loss: 0.3486 - val_accuracy: 0.8480\n",
            "Epoch 17/70\n",
            "43/43 [==============================] - 14s 315ms/step - loss: 0.3428 - accuracy: 0.8617 - val_loss: 0.3423 - val_accuracy: 0.8693\n",
            "Epoch 18/70\n",
            "43/43 [==============================] - 14s 313ms/step - loss: 0.3274 - accuracy: 0.8635 - val_loss: 0.3571 - val_accuracy: 0.8613\n",
            "Epoch 19/70\n",
            "43/43 [==============================] - 14s 313ms/step - loss: 0.3068 - accuracy: 0.8844 - val_loss: 0.2639 - val_accuracy: 0.8933\n",
            "Epoch 20/70\n",
            "43/43 [==============================] - 14s 324ms/step - loss: 0.3105 - accuracy: 0.8775 - val_loss: 0.2865 - val_accuracy: 0.8933\n",
            "Epoch 21/70\n",
            "43/43 [==============================] - 14s 315ms/step - loss: 0.2838 - accuracy: 0.8917 - val_loss: 0.2675 - val_accuracy: 0.9013\n",
            "Epoch 22/70\n",
            "43/43 [==============================] - 14s 314ms/step - loss: 0.2975 - accuracy: 0.8808 - val_loss: 0.2624 - val_accuracy: 0.8933\n",
            "Epoch 23/70\n",
            "43/43 [==============================] - 14s 316ms/step - loss: 0.2498 - accuracy: 0.8963 - val_loss: 0.2607 - val_accuracy: 0.8987\n",
            "Epoch 24/70\n",
            "43/43 [==============================] - 14s 313ms/step - loss: 0.2188 - accuracy: 0.9108 - val_loss: 0.2609 - val_accuracy: 0.8933\n",
            "Epoch 25/70\n",
            "43/43 [==============================] - 14s 317ms/step - loss: 0.2318 - accuracy: 0.9081 - val_loss: 0.2548 - val_accuracy: 0.8960\n",
            "Epoch 26/70\n",
            "43/43 [==============================] - 14s 313ms/step - loss: 0.2652 - accuracy: 0.8926 - val_loss: 0.2401 - val_accuracy: 0.9093\n",
            "Epoch 27/70\n",
            "43/43 [==============================] - 14s 314ms/step - loss: 0.2225 - accuracy: 0.9099 - val_loss: 0.2680 - val_accuracy: 0.8987\n",
            "Epoch 28/70\n",
            "43/43 [==============================] - 14s 316ms/step - loss: 0.2334 - accuracy: 0.9035 - val_loss: 0.2948 - val_accuracy: 0.8853\n",
            "Epoch 29/70\n",
            "43/43 [==============================] - 14s 316ms/step - loss: 0.2288 - accuracy: 0.9017 - val_loss: 0.2717 - val_accuracy: 0.9013\n",
            "Epoch 30/70\n",
            "43/43 [==============================] - 14s 320ms/step - loss: 0.2051 - accuracy: 0.9347 - val_loss: 0.3135 - val_accuracy: 0.8933\n",
            "Epoch 31/70\n",
            "43/43 [==============================] - 14s 320ms/step - loss: 0.2000 - accuracy: 0.9159 - val_loss: 0.2755 - val_accuracy: 0.9040\n",
            "Epoch 32/70\n",
            "43/43 [==============================] - 14s 315ms/step - loss: 0.2162 - accuracy: 0.9136 - val_loss: 0.2554 - val_accuracy: 0.9093\n",
            "Epoch 33/70\n",
            "43/43 [==============================] - 14s 315ms/step - loss: 0.1893 - accuracy: 0.9172 - val_loss: 0.2388 - val_accuracy: 0.9067\n",
            "Epoch 34/70\n",
            "43/43 [==============================] - 13s 311ms/step - loss: 0.1905 - accuracy: 0.9272 - val_loss: 0.2196 - val_accuracy: 0.9120\n",
            "Epoch 35/70\n",
            "43/43 [==============================] - 14s 316ms/step - loss: 0.1654 - accuracy: 0.9381 - val_loss: 0.3193 - val_accuracy: 0.8853\n",
            "Epoch 36/70\n",
            "43/43 [==============================] - 13s 311ms/step - loss: 0.1705 - accuracy: 0.9299 - val_loss: 0.2508 - val_accuracy: 0.8987\n",
            "Epoch 37/70\n",
            "43/43 [==============================] - 14s 313ms/step - loss: 0.1618 - accuracy: 0.9354 - val_loss: 0.2905 - val_accuracy: 0.8853\n",
            "Epoch 38/70\n",
            "43/43 [==============================] - 14s 318ms/step - loss: 0.1564 - accuracy: 0.9418 - val_loss: 0.2473 - val_accuracy: 0.9120\n",
            "Epoch 39/70\n",
            "43/43 [==============================] - 14s 324ms/step - loss: 0.1727 - accuracy: 0.9409 - val_loss: 0.2465 - val_accuracy: 0.9173\n",
            "Epoch 40/70\n",
            "43/43 [==============================] - 14s 318ms/step - loss: 0.1544 - accuracy: 0.9354 - val_loss: 0.2975 - val_accuracy: 0.9040\n",
            "Epoch 41/70\n",
            "43/43 [==============================] - 14s 319ms/step - loss: 0.1575 - accuracy: 0.9454 - val_loss: 0.2904 - val_accuracy: 0.9013\n",
            "Epoch 42/70\n",
            "43/43 [==============================] - 14s 314ms/step - loss: 0.1678 - accuracy: 0.9418 - val_loss: 0.3088 - val_accuracy: 0.8933\n",
            "Epoch 43/70\n",
            "43/43 [==============================] - 14s 319ms/step - loss: 0.1474 - accuracy: 0.9363 - val_loss: 0.2684 - val_accuracy: 0.9120\n",
            "Epoch 44/70\n",
            "43/43 [==============================] - 14s 318ms/step - loss: 0.1190 - accuracy: 0.9518 - val_loss: 0.2670 - val_accuracy: 0.9093\n",
            "Epoch 45/70\n",
            "43/43 [==============================] - 14s 316ms/step - loss: 0.1282 - accuracy: 0.9490 - val_loss: 0.2249 - val_accuracy: 0.9227\n",
            "Epoch 46/70\n",
            "43/43 [==============================] - 14s 317ms/step - loss: 0.1346 - accuracy: 0.9509 - val_loss: 0.2978 - val_accuracy: 0.9040\n",
            "Epoch 47/70\n",
            "43/43 [==============================] - 14s 315ms/step - loss: 0.1046 - accuracy: 0.9554 - val_loss: 0.3137 - val_accuracy: 0.9040\n",
            "Epoch 48/70\n",
            "43/43 [==============================] - 14s 324ms/step - loss: 0.1212 - accuracy: 0.9572 - val_loss: 0.3286 - val_accuracy: 0.9067\n",
            "Epoch 49/70\n",
            "43/43 [==============================] - 14s 318ms/step - loss: 0.1031 - accuracy: 0.9609 - val_loss: 0.3160 - val_accuracy: 0.9013\n",
            "Epoch 50/70\n",
            "43/43 [==============================] - 14s 314ms/step - loss: 0.1086 - accuracy: 0.9618 - val_loss: 0.2551 - val_accuracy: 0.9173\n",
            "Epoch 51/70\n",
            "43/43 [==============================] - 14s 328ms/step - loss: 0.1031 - accuracy: 0.9682 - val_loss: 0.2476 - val_accuracy: 0.9333\n",
            "Epoch 52/70\n",
            "43/43 [==============================] - 14s 320ms/step - loss: 0.1082 - accuracy: 0.9627 - val_loss: 0.3279 - val_accuracy: 0.8933\n",
            "Epoch 53/70\n",
            "43/43 [==============================] - 14s 321ms/step - loss: 0.1056 - accuracy: 0.9600 - val_loss: 0.2567 - val_accuracy: 0.9307\n",
            "Epoch 54/70\n",
            "43/43 [==============================] - 14s 321ms/step - loss: 0.1111 - accuracy: 0.9509 - val_loss: 0.3174 - val_accuracy: 0.9067\n",
            "Epoch 55/70\n",
            "43/43 [==============================] - 14s 316ms/step - loss: 0.0864 - accuracy: 0.9709 - val_loss: 0.2718 - val_accuracy: 0.9307\n",
            "Epoch 56/70\n",
            "43/43 [==============================] - 14s 321ms/step - loss: 0.0795 - accuracy: 0.9736 - val_loss: 0.3315 - val_accuracy: 0.9067\n",
            "Epoch 57/70\n",
            "43/43 [==============================] - 14s 316ms/step - loss: 0.1078 - accuracy: 0.9581 - val_loss: 0.2829 - val_accuracy: 0.9307\n",
            "Epoch 58/70\n",
            "43/43 [==============================] - 14s 319ms/step - loss: 0.1172 - accuracy: 0.9591 - val_loss: 0.2671 - val_accuracy: 0.9147\n",
            "Epoch 59/70\n",
            "43/43 [==============================] - 14s 324ms/step - loss: 0.0902 - accuracy: 0.9627 - val_loss: 0.2770 - val_accuracy: 0.9227\n",
            "Epoch 60/70\n",
            "43/43 [==============================] - 14s 318ms/step - loss: 0.0962 - accuracy: 0.9672 - val_loss: 0.2855 - val_accuracy: 0.9200\n",
            "Epoch 61/70\n",
            "43/43 [==============================] - 14s 318ms/step - loss: 0.0858 - accuracy: 0.9718 - val_loss: 0.2717 - val_accuracy: 0.9360\n",
            "Epoch 62/70\n",
            "43/43 [==============================] - 14s 315ms/step - loss: 0.0885 - accuracy: 0.9709 - val_loss: 0.2502 - val_accuracy: 0.9200\n",
            "Epoch 63/70\n",
            "43/43 [==============================] - 14s 319ms/step - loss: 0.0756 - accuracy: 0.9709 - val_loss: 0.2868 - val_accuracy: 0.9253\n",
            "Epoch 64/70\n",
            "43/43 [==============================] - 14s 318ms/step - loss: 0.0730 - accuracy: 0.9736 - val_loss: 0.2569 - val_accuracy: 0.9253\n",
            "Epoch 65/70\n",
            "43/43 [==============================] - 14s 314ms/step - loss: 0.0869 - accuracy: 0.9745 - val_loss: 0.2900 - val_accuracy: 0.9120\n",
            "Epoch 66/70\n",
            "43/43 [==============================] - 13s 312ms/step - loss: 0.0722 - accuracy: 0.9745 - val_loss: 0.3138 - val_accuracy: 0.9093\n",
            "Epoch 67/70\n",
            "43/43 [==============================] - 14s 319ms/step - loss: 0.0775 - accuracy: 0.9682 - val_loss: 0.2732 - val_accuracy: 0.9280\n",
            "Epoch 68/70\n",
            "43/43 [==============================] - 14s 316ms/step - loss: 0.0817 - accuracy: 0.9654 - val_loss: 0.2751 - val_accuracy: 0.9333\n",
            "Epoch 69/70\n",
            "43/43 [==============================] - 14s 315ms/step - loss: 0.0862 - accuracy: 0.9709 - val_loss: 0.3183 - val_accuracy: 0.9093\n",
            "Epoch 70/70\n",
            "43/43 [==============================] - 13s 312ms/step - loss: 0.0866 - accuracy: 0.9627 - val_loss: 0.2721 - val_accuracy: 0.9227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRfBZqTuNuHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bff2ebe-1f9a-49e0-ead2-0352985317a0"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvRsiddINvqx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "4eaa594c-cf08-4f3d-e5f7-68a3125410b8"
      },
      "source": [
        "#Accuracy plot\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqI9chkjNxgm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "2cc26c67-64fc-4ff6-d9c3-3ec40387638e"
      },
      "source": [
        "#Loss plot\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnm9xpo2Nzdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0a2ceb1-27dc-45ac-911f-0ae1b59ce06c"
      },
      "source": [
        "score = conv.evaluate(X_test, y_test)\n",
        "print(\"Model accuracy on validation dataset: %f.\" %(score[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 1s 45ms/step - loss: 0.2910 - accuracy: 0.8844\n",
            "Model accuracy on validation dataset: 88.444442.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOaS5waSN1Mw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49b106f-2986-427e-d11c-dca6e0301295"
      },
      "source": [
        "y_pred = np.argmax(conv.predict(X_test), axis=1)\n",
        "print(y_pred)\n",
        "print(len(y_pred))\n",
        "print(le.classes_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 0 2 2 2 0 2 1 0 1 0 2 2 0 1 2 0 0 1 0 0 2 1 1 1 1 1 0 1 0 1 1 0 2 0 2 2\n",
            " 0 1 2 2 2 2 2 2 2 0 1 2 1 0 1 1 2 2 1 1 1 1 2 2 1 0 2 1 0 0 0 0 1 2 1 0 2\n",
            " 1 1 0 1 1 1 0 0 0 0 1 2 0 1 2 2 1 2 2 1 1 0 0 2 0 1 0 1 1 2 0 1 2 0 0 2 0\n",
            " 1 0 1 2 2 1 1 2 2 1 2 0 1 0 1 1 1 0 0 0 1 0 0 2 2 2 0 0 1 1 2 0 1 2 0 1 2\n",
            " 0 0 2 0 0 1 2 2 2 1 0 2 2 1 2 0 1 2 2 1 1 0 0 1 2 1 0 2 1 1 0 2 2 0 0 2 0\n",
            " 2 0 0 1 1 0 2 2 1 2 2 1 1 2 0 0 0 0 2 2 1 0 2 0 0 0 1 2 1 2 1 2 1 2 0 1 1\n",
            " 1 2 2 1 1 2 2 1 2 2 2 0 1 1 2 1 1 0 2 0 1 1 2 1 1 0 1 2 2 2 0 2 0 0 0 2 2\n",
            " 2 0 2 2 1 1 2 0 1 0 2 0 2 1 1 0 1 1 1 2 1 0 2 1 2 0 1 1 1 2 0 2 1 0 0 1 2\n",
            " 1 0 0 2 1 0 0 1 0 0 1 1 1 0 2 1 0 0 2 1 1 2 2 1 2 0 0 0 0 0 0 1 1 0 1 1 2\n",
            " 2 1 2 1 1 0 2 2 1 1 2 1 2 1 0 0 2 1 1 0 1 2 0 2 1 1 1 1 1 2 1 2 0 0 2 0 1\n",
            " 0 2 2 1 2]\n",
            "375\n",
            "['COVID' 'Normal' 'Viral Pneumonia']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekL7Zum1N3Dg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "478616cb-5ca7-4c6d-8a9d-8035a81c91c4"
      },
      "source": [
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "print(y_test_labels)\n",
        "print(len(y_test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 0 2 2 2 0 2 1 0 1 0 2 2 0 1 2 0 0 1 0 0 2 1 1 1 0 1 0 1 0 1 1 0 2 0 2 2\n",
            " 0 1 2 2 2 2 2 2 2 0 1 2 1 0 1 1 2 2 1 1 1 1 2 2 1 0 2 0 0 0 0 0 1 2 1 0 2\n",
            " 2 1 0 1 1 1 0 0 0 0 1 0 0 1 2 2 1 2 2 1 1 0 0 2 0 0 0 1 2 2 0 1 2 0 0 2 0\n",
            " 1 0 1 2 2 1 1 2 2 1 2 0 1 0 0 1 1 0 0 0 1 0 0 2 2 2 0 0 1 0 2 0 1 2 0 1 2\n",
            " 0 0 2 0 0 0 2 2 2 1 0 1 2 1 2 0 0 2 2 1 1 0 0 1 2 1 0 2 1 1 0 2 1 0 0 2 0\n",
            " 2 0 0 1 1 0 2 2 1 2 2 0 1 2 0 0 0 0 2 2 1 2 2 0 0 0 1 2 1 2 1 2 1 2 0 1 1\n",
            " 2 2 2 1 1 2 2 1 2 2 2 0 1 0 2 0 1 0 2 0 1 1 2 1 1 0 1 2 2 2 0 2 0 0 0 2 2\n",
            " 2 0 2 2 1 0 2 0 1 0 2 0 2 1 1 1 1 1 1 2 1 0 2 1 2 0 1 1 1 2 0 2 1 0 0 1 2\n",
            " 1 0 0 2 1 1 0 1 0 0 1 1 1 0 2 0 0 0 2 1 1 2 2 1 1 2 0 1 0 0 1 1 1 0 1 1 2\n",
            " 2 1 2 1 1 0 2 2 1 1 2 0 2 1 0 0 2 1 1 0 1 2 0 2 1 0 1 1 1 2 2 2 0 0 2 0 1\n",
            " 0 2 1 1 2]\n",
            "375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0jKoUlrN5wz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "7c6fa001-f78c-40d8-b4af-d0ae599d81f8"
      },
      "source": [
        "#Confusion matrix\n",
        "cm = confusion_matrix(y_test_labels, y_pred)\n",
        "print(cm)\n",
        "cm_df = pd.DataFrame(cm, index=le.classes_, columns=le.classes_)\n",
        "cm_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[110  14   1]\n",
            " [  4 117   4]\n",
            " [  2   4 119]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COVID</th>\n",
              "      <th>Normal</th>\n",
              "      <th>Viral Pneumonia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>COVID</th>\n",
              "      <td>110</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Normal</th>\n",
              "      <td>4</td>\n",
              "      <td>117</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Viral Pneumonia</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 COVID  Normal  Viral Pneumonia\n",
              "COVID              110      14                1\n",
              "Normal               4     117                4\n",
              "Viral Pneumonia      2       4              119"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W395b8WmN53_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "95e102dc-789e-4cdf-8a8d-dc4b02b7586a"
      },
      "source": [
        "sns.set(font_scale=1.5, color_codes=True, palette='deep')\n",
        "sns.heatmap(cm_df, annot=True, annot_kws={'size':16}, fmt='d', cmap='YlGnBu')\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.title('Confusion Matrix of Validation Data')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUSt12dBLZ2n",
        "outputId": "d635a8a9-9098-4ccd-8833-668bd14bac54"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print('\\nClassification Report\\n')\n",
        "print(classification_report(y_test_labels, y_pred, target_names=['COVID', 'Normal', 'Viral Pneumonia']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report\n",
            "\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          COVID       0.93      0.88      0.90       176\n",
            "         Normal       0.87      0.90      0.89       175\n",
            "Viral Pneumonia       0.96      0.98      0.97       175\n",
            "\n",
            "       accuracy                           0.92       526\n",
            "      macro avg       0.92      0.92      0.92       526\n",
            "   weighted avg       0.92      0.92      0.92       526\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}